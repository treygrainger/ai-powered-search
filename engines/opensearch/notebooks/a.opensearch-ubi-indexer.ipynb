{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aips import get_engine, set_engine\n",
    "from aips.spark.dataframe import from_sql\n",
    "from aips.spark import create_view_from_collection\n",
    "import tqdm\n",
    "\n",
    "set_engine(\"opensearch\")\n",
    "engine = get_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%run chapters/ch04/1.setting-up-the-retrotech-dataset.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_event(signal):\n",
    "    return {\"application\": \"aips_search\",\n",
    "            \"action_name\": signal[\"type\"],\n",
    "            \"query_id\": signal[\"query_id\"], \n",
    "            \"client_id\": signal[\"user\"],\n",
    "            \"timestamp\": datetime.now(),\n",
    "            \"message_type\": signal[\"type\"],\n",
    "            \"message\": signal[\"target\"],\n",
    "            \"target\": signal[\"target\"]}   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_events_dataframe():\n",
    "    signals_collection = engine.get_collection(\"signals\")\n",
    "    create_view_from_collection(signals_collection, \"signals\")\n",
    "    query = \"\"\"SELECT type AS action_name, query_id, user AS client_id\n",
    "                      signal_time AS timestamp, type AS message_type,\n",
    "                      target AS message, target AS target\n",
    "               FROM signals WHERE type != 'query'\"\"\"\n",
    "    events = from_sql(query)\n",
    "    return events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#events_collection = engine.create_collection(\"ubi_events\")\n",
    "#ubi_events_dataframe = get_events_dataframe()\n",
    "#events_collection.write(ubi_events_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_queries_dataframe():\n",
    "    signals_collection = engine.get_collection(\"signals\")\n",
    "    create_view_from_collection(signals_collection, \"signals\")\n",
    "    queries = from_sql(\"SELECT * FROM signals WHERE type = 'query'\")\n",
    "    queries_transformed = queries.rdd.map(lambda r: \n",
    "        (r[\"signal_time\"], r[\"query_id\"], r[\"user\"], r[\"target\"]))\n",
    "    ubi_queries_dataframe = queries_transformed.toDF(\n",
    "        [\"timestamp\", \"query_id\", \"client_id\", \"user_query\"])\n",
    "    return ubi_queries_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_search(collection, signal, log=False):\n",
    "    request = {\"query\": signal[\"user_query\"],\n",
    "               \"query_fields\": [\"name\", \"manufacturer\",\n",
    "                                \"long_description\", \"short_description\"],\n",
    "               \"return_fields\": [\"*\"],\n",
    "               \"limit\": 10,\n",
    "               \"ext\": {\"ubi\": signal}}\n",
    "    results = collection.search(**request, log=log)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wiping \"ubi_queries\" collection\n",
      "Creating \"ubi_queries\" collection\n",
      "Successfully written 725459 documents\n"
     ]
    }
   ],
   "source": [
    "queries_collection = engine.create_collection(\"ubi_queries\")\n",
    "ubi_queries_dataframe = get_queries_dataframe()\n",
    "queries_collection.write(ubi_queries_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/725459 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search Request:\n",
      "{\n",
      "  \"query\": {\n",
      "    \"query_string\": {\n",
      "      \"query\": \"Iphone headphones\",\n",
      "      \"boost\": 0.454545454,\n",
      "      \"fields\": [\n",
      "        \"name\",\n",
      "        \"manufacturer\",\n",
      "        \"long_description\",\n",
      "        \"short_description\"\n",
      "      ]\n",
      "    }\n",
      "  },\n",
      "  \"size\": 10,\n",
      "  \"fields\": [\n",
      "    \"*\"\n",
      "  ],\n",
      "  \"ext\": {\n",
      "    \"ubi\": {\n",
      "      \"timestamp\": 1572238882476,\n",
      "      \"query_id\": \"u420243_0_1\",\n",
      "      \"client_id\": \"u420243\",\n",
      "      \"user_query\": \"Iphone headphones\"\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "{'error': {'root_cause': [{'type': 'named_object_not_found_exception', 'reason': '[1:204] unknown field [ubi]'}], 'type': 'named_object_not_found_exception', 'reason': '[1:204] unknown field [ubi]'}, 'status': 400}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m ubi_queries_dataframe \u001b[38;5;241m=\u001b[39m get_queries_dataframe()\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m q \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(ubi_queries_dataframe\u001b[38;5;241m.\u001b[39mcollect(), total\u001b[38;5;241m=\u001b[39mubi_queries_dataframe\u001b[38;5;241m.\u001b[39mcount()):\n\u001b[0;32m---> 14\u001b[0m     \u001b[43mexecute_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproducts_collection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masDict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 8\u001b[0m, in \u001b[0;36mexecute_search\u001b[0;34m(collection, signal, log)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecute_search\u001b[39m(collection, signal, log\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m      2\u001b[0m     request \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m: signal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_query\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      3\u001b[0m                \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery_fields\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmanufacturer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m                                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlong_description\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshort_description\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      5\u001b[0m                \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn_fields\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      6\u001b[0m                \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlimit\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m      7\u001b[0m                \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mext\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mubi\u001b[39m\u001b[38;5;124m\"\u001b[39m: signal}}\n\u001b[0;32m----> 8\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mcollection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/engines/opensearch/OpenSearchCollection.py:132\u001b[0m, in \u001b[0;36mOpenSearchCollection.search\u001b[0;34m(self, **search_args)\u001b[0m\n\u001b[1;32m    130\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform_request(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msearch_args)\n\u001b[1;32m    131\u001b[0m search_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnative_search(request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m--> 132\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43msearch_response\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/engines/opensearch/OpenSearchCollection.py:119\u001b[0m, in \u001b[0;36mOpenSearchCollection.transform_response\u001b[0;34m(self, search_response)\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m formatted\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhits\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m search_response:\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(search_response)\n\u001b[1;32m    120\u001b[0m response \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [format_doc(d)\n\u001b[1;32m    121\u001b[0m                      \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m search_response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhits\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhits\u001b[39m\u001b[38;5;124m\"\u001b[39m]]}\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhighlighting\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m search_response:\n",
      "\u001b[0;31mValueError\u001b[0m: {'error': {'root_cause': [{'type': 'named_object_not_found_exception', 'reason': '[1:204] unknown field [ubi]'}], 'type': 'named_object_not_found_exception', 'reason': '[1:204] unknown field [ubi]'}, 'status': 400}"
     ]
    }
   ],
   "source": [
    "\n",
    "products_collection = engine.get_collection(\"products\")\n",
    "ubi_queries_dataframe = get_queries_dataframe()\n",
    "for q in tqdm.tqdm(ubi_queries_dataframe.collect(), total=ubi_queries_dataframe.count()):\n",
    "    execute_search(products_collection, q.asDict(), log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wiping \"signals\" collection\n",
      "Creating \"signals\" collection\n",
      "Successfully written 725459 documents\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Some of types cannot be determined by the first 100 rows, please try again with sampling",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m signals_collection \u001b[38;5;241m=\u001b[39m engine\u001b[38;5;241m.\u001b[39mcreate_collection(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msignals\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     24\u001b[0m write_queries_to_collection(signals_collection)\n\u001b[0;32m---> 25\u001b[0m \u001b[43mwrite_events_to_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[43msignals_collection\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 8\u001b[0m, in \u001b[0;36mwrite_events_to_collection\u001b[0;34m(collection)\u001b[0m\n\u001b[1;32m      4\u001b[0m events \u001b[38;5;241m=\u001b[39m from_sql(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSELECT * FROM ubi_events\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m events_transformed \u001b[38;5;241m=\u001b[39m events\u001b[38;5;241m.\u001b[39mrdd\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m r: \n\u001b[1;32m      6\u001b[0m     (r[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m\"\u001b[39m], r[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery_id\u001b[39m\u001b[38;5;124m\"\u001b[39m], r[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclient_id\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      7\u001b[0m      r[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m], r[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage_type\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[0;32m----> 8\u001b[0m events_dataframe \u001b[38;5;241m=\u001b[39m \u001b[43mevents_transformed\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoDF\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msignal_time\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquery_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtarget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m collection\u001b[38;5;241m.\u001b[39mwrite(events_dataframe)\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/session.py:102\u001b[0m, in \u001b[0;36m_monkey_patch_RDD.<locals>.toDF\u001b[0;34m(self, schema, sampleRatio)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;129m@no_type_check\u001b[39m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtoDF\u001b[39m(\u001b[38;5;28mself\u001b[39m, schema\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sampleRatio\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     76\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;124;03m    Converts current :class:`RDD` into a :class:`DataFrame`\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;124;03m    [Row(name='Alice', age=1)]\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreateDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampleRatio\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/session.py:894\u001b[0m, in \u001b[0;36mSparkSession.createDataFrame\u001b[0;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[1;32m    889\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_pandas \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, pandas\u001b[38;5;241m.\u001b[39mDataFrame):\n\u001b[1;32m    890\u001b[0m     \u001b[38;5;66;03m# Create a DataFrame from pandas DataFrame.\u001b[39;00m\n\u001b[1;32m    891\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(SparkSession, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mcreateDataFrame(  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[1;32m    892\u001b[0m         data, schema, samplingRatio, verifySchema\n\u001b[1;32m    893\u001b[0m     )\n\u001b[0;32m--> 894\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_dataframe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamplingRatio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverifySchema\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    896\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/session.py:934\u001b[0m, in \u001b[0;36mSparkSession._create_dataframe\u001b[0;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[1;32m    933\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, RDD):\n\u001b[0;32m--> 934\u001b[0m     rdd, struct \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_createFromRDD\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprepare\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamplingRatio\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    935\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    936\u001b[0m     rdd, struct \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_createFromLocal(\u001b[38;5;28mmap\u001b[39m(prepare, data), schema)\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/session.py:600\u001b[0m, in \u001b[0;36mSparkSession._createFromRDD\u001b[0;34m(self, rdd, schema, samplingRatio)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;124;03mCreate an RDD for DataFrame from an existing RDD, returns the RDD and schema.\u001b[39;00m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(schema, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m--> 600\u001b[0m     struct \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inferSchema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrdd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamplingRatio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    601\u001b[0m     converter \u001b[38;5;241m=\u001b[39m _create_converter(struct)\n\u001b[1;32m    602\u001b[0m     tupled_rdd \u001b[38;5;241m=\u001b[39m rdd\u001b[38;5;241m.\u001b[39mmap(converter)\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/session.py:573\u001b[0m, in \u001b[0;36mSparkSession._inferSchema\u001b[0;34m(self, rdd, samplingRatio, names)\u001b[0m\n\u001b[1;32m    571\u001b[0m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    572\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 573\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    574\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSome of types cannot be determined by the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    575\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfirst 100 rows, please try again with sampling\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    576\u001b[0m             )\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m samplingRatio \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.99\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: Some of types cannot be determined by the first 100 rows, please try again with sampling"
     ]
    }
   ],
   "source": [
    "def write_events_to_collection(collection):\n",
    "    ubi_events_collection = engine.get_collection(\"ubi_events\")\n",
    "    create_view_from_collection(ubi_events_collection, \"ubi_events\")\n",
    "    events = from_sql(\"SELECT * FROM ubi_events\")\n",
    "    events_transformed = events.rdd.map(lambda r: \n",
    "        (r[\"timestamp\"], r[\"query_id\"], r[\"client_id\"],\n",
    "         r[\"message\"], r[\"message_type\"]))\n",
    "    events_dataframe = events_transformed.toDF(\n",
    "        [\"signal_time\", \"query_id\", \"user\", \"target\", \"type\"])\n",
    "    collection.write(events_dataframe) \n",
    "\n",
    "def write_queries_to_collection(collection):\n",
    "    ubi_queries_collection = engine.get_collection(\"ubi_queries\")\n",
    "    create_view_from_collection(ubi_queries_collection, \"ubi_queries\")\n",
    "    queries = from_sql(\"SELECT * FROM ubi_queries\")\n",
    "    queries_transformed = queries.rdd.map(lambda r: \n",
    "        (r[\"timestamp\"], r[\"query_id\"], r[\"client_id\"],\n",
    "         r[\"user_query\"], \"query\"))\n",
    "    queries_dataframe = queries_transformed.toDF(\n",
    "        [\"signal_time\", \"query_id\", \"user\", \"target\", \"type\"])\n",
    "    collection.write(queries_dataframe)\n",
    "\n",
    "signals_collection = engine.create_collection(\"signals\")\n",
    "write_queries_to_collection(signals_collection)\n",
    "write_events_to_collection(signals_collection)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
