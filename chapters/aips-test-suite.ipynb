{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Testing Harness\n",
    "\n",
    "This notebook executes all Jupyter notebooks in the project recursively and reports their completion status.\n",
    "\n",
    "It serves as a testing harness to verify that all notebooks run successfully without errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import nbformat\n",
    "from nbconvert.preprocessors import ExecutePreprocessor\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import traceback\n",
    "from pathlib import Path\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from pyspark.conf import SparkConf #Recommended for making ALS run faster, if you have enough memory / cores allocated to docker\n",
    "conf = SparkConf()\n",
    "conf.set(\"spark.driver.memory\", \"7g\")\n",
    "conf.set(\"spark.executor.memory\", \"7g\")\n",
    "conf.set(\"spark.dynamicAllocation.enabled\", \"true\")\n",
    "conf.set(\"spark.dynamicAllocation.executorMemoryOverhead\", \"7g\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "KERNEL_NAME = \"python3\"\n",
    "KERNEL_OVERRIDES = {\"1.open-information-extraction.ipynb\": \"ch5-spacy\"}\n",
    "EXCLUDE_DIRS = [\".ipynb_checkpoints\", \"__pycache__\"]\n",
    "EXPORT_RESULTS = True\n",
    "RESULTS_FILE = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(seconds):\n",
    "    if seconds < 60:\n",
    "        formatted = f\"{seconds:.2f}s\"\n",
    "    elif seconds < 3600:\n",
    "        formatted =  f\"{seconds / 60:.2f}m\"\n",
    "    else:\n",
    "        formatted =  f\"{seconds / 3600:.2f}h\"\n",
    "    return formatted\n",
    "\n",
    "def export_results(results, filename=\"test_results.json\"):\n",
    "    if results:\n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump({\"timestamp\": datetime.now().isoformat(),\n",
    "                       \"results\": results[\"details\"],\n",
    "                       \"summary\": results[\"summary\"]}, f, indent=2)\n",
    "        print(f\"📄 Results exported to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_notebook_files(root_dir=\".\", exclude_dirs=None, excluded_notebooks=None):\n",
    "    \"\"\"\n",
    "    Recursively get all .ipynb files in the specified directory and its subdirectories,\n",
    "    excluding specific directories and notebooks.\n",
    "    \n",
    "    Args:\n",
    "        root_dir (str): Root directory to search from\n",
    "        exclude_dirs (list): List of directory names to exclude\n",
    "        exclude_notebooks (list): List of notebook filenames to exclude\n",
    "        \n",
    "    Returns:\n",
    "        list: Sorted list of notebook file paths\n",
    "    \"\"\"\n",
    "    if exclude_dirs is None:\n",
    "        exclude_dirs = []\n",
    "    \n",
    "    if excluded_notebooks is None:\n",
    "        excluded_notebooks = [\"bonus.related-terms-from-documents.ipynb\"\n",
    "                              \"bonus.phrase-detection.ipynb\",\n",
    "                              \"bonus.phrase-detection.ipynb\",\n",
    "                              \"bonus.related-terms-from-documents.ipynb\",\n",
    "                              \"a.defunct.synthesize-search-sessions.ipynb\",\n",
    "                              \"a.synthesize-search-sessions.ipynb\",\n",
    "                              \"a.generate-movie-embeddings.ipynb\",\n",
    "                              \"welcome.ipynb\",\n",
    "                              \"aips-test-suite.ipynb\",\n",
    "                              \"4.train-upload-search-ltr.ipynb\"]\n",
    "        \n",
    "    notebook_files = []\n",
    "    \n",
    "    for directory in os.walk(root_dir):\n",
    "        for path in Path(directory[0]).rglob(\"*.ipynb\"):\n",
    "            if any(exclude_dir in str(path) for exclude_dir in exclude_dirs) or \\\n",
    "                path.name in excluded_notebooks:\n",
    "                continue\n",
    "            if str(path) not in notebook_files:\n",
    "                notebook_files.append(str(path))\n",
    "    \n",
    "    notebook_files = sorted(notebook_files)\n",
    "    return list(map(Path, notebook_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_notebook(notebook_path, timeout=600, kernel_name=\"python3\"):\n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    try:\n",
    "        with open(notebook_path, 'r', encoding='utf-8') as f:\n",
    "            nb = nbformat.read(f, as_version=4)\n",
    "            ep = ExecutePreprocessor(timeout=timeout, kernel_name=kernel_name)\n",
    "            ep.preprocess(nb, {'metadata': {'path': os.path.dirname(notebook_path)}})\n",
    "        execution_time = (datetime.now() - start_time).total_seconds()\n",
    "        return True, execution_time, None\n",
    "    \n",
    "    except Exception as e:\n",
    "        execution_time = (datetime.now() - start_time).total_seconds()\n",
    "        error_type = type(e).__name__\n",
    "        error_msg = str(e)\n",
    "        # Get traceback for detailed error information\n",
    "        tb = traceback.format_exc()\n",
    "        \n",
    "        return False, execution_time, {\n",
    "            'type': error_type,\n",
    "            'message': error_msg,\n",
    "            'traceback': tb\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Testing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test_harness(exclude_dirs=None, exclude_notebooks=None, stop_on_failure=False,\n",
    "                     chapter_to_run=None, verbose_errors=True):\n",
    "    \"\"\"\n",
    "    Run the testing harness on all notebooks recursively.\n",
    "    \n",
    "    Args:\n",
    "        root_dir (str): Root directory to search from\n",
    "        timeout (int): Execution timeout in seconds\n",
    "        kernel_name (str): Name of the kernel to use\n",
    "        exclude_dirs (list): List of directory names to exclude\n",
    "        exclude_notebooks (list): List of notebook filenames to exclude\n",
    "        \n",
    "    Returns:\n",
    "        dict: Test results\n",
    "    \"\"\"\n",
    "    root_dir = \".\"\n",
    "    timeout = 600 \n",
    "    print(f\"🔍 Notebook Testing Harness - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(f\"📁 Testing from root directory: {os.path.abspath(root_dir)}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    notebook_files = get_notebook_files(root_dir, exclude_dirs, exclude_notebooks)\n",
    "\n",
    "    if chapter_to_run:\n",
    "        notebook_files = [f for f in notebook_files if (chapter_to_run in str(f))]\n",
    "\n",
    "    print(f\"📋 Found {len(notebook_files)} notebook(s) to test.\")\n",
    "    for nb_file in notebook_files:\n",
    "        # Make paths relative to root_dir for cleaner display\n",
    "        rel_path = os.path.relpath(str(nb_file), root_dir)\n",
    "        print(f\"   • {rel_path}\")\n",
    "    print()\n",
    "    \n",
    "    # Results tracking\n",
    "    results = {\n",
    "        'details': [],\n",
    "        'summary': {\n",
    "            'total': len(notebook_files),\n",
    "            'successful': 0,\n",
    "            'failed': 0,\n",
    "            'total_time': 0\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Execute each notebook with progress bar\n",
    "    print(\"🚀 Executing notebooks:\")\n",
    "    for notebook_path in tqdm(notebook_files, desc=\"Progress\", colour=\"purple\"):\n",
    "        rel_path = os.path.relpath(str(notebook_path), root_dir)\n",
    "        print(f\"\\n📔 Testing: {rel_path}\")\n",
    "        if \"checkpoint\" in str(notebook_path):\n",
    "            print(f\"\\n📔 Skipping: {rel_path}\")\n",
    "            continue\n",
    "        kernel_name = KERNEL_OVERRIDES.get(notebook_path.name, \"python3\")\n",
    "        success, execution_time, error = execute_notebook(str(notebook_path), timeout, kernel_name)\n",
    "        \n",
    "        results['summary']['total_time'] += execution_time\n",
    "        \n",
    "        if success:\n",
    "            print(f\"   ✅ SUCCESS - Completed in {format_time(execution_time)}\")\n",
    "            results['summary']['successful'] += 1\n",
    "        else:\n",
    "            print(f\"   ❌ FAILED - Error after {format_time(execution_time)}\")\n",
    "            print(f\"      Error: {error['type']}\")\n",
    "            results['summary']['failed'] += 1\n",
    "        \n",
    "        results['details'].append({\n",
    "            'notebook': rel_path,\n",
    "            'success': success,\n",
    "            'execution_time': execution_time,\n",
    "            'error': error\n",
    "        })\n",
    "        if not success and stop_on_failure:\n",
    "            print(\"Terminating test run due to test failure.\")\n",
    "            break\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"📊 SUMMARY:\")\n",
    "    print(f\"   Total notebooks tested: {results['summary']['total']}\")\n",
    "    print(f\"   ✅ Successful: {results['summary']['successful']}\")\n",
    "    print(f\"   ❌ Failed: {results['summary']['failed']}\")\n",
    "    \n",
    "    success_rate = (results['summary']['successful'] / results['summary']['total']) * 100\n",
    "    print(f\"   Success rate: {success_rate:.1f}%\")\n",
    "    print(f\"   Total execution time: {format_time(results['summary']['total_time'])}\")\n",
    "\n",
    "    if results['summary']['failed'] > 0:\n",
    "        print(f\"\\n❌ FAILED NOTEBOOKS:\")\n",
    "        for result in results['details']:\n",
    "            if not result['success']:\n",
    "                if verbose_errors:\n",
    "                    print(f\"   • {result['notebook']}: {result['error']['type']}: {result['error']['message']}\")\n",
    "                else:\n",
    "                    print(f\"   • {result['notebook']}: {result['error']['type']}\")\n",
    "    \n",
    "    print(f\"\\n🏁 Testing completed at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    \n",
    "    if EXPORT_RESULTS and results:\n",
    "        export_results(results, \"AIPS_test_resulsts.json\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Testing Harness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Notebook Testing Harness - 2025-07-28 17:11:35\n",
      "📁 Testing from root directory: /home/jovyan\n",
      "================================================================================\n",
      "📋 Found 4 notebook(s) to test.\n",
      "   • chapters/ch14/1.question-answering-visualizer.ipynb\n",
      "   • chapters/ch14/2.question-answering-data-preparation.ipynb\n",
      "   • chapters/ch14/3.question-answering-fine-tuning.ipynb\n",
      "   • chapters/ch14/4.question-answering-demo-application.ipynb\n",
      "\n",
      "🚀 Executing notebooks:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e70240e9ce24e9c9ad9f60531f8d9bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Progress:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📔 Testing: chapters/ch14/1.question-answering-visualizer.ipynb\n",
      "   ✅ SUCCESS - Completed in 20.37s\n",
      "\n",
      "📔 Testing: chapters/ch14/2.question-answering-data-preparation.ipynb\n",
      "   ✅ SUCCESS - Completed in 4.27m\n",
      "\n",
      "📔 Testing: chapters/ch14/3.question-answering-fine-tuning.ipynb\n",
      "   ❌ FAILED - Error after 4.29s\n",
      "      Error: CellExecutionError\n",
      "Terminating test run due to test failure.\n",
      "\n",
      "================================================================================\n",
      "📊 SUMMARY:\n",
      "   Total notebooks tested: 4\n",
      "   ✅ Successful: 2\n",
      "   ❌ Failed: 1\n",
      "   Success rate: 50.0%\n",
      "   Total execution time: 4.68m\n",
      "\n",
      "❌ FAILED NOTEBOOKS:\n",
      "   • chapters/ch14/3.question-answering-fine-tuning.ipynb: CellExecutionError: An error occurred while executing the following cell:\n",
      "------------------\n",
      "#This method adopted from the following example notebook:\n",
      "#https://github.com/huggingface/notebooks/blob/master/examples/question_answering.ipynb\n",
      "#Copyright 2021, Huggingface.  Apache 2.0 license.\n",
      "import datasets\n",
      "\n",
      "file = \"data/question-answering/question-answering-training-set\"\n",
      "datadict = datasets.load_from_disk(file)\n",
      "\n",
      "def tokenize_dataset(examples):\n",
      "\n",
      "    maximum_tokens = 384 # This will be the number of tokens in BOTH the question and context\n",
      "    document_overlap = 128 # Sometimes we need to split the context into smaller chunks, so we will overlap with this window\n",
      "    pad_on_right = tokenizer.padding_side == \"right\"\n",
      "    \n",
      "    # Tokenize our examples with truncation and padding, but keep the overflows using a stride. This results\n",
      "    # in one example possible giving several features when a context is long, each of those features having a\n",
      "    # context that overlaps a bit the context of the previous feature.\n",
      "    tokenized_examples = tokenizer(\n",
      "        examples[\"question\" if pad_on_right else \"context\"],\n",
      "        examples[\"context\" if pad_on_right else \"question\"],\n",
      "        truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
      "        max_length=maximum_tokens,\n",
      "        stride=document_overlap,\n",
      "        return_overflowing_tokens=True,\n",
      "        return_offsets_mapping=True,\n",
      "        padding=\"max_length\"\n",
      "    )\n",
      "    \n",
      "    print(tokenized_examples[0])\n",
      "\n",
      "    # Since one example might give us several features if it has a long context, we need a map from a feature to\n",
      "    # its corresponding example. This key gives us just that.\n",
      "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
      "    # The offset mappings will give us a map from token to character position in the original context. This will\n",
      "    # help us compute the start_positions and end_positions.\n",
      "    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n",
      "\n",
      "    # Let's label those examples!\n",
      "    tokenized_examples[\"start_positions\"] = []\n",
      "    tokenized_examples[\"end_positions\"] = []\n",
      "\n",
      "    for i, offsets in enumerate(offset_mapping):\n",
      "        # We will label impossible answers with the index of the CLS token.\n",
      "        input_ids = tokenized_examples[\"input_ids\"][i]\n",
      "        cls_index = input_ids.index(tokenizer.cls_token_id)\n",
      "\n",
      "        # Grab the sequence corresponding to that example (to know what is the context and what is the question).\n",
      "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
      "\n",
      "        # One example can give several spans, this is the index of the example containing this span of text.\n",
      "        sample_index = sample_mapping[i]\n",
      "        answers = examples[\"answers\"][sample_index]\n",
      "        # If no answers are given, set the cls_index as answer.\n",
      "        if len(answers[\"answer_start\"]) == 0:\n",
      "            tokenized_examples[\"start_positions\"].append(cls_index)\n",
      "            tokenized_examples[\"end_positions\"].append(cls_index)\n",
      "        else:\n",
      "            # Start/end character index of the answer in the text.\n",
      "            start_char = answers[\"answer_start\"][0]\n",
      "            end_char = start_char + len(answers[\"text\"][0])\n",
      "\n",
      "            # Start token index of the current span in the text.\n",
      "            token_start_index = 0\n",
      "            while sequence_ids[token_start_index] != (1 if pad_on_right else 0):\n",
      "                token_start_index += 1\n",
      "\n",
      "            # End token index of the current span in the text.\n",
      "            token_end_index = len(input_ids) - 1\n",
      "            while sequence_ids[token_end_index] != (1 if pad_on_right else 0):\n",
      "                token_end_index -= 1\n",
      "\n",
      "            # Detect if the answer is out of the span (in which case this feature is labeled with the CLS index).\n",
      "            if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n",
      "                tokenized_examples[\"start_positions\"].append(cls_index)\n",
      "                tokenized_examples[\"end_positions\"].append(cls_index)\n",
      "            else:\n",
      "                # Otherwise move the token_start_index and token_end_index to the two ends of the answer.\n",
      "                # Note: we could go after the last offset if the answer is the last word (edge case).\n",
      "                while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
      "                    token_start_index += 1\n",
      "                tokenized_examples[\"start_positions\"].append(token_start_index - 1)\n",
      "                while offsets[token_end_index][1] >= end_char:\n",
      "                    token_end_index -= 1\n",
      "                tokenized_examples[\"end_positions\"].append(token_end_index + 1)\n",
      "\n",
      "    return tokenized_examples\n",
      "\"\"\"\n",
      "To apply this function on all the sentences (or pairs of sentences) in our dataset, we just use the map method of our dataset object we created earlier. \n",
      "This will apply the function on all the elements of all the splits in dataset, so our training, validation and testing data will be preprocessed in one single command. \n",
      "Since our preprocessing changes the number of samples, we need to remove the old columns when applying it.\n",
      " --Huggingface\n",
      "\"\"\"\n",
      "tokenized_datasets = datadict.map(tokenize_dataset, batched=True, remove_columns=datadict[\"train\"].column_names)\n",
      "------------------\n",
      "\n",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[7], line 7\u001b[0m\n",
      "\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m\n",
      "\u001b[1;32m      6\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/question-answering/question-answering-training-set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;32m----> 7\u001b[0m datadict \u001b[38;5;241m=\u001b[39m \u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_from_disk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtokenize_dataset\u001b[39m(examples):\n",
      "\u001b[1;32m     11\u001b[0m     maximum_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m384\u001b[39m \u001b[38;5;66;03m# This will be the number of tokens in BOTH the question and context\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/load.py:2152\u001b[0m, in \u001b[0;36mload_from_disk\u001b[0;34m(dataset_path, keep_in_memory, storage_options)\u001b[0m\n",
      "\u001b[1;32m   2150\u001b[0m fs, \u001b[38;5;241m*\u001b[39m_ \u001b[38;5;241m=\u001b[39m url_to_fs(dataset_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(storage_options \u001b[38;5;129;01mor\u001b[39;00m {}))\n",
      "\u001b[1;32m   2151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fs\u001b[38;5;241m.\u001b[39mexists(dataset_path):\n",
      "\u001b[0;32m-> 2152\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDirectory \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;32m   2153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fs\u001b[38;5;241m.\u001b[39misfile(posixpath\u001b[38;5;241m.\u001b[39mjoin(dataset_path, config\u001b[38;5;241m.\u001b[39mDATASET_INFO_FILENAME)) \u001b[38;5;129;01mand\u001b[39;00m fs\u001b[38;5;241m.\u001b[39misfile(\n",
      "\u001b[1;32m   2154\u001b[0m     posixpath\u001b[38;5;241m.\u001b[39mjoin(dataset_path, config\u001b[38;5;241m.\u001b[39mDATASET_STATE_JSON_FILENAME)\n",
      "\u001b[1;32m   2155\u001b[0m ):\n",
      "\u001b[1;32m   2156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Dataset\u001b[38;5;241m.\u001b[39mload_from_disk(dataset_path, keep_in_memory\u001b[38;5;241m=\u001b[39mkeep_in_memory, storage_options\u001b[38;5;241m=\u001b[39mstorage_options)\n",
      "\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Directory data/question-answering/question-answering-training-set not found\n",
      "FileNotFoundError: Directory data/question-answering/question-answering-training-set not found\n",
      "\n",
      "\n",
      "🏁 Testing completed at 2025-07-28 17:16:16\n",
      "📄 Results exported to AIPS_test_resulsts.json\n",
      "🔍 Notebook Testing Harness - 2025-07-28 17:16:16\n",
      "📁 Testing from root directory: /home/jovyan\n",
      "================================================================================\n",
      "📋 Found 2 notebook(s) to test.\n",
      "   • chapters/ch15/1.llm-exploration.ipynb\n",
      "   • chapters/ch15/2.multimodal-and-hybrid-search.ipynb\n",
      "\n",
      "🚀 Executing notebooks:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b551cab6013a484aba2876e3aa53a2fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Progress:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📔 Testing: chapters/ch15/1.llm-exploration.ipynb\n",
      "   ❌ FAILED - Error after 7.36s\n",
      "      Error: CellExecutionError\n",
      "Terminating test run due to test failure.\n",
      "\n",
      "================================================================================\n",
      "📊 SUMMARY:\n",
      "   Total notebooks tested: 2\n",
      "   ✅ Successful: 0\n",
      "   ❌ Failed: 1\n",
      "   Success rate: 0.0%\n",
      "   Total execution time: 7.36s\n",
      "\n",
      "❌ FAILED NOTEBOOKS:\n",
      "   • chapters/ch15/1.llm-exploration.ipynb: CellExecutionError: An error occurred while executing the following cell:\n",
      "------------------\n",
      "r = get_generative_response(\"What is a unicorn?\")\n",
      "------------------\n",
      "\n",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n",
      "\u001b[0;32m----> 1\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43mget_generative_response\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWhat is a unicorn?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\n",
      "Cell \u001b[0;32mIn[2], line 9\u001b[0m, in \u001b[0;36mget_generative_response\u001b[0;34m(prompt)\u001b[0m\n",
      "\u001b[1;32m      4\u001b[0m response \u001b[38;5;241m=\u001b[39m mockedGenerativeResponses\u001b[38;5;241m.\u001b[39mloc[mockedGenerativeResponses[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m prompt, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n",
      "\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(response) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;32m      6\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'''\u001b[39m\n",
      "\u001b[1;32m      7\u001b[0m \u001b[38;5;124m    <div style=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverflow: auto; margin-bottom: 10px;\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>\u001b[39m\n",
      "\u001b[1;32m      8\u001b[0m \u001b[38;5;124m      <h3 style=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat: left; width: 100px; margin-right: 10px;\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>Query:</h3>\u001b[39m\n",
      "\u001b[0;32m----> 9\u001b[0m \u001b[38;5;124m      <p style=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverflow: hidden; margin-left: 110px;\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m><pre>\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mhtml\u001b[49m\u001b[38;5;241m.\u001b[39mescape(prompt)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m<pre></p>\u001b[39m\n",
      "\u001b[1;32m     10\u001b[0m \u001b[38;5;124m    </div>\u001b[39m\n",
      "\u001b[1;32m     11\u001b[0m \n",
      "\u001b[1;32m     12\u001b[0m \u001b[38;5;124m    <div style=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverflow: auto; margin-bottom: 10px;\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>\u001b[39m\n",
      "\u001b[1;32m     13\u001b[0m \u001b[38;5;124m      <h3 style=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat: left; width: 100px; margin-right: 10px;\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>Response:</h3>\u001b[39m\n",
      "\u001b[1;32m     14\u001b[0m \u001b[38;5;124m      <p style=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverflow: hidden; margin-left: 110px;\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m><pre>\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhtml\u001b[38;5;241m.\u001b[39mescape(response[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m</pre></p>\u001b[39m\n",
      "\u001b[1;32m     15\u001b[0m \u001b[38;5;124m    </div>\u001b[39m\n",
      "\u001b[1;32m     16\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m'''\u001b[39m\n",
      "\u001b[1;32m     17\u001b[0m     display(HTML(output))\n",
      "\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response[\u001b[38;5;241m0\u001b[39m]\n",
      "\n",
      "\u001b[0;31mNameError\u001b[0m: name 'html' is not defined\n",
      "NameError: name 'html' is not defined\n",
      "\n",
      "\n",
      "🏁 Testing completed at 2025-07-28 17:16:24\n",
      "📄 Results exported to AIPS_test_resulsts.json\n"
     ]
    }
   ],
   "source": [
    "results = run_test_harness(exclude_dirs=EXCLUDE_DIRS, stop_on_failure=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Results (Optional)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
