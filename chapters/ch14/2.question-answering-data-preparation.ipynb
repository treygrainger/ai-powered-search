{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Answering Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import sys\n",
    "\n",
    "import pandas\n",
    "\n",
    "sys.path.append('../..')\n",
    "from aips import *\n",
    "\n",
    "engine = get_engine()\n",
    "outdoors_collection = engine.get_collection(\"outdoors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: This notebook depends upon the Outdoors dataset. If you have any issues, please rerun the [Setting up the Outdoors Dataset](../ch13/1.setting-up-the-outdoors-dataset.ipynb) notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 14.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_questions():\n",
    "    question_types = [\"who\", \"what\", \"when\", \"where\", \"why\", \"how\"]\n",
    "    questions = []\n",
    "    for type in question_types:\n",
    "        request = {\n",
    "            \"query\": type,\n",
    "            \"query_fields\": [\"title\"],\n",
    "            \"return_fields\": [\"id\", \"url\", \"owner_user_id\", \"title\", \"accepted_answer_id\"],\n",
    "            \"filters\": [(\"accepted_answer_id\", \"*\")],\n",
    "            \"limit\": 10000\n",
    "        }\n",
    "        docs = outdoors_collection.search(**request)[\"docs\"]\n",
    "        questions += [d for d in docs\n",
    "                      if d[\"title\"].lower().startswith(type)]  #Only titles starting with a question type\n",
    "    return questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 14.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answers_from_questions(questions, batch_size=500):\n",
    "    answer_ids = list(set([str(q[\"accepted_answer_id\"]) for q in questions]))\n",
    "    batches = -(-len(answer_ids) // batch_size)\n",
    "    answers = {}\n",
    "    for n in range(0, batches):\n",
    "        ids = answer_ids[n * batch_size:(n + 1) * batch_size]\n",
    "        request = {\"query\": \"(\" + \" \".join(ids) + \")\",\n",
    "                   \"query_fields\": \"id\",\n",
    "                   \"limit\": len(questions),\n",
    "                   \"filters\": [(\"post_type\", \"answer\")],\n",
    "                   \"order_by\": [(\"score\", \"desc\")]}\n",
    "        docs = outdoors_collection.search(**request)[\"docs\"]\n",
    "        answers |= {int(d[\"id\"]): d[\"body\"] for d in docs}\n",
    "    return answers\n",
    "    \n",
    "def get_context_dataframe(questions):\n",
    "    answers = get_answers_from_questions(questions)\n",
    "    print(len(answers.keys()))\n",
    "    contexts = {\"id\": [], \"question\": [], \"context\": [], \"url\": []}\n",
    "    for question in questions:\n",
    "        contexts[\"id\"].append(question[\"id\"])\n",
    "        contexts[\"url\"].append(question[\"url\"])\n",
    "        contexts[\"question\"].append(question[\"title\"]),\n",
    "        if question[\"accepted_answer_id\"] in answers:\n",
    "            context = answers[question[\"accepted_answer_id\"]]\n",
    "        else:\n",
    "            context = \"Not found\"\n",
    "        contexts[\"context\"].append(context)\n",
    "    return pandas.DataFrame(contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1663\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4410</td>\n",
       "      <td>Who places the anchors that rock climbers use?</td>\n",
       "      <td>There are two distinct styles of free rock cli...</td>\n",
       "      <td>https://outdoors.stackexchange.com/questions/4410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5347</td>\n",
       "      <td>Who places the bolts on rock climbing routes, ...</td>\n",
       "      <td>What you're talking about is Sport climbing. G...</td>\n",
       "      <td>https://outdoors.stackexchange.com/questions/5347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20662</td>\n",
       "      <td>Who gets the bill if you activate a PLB to hel...</td>\n",
       "      <td>Almost always the victim gets the bill, but as...</td>\n",
       "      <td>https://outdoors.stackexchange.com/questions/2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11587</td>\n",
       "      <td>What sort of crane, and what sort of snake?</td>\n",
       "      <td>To answer the snake part of it, looking at som...</td>\n",
       "      <td>https://outdoors.stackexchange.com/questions/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7623</td>\n",
       "      <td>What knot is this one? What are its purposes?</td>\n",
       "      <td>Slip knot It's undoubtably a slip knot that's ...</td>\n",
       "      <td>https://outdoors.stackexchange.com/questions/7623</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                           question  \\\n",
       "0   4410     Who places the anchors that rock climbers use?   \n",
       "1   5347  Who places the bolts on rock climbing routes, ...   \n",
       "2  20662  Who gets the bill if you activate a PLB to hel...   \n",
       "3  11587        What sort of crane, and what sort of snake?   \n",
       "4   7623      What knot is this one? What are its purposes?   \n",
       "\n",
       "                                             context  \\\n",
       "0  There are two distinct styles of free rock cli...   \n",
       "1  What you're talking about is Sport climbing. G...   \n",
       "2  Almost always the victim gets the bill, but as...   \n",
       "3  To answer the snake part of it, looking at som...   \n",
       "4  Slip knot It's undoubtably a slip knot that's ...   \n",
       "\n",
       "                                                 url  \n",
       "0  https://outdoors.stackexchange.com/questions/4410  \n",
       "1  https://outdoors.stackexchange.com/questions/5347  \n",
       "2  https://outdoors.stackexchange.com/questions/2...  \n",
       "3  https://outdoors.stackexchange.com/questions/1...  \n",
       "4  https://outdoors.stackexchange.com/questions/7623  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions = get_questions()\n",
    "contexts = get_context_dataframe(questions)\n",
    "contexts[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts.to_csv(\"../../data/question-answer-seed-contexts.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 14.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def get_processor_device():\n",
    "    return 0 if torch.cuda.is_available() else -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import tqdm\n",
    "\n",
    "model_name = \"deepset/roberta-base-squad2\"\n",
    "device = get_processor_device()\n",
    "\n",
    "def answer_questions(contexts, k=10):\n",
    "    nlp = pipeline(\"question-answering\", model=model_name,\n",
    "                   tokenizer=model_name, device=device)\n",
    "    guesses = []\n",
    "    for _, row in tqdm.tqdm(contexts[0:k].iterrows(), total=k):\n",
    "        result = nlp({\"question\": row[\"question\"],\n",
    "                      \"context\": row[\"context\"]})\n",
    "        guesses.append(result)\n",
    "    return guesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1663/1663 [08:36<00:00,  3.22it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.278927</td>\n",
       "      <td>474</td>\n",
       "      <td>516</td>\n",
       "      <td>a local enthusiast or group of enthusiasts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.200849</td>\n",
       "      <td>81</td>\n",
       "      <td>117</td>\n",
       "      <td>the person who is creating the climb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.018632</td>\n",
       "      <td>14</td>\n",
       "      <td>24</td>\n",
       "      <td>the victim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000551</td>\n",
       "      <td>1255</td>\n",
       "      <td>1262</td>\n",
       "      <td>aquatic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.222317</td>\n",
       "      <td>29</td>\n",
       "      <td>38</td>\n",
       "      <td>slip knot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.374998</td>\n",
       "      <td>15</td>\n",
       "      <td>40</td>\n",
       "      <td>a high-tech treasure hunt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.050992</td>\n",
       "      <td>52</td>\n",
       "      <td>66</td>\n",
       "      <td>Tree of Heaven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.344535</td>\n",
       "      <td>20</td>\n",
       "      <td>31</td>\n",
       "      <td>Anchor Bend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.110915</td>\n",
       "      <td>125</td>\n",
       "      <td>154</td>\n",
       "      <td>the cheapest one of the three</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.566709</td>\n",
       "      <td>108</td>\n",
       "      <td>135</td>\n",
       "      <td>a hut funded by the village</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      score  start   end                                      answer\n",
       "0  0.278927    474   516  a local enthusiast or group of enthusiasts\n",
       "1  0.200849     81   117        the person who is creating the climb\n",
       "2  0.018632     14    24                                  the victim\n",
       "3  0.000551   1255  1262                                     aquatic\n",
       "4  0.222317     29    38                                   slip knot\n",
       "5  0.374998     15    40                   a high-tech treasure hunt\n",
       "6  0.050992     52    66                              Tree of Heaven\n",
       "7  0.344535     20    31                                 Anchor Bend\n",
       "8  0.110915    125   154               the cheapest one of the three\n",
       "9  0.566709    108   135                 a hut funded by the village"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guesses = answer_questions(contexts, k=len(contexts))\n",
    "contexts[\"answers\"] = guesses\n",
    "pandas.DataFrame(guesses[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts.to_csv(\"../../data/question-answer-squad2-guesses.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 14.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Manually labeling data**\n",
    "*The above csv file (../../data/question-answer-squad2-guesses.csv) is used as a raw first pass at attempting to answer the questions.  This is then used with human-in-the-loop manual correction and labelling of the data.  There is no python code that can do this for you.  The data MUST be labelled by an intelligent person with an understanding of the domain.  All further listings will use the 'golden set' - the manually corrected answer file, and not the guesses that were generated above.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'url', 'title', 'question', 'context', 'answers', '__index_level_0__'],\n",
       "        num_rows: 1242\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'url', 'title', 'question', 'context', 'answers', '__index_level_0__'],\n",
       "        num_rows: 331\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'url', 'title', 'question', 'context', 'answers', '__index_level_0__'],\n",
       "        num_rows: 84\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "random.seed(0)\n",
    "\n",
    "def get_training_data(filename):\n",
    "    golden_answers = pandas.read_csv(filename)\n",
    "    golden_answers = golden_answers[golden_answers[\"class\"] != None]\n",
    "    qa_data = []\n",
    "    for _, row in golden_answers.iterrows():\n",
    "        answers = row[\"gold\"].split(\"|\")\n",
    "        starts = [row[\"context\"].find(a) for a in answers]\n",
    "        missing = -1 in starts\n",
    "        if not missing:\n",
    "            row[\"title\"] = row[\"question\"]\n",
    "            row[\"answers\"] = {\"text\": answers, \"answer_start\": starts}\n",
    "            qa_data.append(row)\n",
    "    columns = [\"id\", \"url\", \"title\", \"question\", \"context\", \"answers\"]\n",
    "    df = pandas.DataFrame(qa_data, columns=columns).sample(frac=1)\n",
    "    train_split = int(len(df) * 0.75)\n",
    "    eval_split = (int((len(df) - train_split) / 1.25) +\n",
    "                  train_split - 1)\n",
    "    train_dataset = Dataset.from_pandas(df[:train_split])\n",
    "    test_dataset = Dataset.from_pandas(df[train_split:eval_split])\n",
    "    validation_dataset = Dataset.from_pandas(df[eval_split:])\n",
    "    return DatasetDict({\"train\": train_dataset, \"test\": test_dataset,\n",
    "                        \"validation\": validation_dataset})\n",
    "\n",
    "#This golden answers file was labeled by me (Max Irwin).\n",
    "#It took about 2-3 hours to label 200 question/answer rows\n",
    "#Doing so will give you a deeper appreciation for the difficulty of the NLP task.\n",
    "#I *highly* encourage you to label even more documents, and re-run the fine-tuning tasks coming up.\n",
    "data = get_training_data(\"../../data/outdoors/outdoors_golden_answers_20210130.csv\")\n",
    "#If you would like to use the cached training data, comment out the following line\n",
    "#data.save_to_disk(\"../../data/question-answering/question-answering-training-set\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up next: [Question Answering LLM Fine-tuning](3.question-answering-fine-tuning.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
