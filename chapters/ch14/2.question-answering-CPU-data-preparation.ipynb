{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Answering Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import html\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import pandas\n",
    "\n",
    "sys.path.append('../..')\n",
    "from aips import *\n",
    "\n",
    "engine = get_engine()\n",
    "outdoors_collection = engine.get_collection(\"outdoors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: This notebook depends upon the Outdoors dataset. If you have any issues, please rerun the [Setting up the Outdoors Dataset](../ch13/1.setting-up-the-outdoors-dataset.ipynb) notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 14.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_questions():\n",
    "    question_types = [\"who\", \"what\", \"when\", \"where\", \"why\", \"how\"]\n",
    "    questions = []\n",
    "    for type in question_types:\n",
    "        request = {\n",
    "            \"query\": type,\n",
    "            \"query_fields\": [\"title\"],\n",
    "            \"return_fields\": [\"id\", \"url\", \"owner_user_id\", \"title\", \"accepted_answer_id\"],\n",
    "            \"filters\": [(\"accepted_answer_id\", \"*\")],\n",
    "            \"limit\": 10000\n",
    "        }\n",
    "        docs = outdoors_collection.search(**request)[\"docs\"]\n",
    "        questions += [d for d in docs\n",
    "                      if d[\"title\"].lower().startswith(type)]  #Only titles starting with a question type\n",
    "    return questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 14.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context_dataframe(questions):\n",
    "    contexts = {\"id\": [], \"question\":[], \"context\":[], \"url\": []}\n",
    "    for question in questions:\n",
    "        print(question)\n",
    "        request = {\"query\": \"*\",\n",
    "                   \"query_fields\": [\"body\"],\n",
    "                   \"filters\": [(\"id\", question[\"accepted_answer_id\"])],\n",
    "                   \"limit\": 1,\n",
    "                   \"order_by\": [(\"score\", \"desc\")]}\n",
    "        docs = outdoors_collection.search(**request)[\"docs\"]\n",
    "        contexts[\"id\"].append(question[\"id\"])\n",
    "        contexts[\"url\"].append(question[\"url\"])\n",
    "        contexts[\"question\"].append(question[\"title\"]),\n",
    "        contexts[\"context\"].append(docs[0][\"body\"])\n",
    "    return pandas.DataFrame(contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/requests/models.py:971\u001b[0m, in \u001b[0;36mResponse.json\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    970\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 971\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcomplexjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    973\u001b[0m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03mcontaining a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m questions \u001b[38;5;241m=\u001b[39m \u001b[43mget_questions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m contexts \u001b[38;5;241m=\u001b[39m get_context_dataframe(questions)\n\u001b[1;32m      3\u001b[0m contexts[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m10\u001b[39m]\n",
      "Cell \u001b[0;32mIn[2], line 12\u001b[0m, in \u001b[0;36mget_questions\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mtype\u001b[39m \u001b[38;5;129;01min\u001b[39;00m question_types:\n\u001b[1;32m      5\u001b[0m     request \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m,\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery_fields\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlimit\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m10000\u001b[39m\n\u001b[1;32m     11\u001b[0m     }\n\u001b[0;32m---> 12\u001b[0m     docs \u001b[38;5;241m=\u001b[39m \u001b[43moutdoors_collection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocs\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     13\u001b[0m     questions \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [d \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m docs\n\u001b[1;32m     14\u001b[0m                   \u001b[38;5;28;01mif\u001b[39;00m d[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;28mtype\u001b[39m)]  \u001b[38;5;66;03m#Only titles starting with a question type\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m questions\n",
      "File \u001b[0;32m~/engines/solr/SolrCollection.py:101\u001b[0m, in \u001b[0;36mSolrCollection.search\u001b[0;34m(self, **search_args)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msearch\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msearch_args):\n\u001b[1;32m    100\u001b[0m     request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform_request(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msearch_args)\n\u001b[0;32m--> 101\u001b[0m     search_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnative_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform_response(search_response)\n",
      "File \u001b[0;32m~/engines/solr/SolrCollection.py:97\u001b[0m, in \u001b[0;36mSolrCollection.native_search\u001b[0;34m(self, request, data)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnative_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, request\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mSOLR_URL\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/select\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/requests/models.py:975\u001b[0m, in \u001b[0;36mResponse.json\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m complexjson\u001b[38;5;241m.\u001b[39mloads(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    972\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    973\u001b[0m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n\u001b[0;32m--> 975\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RequestsJSONDecodeError(e\u001b[38;5;241m.\u001b[39mmsg, e\u001b[38;5;241m.\u001b[39mdoc, e\u001b[38;5;241m.\u001b[39mpos)\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "questions = get_questions()\n",
    "contexts = get_context_dataframe(questions)\n",
    "contexts[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts.to_csv(\"../../data/outdoors/question-answer-seed-contexts.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 14.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def get_processor_device():\n",
    "    return 0 if torch.cuda.is_available() else -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import tqdm\n",
    "\n",
    "model_name = \"deepset/roberta-base-squad2\"\n",
    "pipeline_type = \"question-answering\"\n",
    "\n",
    "device = get_processor_device()\n",
    "\n",
    "def answer_questions(contexts, k=10):\n",
    "    nlp = pipeline(pipeline_type, model=model_name,\n",
    "                   tokenizer=model_name, device=device)\n",
    "    guesses = []\n",
    "    for _, row in tqdm.tqdm(contexts[0:k].iterrows(), total=k):\n",
    "        result = nlp({\"question\": row[\"question\"], \"context\": row[\"context\"]})\n",
    "        guesses.append(result)\n",
    "    return guesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|â–‹         | 105/1663 [00:23<06:10,  4.21it/s]"
     ]
    }
   ],
   "source": [
    "guesses = answer_questions(contexts, k=len(contexts))\n",
    "contexts[\"answers\"] = guesses\n",
    "guesses[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts.to_csv(\"../../data/outdoors/question-answer-squad2-guesses.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 14.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Manually labeling data**\n",
    "*The above csv file (../../data/question-answer-squad2-guesses.csv) is used as a raw first pass at attempting to answer the questions.  This is then used with human-in-the-loop manual correction and labelling of the data.  There is no python code that can do this for you.  The data MUST be labelled by an intelligent person with an understanding of the domain.  All further listings will use the 'golden set' - the manually corrected answer file, and not the guesses that were generated above.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'url', 'title', 'question', 'context', 'answers', '__index_level_0__'],\n",
       "        num_rows: 125\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'url', 'title', 'question', 'context', 'answers', '__index_level_0__'],\n",
       "        num_rows: 32\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'url', 'title', 'question', 'context', 'answers', '__index_level_0__'],\n",
       "        num_rows: 10\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "random.seed(0)\n",
    "\n",
    "def get_training_data(filename):\n",
    "    golden_answers = pandas.read_csv(filename)\n",
    "    golden_answers[\"class\"] = golden_answers[\"class\"].fillna(-2).astype(int)\n",
    "    validated = golden_answers[golden_answers[\"class\"] > -1]    \n",
    "    table = {\"id\": [], \"url\": [], \"title\": [], \"question\": [], \"context\": [], \"answers\": []}\n",
    "    \n",
    "    for _, row in validated.iterrows():\n",
    "        answers = row[\"gold\"].split(\"|\")\n",
    "        starts = []\n",
    "        missing = False\n",
    "        for answer in answers:\n",
    "            result = row[\"context\"].find(answer)\n",
    "            starts.append(result)\n",
    "            if(result < 0):\n",
    "                missing = True\n",
    "        if not missing:\n",
    "            table[\"id\"].append(row[\"id\"])\n",
    "            table[\"url\"].append(row[\"url\"])\n",
    "            table[\"title\"].append(row[\"question\"])\n",
    "            table[\"question\"].append(row[\"question\"])\n",
    "            table[\"context\"].append(row[\"context\"])\n",
    "            table[\"answers\"].append({\"text\": answers, \"answer_start\": starts})\n",
    "            \n",
    "    df = pandas.DataFrame(table).sample(frac=1)\n",
    "    train_split = int(len(df) * 0.75)\n",
    "    eval_split = int((len(df) - train_split) / 1.25) + train_split - 1\n",
    "    train_dataset = Dataset.from_pandas(df[:train_split])\n",
    "    test_dataset = Dataset.from_pandas(df[train_split:eval_split])\n",
    "    validation_dataset = Dataset.from_pandas(df[eval_split:])\n",
    "    return DatasetDict({\"train\": train_dataset, \"test\": test_dataset, \"validation\": validation_dataset})\n",
    "\n",
    "#This golden answers file was labeled by me (Max Irwin).\n",
    "#It took about 2-3 hours to label 200 question/answer rows\n",
    "#Doing so will give you a deeper appreciation for the difficulty of the NLP task.\n",
    "#I *highly* encourage you to label even more documents, and re-run the fine-tuning tasks coming up.\n",
    "data = get_training_data(\"../../data/outdoors/outdoors_golden_answers_20210130.csv\")\n",
    "data.save_to_disk(\"../../data/outdoors/question-answering-training-set\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up next: [Question Answering LLM Fine-tuning](3.question-answering-GPU-fine-tuning.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
