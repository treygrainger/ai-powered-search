{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A/B Testing Simulation to Active Learning\n",
    "\n",
    "In this notebook, users have a hidden preference for a single query. We use this to explore A/B testing to see whether a given LTR model actually gives the users what they want.\n",
    "\n",
    "Then we ask, much like in real life, how can we learn what the user _actually_ wants? We employe active learning to try to escape the 'echo chamber' of presentation bias we learned about at the end of chapter 11. After all users can't click on results that never show up in their search results!\n",
    "\n",
    "## ðŸš¨ We're putting it all together in this chapter\n",
    "\n",
    "As this chapter puts together everything from chapters 10 and 11, much of the setup code below wraps up a lot of chapter 11 and 10 into a 'single function' so we can very easily run through the steps in 'one liners'\n",
    "\n",
    "### Getting training data (Ch 11)\n",
    "\n",
    "Chapter 11 is all about turning raw clickstream data into search training data (aka judgments). This involves overcoming biases in how users percieve search. But here we put that in one function call `calculate_sdbn`.\n",
    "\n",
    "### Train a model (Ch 10)\n",
    "\n",
    "Chapter 10 is about training an LTR model, including the extraction of features from the search engine, how a ranking model works, how to train a model, and how to perform a good test/train split for search. But here we similarly wrap that up into a handful of function calls, `split_training_data`, and `evaluate_model`.\n",
    "\n",
    "*long story short, if you see a reference to chapter 10 and 11, it's probably omited from chapter 12* - don't expect it to be covered in chapter 12 extensively.\n",
    "\n",
    "\n",
    "## Setup - gather some sessions (omitted)\n",
    "\n",
    "To get started, we first load a set of simulated search sessions for all queries. \n",
    "\n",
    "Much of this setup is omitted from the chapter. This first part is just loading and synthesizing a bunch of clickstream sessions, like we used in chapter 11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../..')\n",
    "import glob\n",
    "import time\n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "from aips import *\n",
    "import random; random.seed(0)\n",
    "\n",
    "engine = get_engine()\n",
    "products_collection = engine.get_collection(\"products\")\n",
    "ltr = get_ltr_engine(products_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sess_id</th>\n",
       "      <th>query</th>\n",
       "      <th>rank</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>clicked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50002</td>\n",
       "      <td>blue ray</td>\n",
       "      <td>1.0</td>\n",
       "      <td>827396513927</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50002</td>\n",
       "      <td>blue ray</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24543672067</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50002</td>\n",
       "      <td>blue ray</td>\n",
       "      <td>3.0</td>\n",
       "      <td>719192580374</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50002</td>\n",
       "      <td>blue ray</td>\n",
       "      <td>4.0</td>\n",
       "      <td>885170033412</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50002</td>\n",
       "      <td>blue ray</td>\n",
       "      <td>5.0</td>\n",
       "      <td>58231300826</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74995</th>\n",
       "      <td>5001</td>\n",
       "      <td>transformers dark of the moon</td>\n",
       "      <td>10.0</td>\n",
       "      <td>47875841369</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74996</th>\n",
       "      <td>5001</td>\n",
       "      <td>transformers dark of the moon</td>\n",
       "      <td>11.0</td>\n",
       "      <td>97363560449</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74997</th>\n",
       "      <td>5001</td>\n",
       "      <td>transformers dark of the moon</td>\n",
       "      <td>12.0</td>\n",
       "      <td>93624956037</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74998</th>\n",
       "      <td>5001</td>\n",
       "      <td>transformers dark of the moon</td>\n",
       "      <td>13.0</td>\n",
       "      <td>97363532149</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74999</th>\n",
       "      <td>5001</td>\n",
       "      <td>transformers dark of the moon</td>\n",
       "      <td>14.0</td>\n",
       "      <td>400192926087</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1710000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sess_id                          query  rank        doc_id  clicked\n",
       "1        50002                       blue ray   1.0  827396513927    False\n",
       "2        50002                       blue ray   2.0   24543672067    False\n",
       "3        50002                       blue ray   3.0  719192580374    False\n",
       "4        50002                       blue ray   4.0  885170033412     True\n",
       "5        50002                       blue ray   5.0   58231300826    False\n",
       "...        ...                            ...   ...           ...      ...\n",
       "74995     5001  transformers dark of the moon  10.0   47875841369    False\n",
       "74996     5001  transformers dark of the moon  11.0   97363560449    False\n",
       "74997     5001  transformers dark of the moon  12.0   93624956037    False\n",
       "74998     5001  transformers dark of the moon  13.0   97363532149    False\n",
       "74999     5001  transformers dark of the moon  14.0  400192926087    False\n",
       "\n",
       "[1710000 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signals_upcs_to_omit = [600603132872, 600603125065, 600603141003, 600603139758,\n",
    "                        600603133237, 600603123061, 600603140631, 600603124570,\n",
    "                        600603132827, 600603135101]\n",
    "\n",
    "def all_sessions():\n",
    "    sessions = pandas.concat([pandas.read_csv(f, compression='gzip')\n",
    "                          for f in glob.glob('retrotech/sessions/*_sessions.gz')])\n",
    "    sessions = sessions.sort_values(['query', 'sess_id', 'rank'])\n",
    "    sessions = sessions.rename(columns={'clicked_doc_id': 'doc_id'})\n",
    "    return sessions[~sessions[\"doc_id\"].isin(signals_upcs_to_omit)]\n",
    "    \n",
    "sessions = all_sessions()\n",
    "sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['blue ray', 'bluray', 'dryer', 'headphones', 'ipad', 'iphone',\n",
       "       'kindle', 'lcd tv', 'macbook', 'nook', 'star trek', 'star wars',\n",
       "       'transformers dark of the moon'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sessions[\"query\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Part 2 - Add some more query sessions (omitted)\n",
    "\n",
    "Here we duplicate the simulated queries from above, but we flip a handful of the clicks. This just fills out our data a bit more, gives a bit more data to work with.\n",
    "\n",
    "## Setup Part 3 - Our test query, `transformers dvd`, with hidden, 'true' preferences\n",
    "\n",
    "We add a new query to our set of queries `transformers dvd` and we note the users' hidden preferences in the variables `desired_movies` as well as what they consider mediocre `meh_transformers_movies` and not at all relevant `irrelevant_transformers_products`. Each holds the UPC of the associated product.\n",
    "\n",
    "This simulates biased sessions in the data, as if the user never actually sees (and hence never clicks) their actual desired item. If the users desired results are shown, those results get a higher probability of click. Otherwise there is a lower probability of clicks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        sess_id     query  rank        doc_id  clicked\n",
      "1         50002  blue ray   1.0  827396513927    False\n",
      "2         50002  blue ray   2.0   24543672067    False\n",
      "3         50002  blue ray   3.0  719192580374    False\n",
      "4         50002  blue ray   4.0  885170033412     True\n",
      "5         50002  blue ray   5.0   58231300826    False\n",
      "...         ...       ...   ...           ...      ...\n",
      "149994    55001   blueray  24.0   36725617605    False\n",
      "149995    55001   blueray  25.0   22265004517    False\n",
      "149996    55001   blueray  26.0  885170038875    False\n",
      "149997    55001   blueray  27.0  786936817232    False\n",
      "149999    55001   blueray  29.0   27242815414    False\n",
      "\n",
      "[3085000 rows x 5 columns]\n",
      "Click num 4158\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sess_id</th>\n",
       "      <th>query</th>\n",
       "      <th>rank</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>clicked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50002</td>\n",
       "      <td>blue ray</td>\n",
       "      <td>1.0</td>\n",
       "      <td>827396513927</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50002</td>\n",
       "      <td>blue ray</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24543672067</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50002</td>\n",
       "      <td>blue ray</td>\n",
       "      <td>3.0</td>\n",
       "      <td>719192580374</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50002</td>\n",
       "      <td>blue ray</td>\n",
       "      <td>4.0</td>\n",
       "      <td>885170033412</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50002</td>\n",
       "      <td>blue ray</td>\n",
       "      <td>5.0</td>\n",
       "      <td>58231300826</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79995</th>\n",
       "      <td>65000</td>\n",
       "      <td>transformers dvd</td>\n",
       "      <td>11.0</td>\n",
       "      <td>47875842328</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79996</th>\n",
       "      <td>65000</td>\n",
       "      <td>transformers dvd</td>\n",
       "      <td>12.0</td>\n",
       "      <td>879862003517</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79997</th>\n",
       "      <td>65000</td>\n",
       "      <td>transformers dvd</td>\n",
       "      <td>13.0</td>\n",
       "      <td>97361372389</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79998</th>\n",
       "      <td>65000</td>\n",
       "      <td>transformers dvd</td>\n",
       "      <td>14.0</td>\n",
       "      <td>93624995012</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79999</th>\n",
       "      <td>65000</td>\n",
       "      <td>transformers dvd</td>\n",
       "      <td>15.0</td>\n",
       "      <td>47875839090</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3165000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sess_id             query  rank        doc_id  clicked\n",
       "1        50002          blue ray   1.0  827396513927    False\n",
       "2        50002          blue ray   2.0   24543672067    False\n",
       "3        50002          blue ray   3.0  719192580374    False\n",
       "4        50002          blue ray   4.0  885170033412     True\n",
       "5        50002          blue ray   5.0   58231300826    False\n",
       "...        ...               ...   ...           ...      ...\n",
       "79995    65000  transformers dvd  11.0   47875842328    False\n",
       "79996    65000  transformers dvd  12.0  879862003517    False\n",
       "79997    65000  transformers dvd  13.0   97361372389    False\n",
       "79998    65000  transformers dvd  14.0   93624995012    False\n",
       "79999    65000  transformers dvd  15.0   47875839090    False\n",
       "\n",
       "[3165000 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(0)\n",
    "numpy.random.seed(0)\n",
    "\n",
    "def copy_query_sessions(sessions, src_query, dest_query, flip=False):\n",
    "    new_sessions = sessions[sessions[\"query\"] == src_query].copy()  \n",
    "    new_sessions[\"draw\"] = numpy.random.rand(len(new_sessions), 1)\n",
    "    new_sessions.loc[new_sessions[\"clicked\"] & (new_sessions[\"draw\"] < 0.04), \"clicked\"] = False\n",
    "    new_sessions[\"query\"] = dest_query\n",
    "    return pandas.concat([sessions, new_sessions.drop(\"draw\", axis=1)])\n",
    "\n",
    "sessions = all_sessions()\n",
    "sessions = copy_query_sessions(sessions, \"transformers dark of the moon\", \"transformers dark of moon\")\n",
    "sessions = copy_query_sessions(sessions, \"transformers dark of the moon\", \"dark of moon\")\n",
    "sessions = copy_query_sessions(sessions, \"transformers dark of the moon\", \"dark of the moon\")\n",
    "sessions = copy_query_sessions(sessions, \"headphones\", \"head phones\")\n",
    "sessions = copy_query_sessions(sessions, \"lcd tv\", \"lcd television\")\n",
    "sessions = copy_query_sessions(sessions, \"lcd tv\", \"television, lcd\")\n",
    "sessions = copy_query_sessions(sessions, \"macbook\", \"apple laptop\")\n",
    "sessions = copy_query_sessions(sessions, \"iphone\", \"apple iphone\")\n",
    "sessions = copy_query_sessions(sessions, \"kindle\", \"amazon kindle\")\n",
    "sessions = copy_query_sessions(sessions, \"kindle\", \"amazon ereader\")\n",
    "sessions = copy_query_sessions(sessions, \"blue ray\", \"blueray\")\n",
    "\n",
    "print(sessions)\n",
    "\n",
    "next_sess_id = sessions[\"sess_id\"].max()\n",
    "\n",
    "# For some reason, the sessions only capture examines on the 'dubbed' transformers movies\n",
    "# ie the Japanese shows brought to an English-speaking market. But we'll see this is not what the \n",
    "# user wants (ie presentation bias). These are 'meh' mildly interesting. There are also many many\n",
    "# completely irrelevant movies.\n",
    "\n",
    "# What the user wants, but never visible! Never gets clicked!\n",
    "\n",
    "# These are the widescreen transformers dvds of the hollywood movies\n",
    "desired_transformers_movies = [\"97360724240\", \"97360722345\", \"826663114164\"]\n",
    "# Other transformer movies\n",
    "meh_transformers_movies = [\"97363455349\", \"97361312743\", \"97361372389\",\n",
    "                           \"97361312804\", \"97363532149\", \"97363560449\"]\n",
    "# Bunch of random merchandise\n",
    "irrelevant_transformers_products = [\"708056579739\", \"93624995012\", \"47875819733\", \"47875839090\", \"708056579746\",\n",
    "                                    \"47875332911\", \"47875842328\", \"879862003524\", \"879862003517\", \"93624974918\"] \n",
    "\n",
    "\n",
    "displayed_transformer_products = meh_transformers_movies + irrelevant_transformers_products\n",
    "new_sessions = []\n",
    "click = 0\n",
    "for i in range(0, 5000):\n",
    "    random.shuffle(displayed_transformer_products)\n",
    "\n",
    "    # shuffle each session\n",
    "    for rank, upc in enumerate(displayed_transformer_products):\n",
    "        draw = random.random()        \n",
    "        clicked = ((upc in meh_transformers_movies and draw < 0.13) or\n",
    "                   (upc in irrelevant_transformers_products and draw < 0.005))\n",
    "        click += (1 if clicked else 0)\n",
    "        new_sessions.append({\"sess_id\": next_sess_id + i, \n",
    "                             \"query\": \"transformers dvd\", \n",
    "                             \"rank\": rank,\n",
    "                             \"clicked\": clicked,\n",
    "                             \"doc_id\": upc})\n",
    "\n",
    "print(\"Click num \" + str(click))\n",
    "sessions = pandas.concat([sessions, pandas.DataFrame(new_sessions)])\n",
    "sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['blue ray', 'bluray', 'dryer', 'headphones', 'ipad', 'iphone',\n",
       "       'kindle', 'lcd tv', 'macbook', 'nook', 'star trek', 'star wars',\n",
       "       'transformers dark of the moon', 'transformers dark of moon',\n",
       "       'dark of moon', 'dark of the moon', 'head phones',\n",
       "       'lcd television', 'television, lcd', 'apple laptop',\n",
       "       'apple iphone', 'amazon kindle', 'amazon ereader', 'blueray',\n",
       "       'transformers dvd'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sessions[\"query\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup 4 - chapter 11 In One Function (omitted) \n",
    "\n",
    "Wrapping up Chapter 11 in a single function `generate_training_data`. \n",
    "\n",
    "This function computes a relevance grade out of raw clickstream data. Recall that the SDBN (Simplified Dynamic Bayesian Network) click model we learned about in chapter 11 helps overcome position bias. We also use a beta prior so that a single click doesn't count as much as an observation with hundreds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load -s calculate_ctr,calculate_average_rank,caclulate_examine_probability,calculate_clicked_examined,calculate_grade,calculate_prior,calculate_sdbn ../ltr/sdbn_functions.py\n",
    "def calculate_ctr(sessions):\n",
    "    click_counts = sessions.groupby(\"doc_id\")[\"clicked\"].sum()\n",
    "    sess_counts = sessions.groupby(\"doc_id\")[\"sess_id\"].nunique()\n",
    "    ctrs = click_counts / sess_counts\n",
    "    return ctrs.sort_values(ascending=False)\n",
    "\n",
    "def calculate_average_rank(sessions):\n",
    "    avg_rank = sessions.groupby(\"doc_id\")[\"rank\"].mean()\n",
    "    return avg_rank.sort_values(ascending=True)\n",
    "\n",
    "def caclulate_examine_probability(sessions):\n",
    "    last_click_per_session = sessions.groupby([\"clicked\", \"sess_id\"])[\"rank\"].max()[True]\n",
    "    sessions[\"last_click_rank\"] = last_click_per_session\n",
    "    sessions[\"examined\"] = sessions[\"rank\"] <= sessions[\"last_click_rank\"]\n",
    "    return sessions\n",
    "\n",
    "def calculate_clicked_examined(sessions):\n",
    "    sessions = caclulate_examine_probability(sessions)\n",
    "    return sessions[sessions[\"examined\"]] \\\n",
    "        .groupby(\"doc_id\")[[\"clicked\", \"examined\"]].sum()\n",
    "\n",
    "def calculate_grade(sessions):\n",
    "    sessions = calculate_clicked_examined(sessions)\n",
    "    sessions[\"grade\"] = sessions[\"clicked\"] / sessions[\"examined\"]\n",
    "    return sessions.sort_values(\"grade\", ascending=False)\n",
    "\n",
    "def calculate_prior(sessions, prior_grade, prior_weight):\n",
    "    sessions = calculate_grade(sessions)\n",
    "    sessions[\"prior_a\"] = prior_grade * prior_weight\n",
    "    sessions[\"prior_b\"] = (1 - prior_grade) * prior_weight\n",
    "    return sessions\n",
    "\n",
    "def calculate_sdbn(sessions, prior_grade, prior_weight):\n",
    "    sessions = calculate_prior(sessions, prior_grade, prior_weight)\n",
    "    sessions[\"posterior_a\"] = (sessions[\"prior_a\"] + \n",
    "                               sessions[\"clicked\"])\n",
    "    sessions[\"posterior_b\"] = (sessions[\"prior_b\"] + \n",
    "                               sessions[\"examined\"] - sessions[\"clicked\"])\n",
    "    sessions[\"beta_grade\"] = (sessions[\"posterior_a\"] /\n",
    "      (sessions[\"posterior_a\"] + sessions[\"posterior_b\"]))\n",
    "    return sessions.sort_values(\"beta_grade\", ascending=False)\n",
    "\n",
    "def generate_training_data(sessions, prior_grade=0.2, prior_weight=10):\n",
    "    all_sdbn = pandas.DataFrame()\n",
    "    for query in sessions[\"query\"].unique():        \n",
    "        query_sessions = sessions[sessions[\"query\"] == query].copy().set_index(\"sess_id\")\n",
    "        query_sessions = calculate_sdbn(query_sessions, prior_grade, prior_weight)\n",
    "        query_sessions[\"query\"] = query\n",
    "        all_sdbn = pandas.concat([all_sdbn, query_sessions])\n",
    "    return all_sdbn[[\"query\", \"clicked\", \"examined\", \"grade\", \"beta_grade\"]].reset_index().set_index([\"query\", \"doc_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 10 Functions (omitted from book)\n",
    "\n",
    "Now with the chapter 11 setup out of the way, we'll need to give Chapter 10's code a similar treatment, wrapping that LTR system into a black box.\n",
    "\n",
    "All of the following are support functions for the chapter:\n",
    "\n",
    "1. Convert the sdbn dataframe into individual `Judgment` objects needed for training the model from chapter 10\n",
    "2. Pairwise transformation of the data\n",
    "3. Normalization of the data\n",
    "4. Training the model\n",
    "5. Uploading the model to Solr\n",
    "\n",
    "All of these steps are covered in Chapter 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy\n",
    "from ltr.judgments import judgments_to_nparray\n",
    "from sklearn import svm\n",
    "import json\n",
    "from itertools import groupby\n",
    "from ltr.log import FeatureLogger\n",
    "from itertools import groupby\n",
    "from ltr.judgments import judgments_writer\n",
    "\n",
    "from ltr.judgments import Judgment\n",
    "\n",
    "def as_judgments(training_data):\n",
    "    \"\"\"Turn pandas dataframe into ltr judgments objects.\"\"\"        \n",
    "    qid_map = {}\n",
    "    judgments = []\n",
    "    next_qid = 0\n",
    "    for datum in training_data.reset_index().to_dict(orient=\"records\"):       \n",
    "        if datum[\"query\"] not in qid_map:\n",
    "            qid_map[datum[\"query\"]] = next_qid\n",
    "            next_qid += 1\n",
    "        qid = qid_map[datum[\"query\"]]\n",
    "\n",
    "        judgments.append(Judgment(doc_id=datum[\"doc_id\"],\n",
    "                        keywords=datum[\"query\"],\n",
    "                        qid=qid,\n",
    "                        grade=datum[\"beta_grade\"]))\n",
    "        \n",
    "    return judgments\n",
    "\n",
    "def normalize_features(logged_judgments):\n",
    "    num_features = len(logged_judgments[0].features)\n",
    "    means = [numpy.mean([j.features[i] for j in logged_judgments])\n",
    "             for i in range(0, num_features)]    \n",
    "    \n",
    "    std_devs = [numpy.std([j.features[i] for j in logged_judgments])\n",
    "                for i in range(0, num_features)]\n",
    "    \n",
    "    normed_judgments = copy.deepcopy(logged_judgments)\n",
    "    for j in normed_judgments:\n",
    "        for i, score in enumerate(j.features):\n",
    "            j.features[i] = (score - means[i]) / std_devs[i]\n",
    "\n",
    "    return means, std_devs, normed_judgments\n",
    "\n",
    "def pairwise_transform(normed_judgments):        \n",
    "    predictor_deltas = []\n",
    "    feature_deltas = []\n",
    "    for qid, grouped_judgments in groupby(normed_judgments, key=lambda j: j.qid):\n",
    "        query_judgments = list(grouped_judgments)\n",
    "        for judgment1 in query_judgments:\n",
    "            for judgment2 in query_judgments:\n",
    "                j1_features = numpy.array(judgment1.features)\n",
    "                j2_features = numpy.array(judgment2.features)\n",
    "                \n",
    "                if judgment1.grade > judgment2.grade:\n",
    "                    predictor_deltas.append(1)\n",
    "                    feature_deltas.append(j1_features - j2_features)\n",
    "                elif judgment1.grade < judgment2.grade:\n",
    "                    predictor_deltas.append(-1)\n",
    "                    feature_deltas.append(j1_features - j2_features)\n",
    "\n",
    "    return numpy.array(feature_deltas), numpy.array(predictor_deltas)\n",
    "\n",
    "def write_judgments(judgments, dest=\"retrotech_judgments.txt\"):\n",
    "    with judgments_writer(open(dest, \"wt\")) as writer:\n",
    "        for judgment in judgments:\n",
    "            writer.write(judgment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Also Chapter 10 - Perform a test / train split on the SDBN data (omitted)\n",
    "\n",
    "This function is broken out from the model training. It lets us train a model on one set of data (reusing the chapter 10 training code), reserving test queries for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import floor\n",
    "\n",
    "def split_training_data(training_data, train_proportion=0.8):\n",
    "    \"\"\"Split queries in training_data into train / test split with `train` proportion going to training set.\"\"\"\n",
    "    queries = training_data.index.get_level_values('query').unique().copy().tolist()\n",
    "    random.shuffle(queries)\n",
    "    num_queries = len(queries)\n",
    "    split_point = floor(num_queries * train_proportion)\n",
    "    \n",
    "    train_queries = queries[:split_point]\n",
    "    test_queries = queries[split_point:]\n",
    "    return training_data.loc[train_queries, :], training_data.loc[test_queries]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 10 - Evaluate the model on the test set (omitted)\n",
    "\n",
    "This function computes the model's performance on a set of test queries. The `test_data` is the control set not used to train the model. We compute the precision of these queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svm_model(model_name, features, logged_judgments):\n",
    "    means, std_devs, normed_judgments = normalize_features(logged_judgments)\n",
    "    feature_deltas, predictor_deltas = pairwise_transform(normed_judgments)\n",
    "\n",
    "    model = svm.LinearSVC(max_iter=10000, verbose=1)\n",
    "    model.fit(feature_deltas, predictor_deltas) \n",
    "\n",
    "    feature_names = [ftr[\"name\"] for ftr in features]\n",
    "    linear_model = ltr.generate_model(model_name, feature_names,\n",
    "                                      means, std_devs, model.coef_[0])\n",
    "\n",
    "    return linear_model\n",
    "\n",
    "def train_and_upload_model(training_data, model_name, features, log=False):\n",
    "    \"\"\"Train a RankSVM model with features from the search engine and upload the model.\"\"\"\n",
    "    judgments = as_judgments(training_data)\n",
    "    ltr.delete_feature_store(model_name, log=log)\n",
    "    ltr.delete_model(model_name)\n",
    "    ltr.upload_features(features, model_name, log=log)\n",
    "    ftr_logger = FeatureLogger(engine, products_collection, feature_set=model_name,\n",
    "                               id_field=\"upc\")\n",
    "            \n",
    "    for qid, query_judgments in groupby(judgments, key=lambda j: j.qid):\n",
    "        ftr_logger.log_for_qid(judgments=query_judgments, \n",
    "                               qid=qid, log=False)\n",
    "\n",
    "    linear_model = train_svm_model(model_name, features, ftr_logger.logged)\n",
    "    ltr.upload_model(linear_model, log=log)\n",
    "    return linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(test_data, model_name, training_data, limit=10, log=False):\n",
    "    queries = test_data.index.get_level_values(\"query\").unique()\n",
    "    query_results = {}\n",
    "    \n",
    "    for query in queries:\n",
    "        response = ltr.search_with_model(model_name, query=query,\n",
    "                                         limit=limit, rerank_query=query, log=False)\n",
    "    \n",
    "        results = pandas.DataFrame(response[\"docs\"]).reset_index()\n",
    "        judgments = training_data.loc[query, :].copy().reset_index()\n",
    "        judgments[\"doc_id\"] = judgments[\"doc_id\"].astype(str)\n",
    "        if len(results) == 0:\n",
    "            print(f\"No Results for {query}\")\n",
    "            query_results[query] = 0\n",
    "        else:\n",
    "            graded_results = results.merge(judgments, left_on=\"upc\",\n",
    "                                           right_on=\"doc_id\", how=\"left\")\n",
    "            graded_results[[\"clicked\", \"examined\", \"grade\", \"beta_grade\"]] = graded_results[[\"clicked\", \"examined\", \"grade\", \"beta_grade\"]].fillna(0)\n",
    "            graded_results = graded_results.drop(\"doc_id\", axis=1)\n",
    "            if log:\n",
    "                print(graded_results.drop([\"index\", \"rank\", \"manufacturer\", \"short_description\",\n",
    "                                           \"long_description\", \"grade\", \"name\"], axis=1))\n",
    "\n",
    "            query_results[query] = float(graded_results[\"beta_grade\"].sum() / limit)\n",
    "    return query_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 12.1 Generating the sdbn training data\n",
    "\n",
    "We kickoff with the data we left off with in chapter 11.\n",
    "\n",
    "In this listing we user our \"chapter 11 in one function\" `generate_training_data` to rebuild training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>clicked</th>\n",
       "      <th>examined</th>\n",
       "      <th>grade</th>\n",
       "      <th>beta_grade</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>query</th>\n",
       "      <th>doc_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">blue ray</th>\n",
       "      <th>27242815414</th>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.846154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827396513927</th>\n",
       "      <td>1304</td>\n",
       "      <td>3359</td>\n",
       "      <td>0.388211</td>\n",
       "      <td>0.387652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883929140855</th>\n",
       "      <td>140</td>\n",
       "      <td>506</td>\n",
       "      <td>0.276680</td>\n",
       "      <td>0.275194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885170033412</th>\n",
       "      <td>568</td>\n",
       "      <td>2147</td>\n",
       "      <td>0.264555</td>\n",
       "      <td>0.264256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24543672067</th>\n",
       "      <td>665</td>\n",
       "      <td>2763</td>\n",
       "      <td>0.240680</td>\n",
       "      <td>0.240534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">transformers dvd</th>\n",
       "      <th>47875819733</th>\n",
       "      <td>24</td>\n",
       "      <td>1679</td>\n",
       "      <td>0.014294</td>\n",
       "      <td>0.015394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708056579739</th>\n",
       "      <td>23</td>\n",
       "      <td>1659</td>\n",
       "      <td>0.013864</td>\n",
       "      <td>0.014979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879862003524</th>\n",
       "      <td>23</td>\n",
       "      <td>1685</td>\n",
       "      <td>0.013650</td>\n",
       "      <td>0.014749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93624974918</th>\n",
       "      <td>19</td>\n",
       "      <td>1653</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0.012628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47875839090</th>\n",
       "      <td>16</td>\n",
       "      <td>1669</td>\n",
       "      <td>0.009587</td>\n",
       "      <td>0.010721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>626 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               clicked  examined     grade  beta_grade\n",
       "query            doc_id                                               \n",
       "blue ray         27242815414        42        42  1.000000    0.846154\n",
       "                 827396513927     1304      3359  0.388211    0.387652\n",
       "                 883929140855      140       506  0.276680    0.275194\n",
       "                 885170033412      568      2147  0.264555    0.264256\n",
       "                 24543672067       665      2763  0.240680    0.240534\n",
       "...                                ...       ...       ...         ...\n",
       "transformers dvd 47875819733        24      1679  0.014294    0.015394\n",
       "                 708056579739       23      1659  0.013864    0.014979\n",
       "                 879862003524       23      1685  0.013650    0.014749\n",
       "                 93624974918        19      1653  0.011494    0.012628\n",
       "                 47875839090        16      1669  0.009587    0.010721\n",
       "\n",
       "[626 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_data = generate_training_data(sessions,\n",
    "                                       prior_weight=10,\n",
    "                                       prior_grade=0.2)\n",
    "\n",
    "display(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 12.2 - model training\n",
    "\n",
    "We wrap all the important decisions from chapter 10 in a few lines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(sessions, model_name, features, log=False):\n",
    "    training_data = generate_training_data(sessions)\n",
    "    train, test = split_training_data(training_data, 0.8)\n",
    "    train_and_upload_model(train, model_name, features=features, log=False)\n",
    "    evaluation = evaluate_model(test, model_name, training_data, log=log)\n",
    "    return evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'dryer': 0.03753076750950996,\n",
       " 'blue ray': 0.0,\n",
       " 'headphones': 0.0846717500031762,\n",
       " 'dark of moon': 0.0,\n",
       " 'transformers dvd': 0.0}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random.seed(1234)\n",
    "feature_set = [\n",
    "    ltr.generate_query_feature(feature_name=\"long_description_bm25\",\n",
    "                               field_name=\"long_description\"),\n",
    "    ltr.generate_query_feature(feature_name=\"short_description_constant\",\n",
    "                               field_name=\"short_description\",\n",
    "                               constant_score=True)]\n",
    "\n",
    "evaluation = train_and_evaluate_model(sessions, \"ltr_model_variant_1\", feature_set)\n",
    "display(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'long_description_bm25',\n",
       "  'class': 'org.apache.solr.ltr.feature.SolrFeature',\n",
       "  'params': {'q': 'long_description:(${keywords})'},\n",
       "  'store': 'ltr_model_variant_1'},\n",
       " {'name': 'short_description_constant',\n",
       "  'class': 'org.apache.solr.ltr.feature.SolrFeature',\n",
       "  'params': {'q': 'short_description:(${keywords})^=1'},\n",
       "  'store': 'ltr_model_variant_1'}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(feature_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 12.3\n",
    "\n",
    "Train a model that hypothetically performs better offline called `ltr_model_variant_2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'dryer': 0.07068309073137659,\n",
       " 'blue ray': 0.0,\n",
       " 'headphones': 0.06540945492120899,\n",
       " 'dark of moon': 0.257659200402958,\n",
       " 'transformers dvd': 0.10077083021678328}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random.seed(1234)\n",
    "td = generate_training_data(sessions).reset_index().set_index(\"query\")\n",
    "#print(td.loc[\"headphones\"])\n",
    "\n",
    "feature_set = [\n",
    "    ltr.generate_fuzzy_query_feature(feature_name=\"name_fuzzy\", \n",
    "                                     field_name=\"name\"),\n",
    "    ltr.generate_bigram_query_feature(feature_name=\"name_bigram\",\n",
    "                                      field_name=\"name\"),\n",
    "    ltr.generate_bigram_query_feature(feature_name=\"short_description_bigram\",\n",
    "                                      field_name=\"short_description\")\n",
    "]\n",
    "\n",
    "evaluation = train_and_evaluate_model(sessions, \"ltr_model_variant_2\", feature_set)\n",
    "display(evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate a user querying, clicking, purchasing (omitted)\n",
    "\n",
    "This function simulates a user performing a query and possibly taking an action as they scan down the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_live_user_session(query, model_name,\n",
    "                               desired_probability=0.15,\n",
    "                               indifferent_probability=0.03,\n",
    "                               uninterested_probability=0.01,\n",
    "                               quit_per_result_probability=0.2):\n",
    "    \"\"\"Simulates a user 'query' where purchase probability depends on if \n",
    "       products upc is in one of three sets.\n",
    "       \n",
    "       Users purchase a single product per session.    \n",
    "       \n",
    "       Users quit with `quit_per_result_probability` after scanning each rank\n",
    "       \n",
    "       \"\"\"   \n",
    "    desired_products = [\"97360724240\", \"97360722345\", \"826663114164\"]\n",
    "    indifferent_products = [\"97363455349\", \"97361312743\", \"97361372389\",\n",
    "                            \"97361312804\", \"97363532149\", \"97363560449\"]\n",
    "    \n",
    "    response = ltr.search_with_model(model_name, query=query, rerank_query=query, limit=10)\n",
    "\n",
    "    results = pandas.DataFrame(response[\"docs\"]).reset_index()\n",
    "    for doc in results.to_dict(orient=\"records\"): \n",
    "        draw = random.random()\n",
    "        \n",
    "        if doc[\"upc\"] in desired_products:\n",
    "            if draw < desired_probability:\n",
    "                return True\n",
    "        elif doc[\"upc\"] in indifferent_products:\n",
    "            if draw < indifferent_probability:\n",
    "                return True\n",
    "        elif draw < uninterested_probability:\n",
    "            return True\n",
    "        if random.random() < quit_per_result_probability:\n",
    "            return False\n",
    "        \n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 12.4 - Simulated A/B test on just `transformers dvd` query\n",
    "\n",
    "Here we simulate 1000 users being served two rankings for `transformers dvd` and based on the hidden preferences here (`wants_to_purchase` and `might_purchase`) we see which performs better with conversions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def a_b_test(query, model_a, model_b):\n",
    "    \"\"\"Randomly assign this user to a or b\"\"\"\n",
    "    draw = random.random()\n",
    "    model_name = model_a if draw < 0.5 else model_b    \n",
    "    purchase_made = simulate_live_user_session(query, model_name)\n",
    "    return (model_name, purchase_made)\n",
    "\n",
    "def simulate_user_a_b_test(query, model_a, model_b, number_of_users=1000):\n",
    "    purchases = {model_a: 0, model_b: 0}\n",
    "    for _ in range(number_of_users): \n",
    "        model_name, purchase_made = a_b_test(query, model_a, model_b)\n",
    "        if purchase_made:\n",
    "            purchases[model_name] += 1\n",
    "    return purchases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Takes 6 minutes now, used to be quicker\u001b[39;00m\n\u001b[1;32m      2\u001b[0m random\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m1234\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43msimulate_user_a_b_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtransformers dvd\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mmodel_a\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mltr_model_variant_1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mmodel_b\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mltr_model_variant_2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mnumber_of_users\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m display(results)\n",
      "Cell \u001b[0;32mIn[17], line 11\u001b[0m, in \u001b[0;36msimulate_user_a_b_test\u001b[0;34m(query, model_a, model_b, number_of_users)\u001b[0m\n\u001b[1;32m      9\u001b[0m purchases \u001b[38;5;241m=\u001b[39m {model_a: \u001b[38;5;241m0\u001b[39m, model_b: \u001b[38;5;241m0\u001b[39m}\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(number_of_users): \n\u001b[0;32m---> 11\u001b[0m     model_name, purchase_made \u001b[38;5;241m=\u001b[39m \u001b[43ma_b_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_b\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m purchase_made:\n\u001b[1;32m     13\u001b[0m         purchases[model_name] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[0;32mIn[17], line 5\u001b[0m, in \u001b[0;36ma_b_test\u001b[0;34m(query, model_a, model_b)\u001b[0m\n\u001b[1;32m      3\u001b[0m draw \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mrandom()\n\u001b[1;32m      4\u001b[0m model_name \u001b[38;5;241m=\u001b[39m model_a \u001b[38;5;28;01mif\u001b[39;00m draw \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m model_b    \n\u001b[0;32m----> 5\u001b[0m purchase_made \u001b[38;5;241m=\u001b[39m \u001b[43msimulate_live_user_session\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (model_name, purchase_made)\n",
      "Cell \u001b[0;32mIn[16], line 18\u001b[0m, in \u001b[0;36msimulate_live_user_session\u001b[0;34m(query, model_name, desired_probability, indifferent_probability, uninterested_probability, quit_per_result_probability)\u001b[0m\n\u001b[1;32m     14\u001b[0m desired_products \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m97360724240\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m97360722345\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m826663114164\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     15\u001b[0m indifferent_products \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m97363455349\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m97361312743\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m97361372389\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     16\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m97361312804\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m97363532149\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m97363560449\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 18\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mltr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_with_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrerank_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m results \u001b[38;5;241m=\u001b[39m pandas\u001b[38;5;241m.\u001b[39mDataFrame(response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocs\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mto_dict(orient\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecords\u001b[39m\u001b[38;5;124m\"\u001b[39m): \n",
      "File \u001b[0;32m~/engines/solr/SolrLTR.py:167\u001b[0m, in \u001b[0;36mSolrLTR.search_with_model\u001b[0;34m(self, model_name, **search_args)\u001b[0m\n\u001b[1;32m    164\u001b[0m     request[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrq\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m rq\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m log: \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msearch_with_model() request: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrequest\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 167\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnative_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m            \n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m log: \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msearch_with_model() response: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    170\u001b[0m docs \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocs\u001b[39m\u001b[38;5;124m\"\u001b[39m]    \n",
      "File \u001b[0;32m~/engines/solr/SolrCollection.py:132\u001b[0m, in \u001b[0;36mSolrCollection.native_search\u001b[0;34m(self, request, data)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnative_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, request\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 132\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mSOLR_URL\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/select\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/requests/api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n\u001b[1;32m    717\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py:449\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    444\u001b[0m             httplib_response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m    445\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m             \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m             \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m             \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m             \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py:444\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;66;03m# Python 3\u001b[39;00m\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 444\u001b[0m         httplib_response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m         \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m         \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m         \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m         six\u001b[38;5;241m.\u001b[39mraise_from(e, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/http/client.py:1374\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1372\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1373\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1374\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1375\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1376\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Takes 6 minutes now, used to be quicker\n",
    "random.seed(1234)\n",
    "\n",
    "results = simulate_user_a_b_test(query=\"transformers dvd\",\n",
    "                                 model_a=\"ltr_model_variant_1\",\n",
    "                                 model_b=\"ltr_model_variant_2\",\n",
    "                                 number_of_users=1000)\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New helper: show the features for each SDBN entry (omitted)\n",
    "\n",
    "This function shows us the logged features of each training row for the given sdbn data for debugging.\n",
    "\n",
    "So not just\n",
    "\n",
    "| query   | doc      | grade\n",
    "|---------|----------|---------\n",
    "|transformers dvd | 1234 | 1.0\n",
    "\n",
    "But also a recording of the matches that occured\n",
    "\n",
    "| query           | doc      | grade    | short_desc_match  | long_desc_match |...\n",
    "|-----------------|----------|----------|-------------------|-----------------|---\n",
    "|transformers dvd | 1234     | 1.0      | 0.0               | 1.0             |..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_logged_judgments(training_data, features, model_name):\n",
    "    \"\"\"Log features alongside training_data into a dataframe\"\"\"\n",
    "    judgments = as_judgments(training_data)\n",
    "    ltr.delete_feature_store(model_name)\n",
    "    ltr.upload_features(features, model_name)\n",
    "\n",
    "    ftr_logger = FeatureLogger(engine, index=products_collection,\n",
    "                               feature_set=model_name, id_field=\"upc\")\n",
    "\n",
    "    for qid, query_judgments in groupby(judgments, key=lambda j: j.qid):\n",
    "        ftr_logger.log_for_qid(judgments=query_judgments,\n",
    "                               qid=qid, log=False)\n",
    "        \n",
    "    logged_judgments = ftr_logger.logged\n",
    "    feature_data, predictors, doc_ids = judgments_to_nparray(logged_judgments)\n",
    "    logged_judgments_dataframe = pandas.concat([pandas.DataFrame(predictors),\n",
    "                                                pandas.DataFrame(feature_data),\n",
    "                                                pandas.DataFrame(doc_ids)], \n",
    "                                                axis=1,\n",
    "                                                ignore_index=True)\n",
    "    \n",
    "    qid_map = {j.qid: j.keywords for j in logged_judgments}\n",
    "    qid_map = pandas.DataFrame(qid_map.values()).reset_index() \\\n",
    "                         .rename(columns={\"index\": \"qid\", 0: \"query\"})\n",
    "    \n",
    "    feature_names = [f[\"name\"] for f in features]\n",
    "    columns = {i: name for i, name in enumerate([\"grade\", \"qid\"] + feature_names + [\"doc_id\"])}\n",
    "\n",
    "    logged_judgments_dataframe = logged_judgments_dataframe.rename(columns=columns)\n",
    "    logged_judgments_dataframe = logged_judgments_dataframe.merge(qid_map, how=\"left\", on=\"qid\")\n",
    "    ordered_columns = [\"doc_id\", \"query\", \"grade\"] + feature_names\n",
    "    #logged_judgments_dataframe['grade'] = logged_judgments_dataframe['grade'] / 10.0 \n",
    "    \n",
    "    return logged_judgments_dataframe[ordered_columns].set_index(\"doc_id\").sort_values(\"grade\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 12.5 - Output matches for one feature set\n",
    "\n",
    "Another way of formulating `presentation_bias` is to look at the kinds of documents not being shown to users, so we can strategically show those to users. Below we show the value of each feature in `explore_feature_set` for each document in the sdbn judgments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_explore_features():\n",
    "    return [\n",
    "        ltr.generate_query_feature(feature_name=\"long_description_match\",\n",
    "                                   field_name=\"long_description\",\n",
    "                                   constant_score=True),\n",
    "        ltr.generate_query_feature(feature_name=\"short_description_match\",\n",
    "                                   field_name=\"short_description\",\n",
    "                                   constant_score=True),\n",
    "        ltr.generate_query_feature(feature_name=\"name_match\",\n",
    "                                   field_name=\"name\",\n",
    "                                   constant_score=True),\n",
    "        ltr.generate_query_feature(feature_name=\"has_promotion\",\n",
    "                                   field_name=\"has_promotion\",\n",
    "                                   value=\"true\",\n",
    "                                   constant_score=True)]\n",
    "\n",
    "def get_logged_transformers_judgments(sessions, features):\n",
    "    training_data = generate_training_data(sessions)\n",
    "    logged_judgments = generate_logged_judgments(training_data,\n",
    "                                                 features, \"explore\")\n",
    "    logged_judgments = logged_judgments \\\n",
    "        [logged_judgments[\"query\"] == \"transformers dvd\"]\n",
    "    return logged_judgments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>grade</th>\n",
       "      <th>long_description_match</th>\n",
       "      <th>short_description_match</th>\n",
       "      <th>name_match</th>\n",
       "      <th>has_promotion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>97363560449</th>\n",
       "      <td>transformers dvd</td>\n",
       "      <td>0.347137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97361312804</th>\n",
       "      <td>transformers dvd</td>\n",
       "      <td>0.344041</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97361312743</th>\n",
       "      <td>transformers dvd</td>\n",
       "      <td>0.342160</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97363455349</th>\n",
       "      <td>transformers dvd</td>\n",
       "      <td>0.342065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97361372389</th>\n",
       "      <td>transformers dvd</td>\n",
       "      <td>0.323484</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97363532149</th>\n",
       "      <td>transformers dvd</td>\n",
       "      <td>0.322664</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879862003517</th>\n",
       "      <td>transformers dvd</td>\n",
       "      <td>0.022834</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93624995012</th>\n",
       "      <td>transformers dvd</td>\n",
       "      <td>0.020202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47875842328</th>\n",
       "      <td>transformers dvd</td>\n",
       "      <td>0.018530</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708056579746</th>\n",
       "      <td>transformers dvd</td>\n",
       "      <td>0.016726</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47875332911</th>\n",
       "      <td>transformers dvd</td>\n",
       "      <td>0.015854</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47875819733</th>\n",
       "      <td>transformers dvd</td>\n",
       "      <td>0.015394</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708056579739</th>\n",
       "      <td>transformers dvd</td>\n",
       "      <td>0.014979</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879862003524</th>\n",
       "      <td>transformers dvd</td>\n",
       "      <td>0.014749</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93624974918</th>\n",
       "      <td>transformers dvd</td>\n",
       "      <td>0.012628</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47875839090</th>\n",
       "      <td>transformers dvd</td>\n",
       "      <td>0.010721</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         query     grade  long_description_match  \\\n",
       "doc_id                                                             \n",
       "97363560449   transformers dvd  0.347137                     0.0   \n",
       "97361312804   transformers dvd  0.344041                     0.0   \n",
       "97361312743   transformers dvd  0.342160                     0.0   \n",
       "97363455349   transformers dvd  0.342065                     0.0   \n",
       "97361372389   transformers dvd  0.323484                     0.0   \n",
       "97363532149   transformers dvd  0.322664                     0.0   \n",
       "879862003517  transformers dvd  0.022834                     0.0   \n",
       "93624995012   transformers dvd  0.020202                     0.0   \n",
       "47875842328   transformers dvd  0.018530                     1.0   \n",
       "708056579746  transformers dvd  0.016726                     1.0   \n",
       "47875332911   transformers dvd  0.015854                     1.0   \n",
       "47875819733   transformers dvd  0.015394                     1.0   \n",
       "708056579739  transformers dvd  0.014979                     1.0   \n",
       "879862003524  transformers dvd  0.014749                     1.0   \n",
       "93624974918   transformers dvd  0.012628                     0.0   \n",
       "47875839090   transformers dvd  0.010721                     1.0   \n",
       "\n",
       "              short_description_match  name_match  has_promotion  \n",
       "doc_id                                                            \n",
       "97363560449                       0.0         1.0            0.0  \n",
       "97361312804                       0.0         1.0            0.0  \n",
       "97361312743                       0.0         1.0            0.0  \n",
       "97363455349                       0.0         1.0            0.0  \n",
       "97361372389                       0.0         1.0            0.0  \n",
       "97363532149                       0.0         1.0            0.0  \n",
       "879862003517                      1.0         1.0            0.0  \n",
       "93624995012                       0.0         1.0            0.0  \n",
       "47875842328                       0.0         1.0            1.0  \n",
       "708056579746                      0.0         1.0            0.0  \n",
       "47875332911                       0.0         1.0            0.0  \n",
       "47875819733                       0.0         1.0            0.0  \n",
       "708056579739                      1.0         1.0            0.0  \n",
       "879862003524                      1.0         1.0            0.0  \n",
       "93624974918                       0.0         1.0            0.0  \n",
       "47875839090                       0.0         1.0            0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "explore_features = get_latest_explore_features()\n",
    "logged_transformers_judgments = get_logged_transformers_judgments(sessions,\n",
    "                                                                  explore_features)\n",
    "display(logged_transformers_judgments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 12.6 - Train Gaussian Process Regressor\n",
    "\n",
    "We train data on just the `transformers_training_data`. \n",
    "\n",
    "NOTE we could also train on the full sdbn training data, and see globally what's missing. However it's often convenient to zero in on specific queries to round out their training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "\n",
    "def train_gpr(logged_judgments, feature_names):\n",
    "    feature_data = logged_judgments[feature_names]\n",
    "    grades = logged_judgments[\"grade\"]\n",
    "    gpr = GaussianProcessRegressor()\n",
    "    gpr.fit(feature_data, grades)\n",
    "    return gpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianProcessRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GaussianProcessRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.gaussian_process.GaussianProcessRegressor.html\">?<span>Documentation for GaussianProcessRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GaussianProcessRegressor()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "GaussianProcessRegressor()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = [f[\"name\"] for f in explore_features]\n",
    "train_gpr(logged_transformers_judgments, feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 12.7: Predict on every value\n",
    "\n",
    "Here `gpr` predicts on every possible feature value. This lets us analyze which set of feature values to use when exploring with users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_prediction_data(logged_judgments, feature_names):\n",
    "    index = pandas.MultiIndex.from_product([[0, 1]] * 4,\n",
    "                                           names=feature_names)\n",
    "    with_prediction = pandas.DataFrame(index=index).reset_index()\n",
    "\n",
    "    gpr = train_gpr(logged_judgments, feature_names)\n",
    "    predictions_with_std = gpr.predict(\n",
    "        with_prediction[feature_names], return_std=True)\n",
    "    with_prediction[\"predicted_grade\"] = predictions_with_std[0]\n",
    "    with_prediction[\"predicted_stddev\"] = predictions_with_std[1]\n",
    "   \n",
    "    return  with_prediction.sort_values(\"predicted_stddev\", ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>long_description_match</th>\n",
       "      <th>short_description_match</th>\n",
       "      <th>name_match</th>\n",
       "      <th>has_promotion</th>\n",
       "      <th>predicted_grade</th>\n",
       "      <th>predicted_stddev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.256798</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014674</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014864</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.022834</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.018530</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.161596</td>\n",
       "      <td>0.632121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.014856</td>\n",
       "      <td>0.632121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.017392</td>\n",
       "      <td>0.739305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.155756</td>\n",
       "      <td>0.795060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008900</td>\n",
       "      <td>0.795060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.009016</td>\n",
       "      <td>0.795060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.013849</td>\n",
       "      <td>0.795060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.011239</td>\n",
       "      <td>0.795060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.098013</td>\n",
       "      <td>0.882676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009011</td>\n",
       "      <td>0.882676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010549</td>\n",
       "      <td>0.912794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    long_description_match  short_description_match  name_match  \\\n",
       "2                        0                        0           1   \n",
       "10                       1                        0           1   \n",
       "14                       1                        1           1   \n",
       "6                        0                        1           1   \n",
       "11                       1                        0           1   \n",
       "3                        0                        0           1   \n",
       "15                       1                        1           1   \n",
       "7                        0                        1           1   \n",
       "0                        0                        0           0   \n",
       "8                        1                        0           0   \n",
       "12                       1                        1           0   \n",
       "4                        0                        1           0   \n",
       "9                        1                        0           0   \n",
       "1                        0                        0           0   \n",
       "13                       1                        1           0   \n",
       "5                        0                        1           0   \n",
       "\n",
       "    has_promotion  predicted_grade  predicted_stddev  \n",
       "2               0         0.256798          0.000004  \n",
       "10              0         0.014674          0.000005  \n",
       "14              0         0.014864          0.000007  \n",
       "6               0         0.022834          0.000010  \n",
       "11              1         0.018530          0.000010  \n",
       "3               1         0.161596          0.632121  \n",
       "15              1         0.014856          0.632121  \n",
       "7               1         0.017392          0.739305  \n",
       "0               0         0.155756          0.795060  \n",
       "8               0         0.008900          0.795060  \n",
       "12              0         0.009016          0.795060  \n",
       "4               0         0.013849          0.795060  \n",
       "9               1         0.011239          0.795060  \n",
       "1               1         0.098013          0.882676  \n",
       "13              1         0.009011          0.882676  \n",
       "5               1         0.010549          0.912794  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prediction_data = calculate_prediction_data(logged_transformers_judgments,\n",
    "                                                            feature_names)\n",
    "display(prediction_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 12.8 - Calculate Expected Improvement\n",
    "\n",
    "\n",
    "We use [Expected Improvement](https://distill.pub/2020/bayesian-optimization/) scoring to select candidates for exploration within the `transformers dvd` query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "def calculate_expected_improvement(logged_judgments, feature_names, theta=0.6):\n",
    "    data = calculate_prediction_data(logged_judgments, feature_names)\n",
    "    data[\"opportunity\"] = (data[\"predicted_grade\"] -\n",
    "                           logged_judgments[\"grade\"].mean() -\n",
    "                           theta)\n",
    "    data[\"prob_of_improvement\"] = (\n",
    "        norm.cdf(data[\"opportunity\"] /\n",
    "                 data[\"predicted_stddev\"]))\n",
    "    data[\"expected_improvement\"] = (\n",
    "        data[\"opportunity\"] * data[\"prob_of_improvement\"] + \n",
    "        data[\"predicted_stddev\"] *\n",
    "        norm.pdf(data[\"opportunity\"] /\n",
    "                 data[\"predicted_stddev\"]))    \n",
    "    return data.sort_values(\"expected_improvement\",\n",
    "                            ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>long_description_match</th>\n",
       "      <th>short_description_match</th>\n",
       "      <th>name_match</th>\n",
       "      <th>has_promotion</th>\n",
       "      <th>predicted_grade</th>\n",
       "      <th>predicted_stddev</th>\n",
       "      <th>opportunity</th>\n",
       "      <th>prob_of_improvement</th>\n",
       "      <th>expected_improvement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.098013</td>\n",
       "      <td>0.882676</td>\n",
       "      <td>-0.638497</td>\n",
       "      <td>0.234728</td>\n",
       "      <td>0.121201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010549</td>\n",
       "      <td>0.912794</td>\n",
       "      <td>-0.725962</td>\n",
       "      <td>0.213214</td>\n",
       "      <td>0.110633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.155756</td>\n",
       "      <td>0.795060</td>\n",
       "      <td>-0.580755</td>\n",
       "      <td>0.232556</td>\n",
       "      <td>0.107853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009011</td>\n",
       "      <td>0.882676</td>\n",
       "      <td>-0.727500</td>\n",
       "      <td>0.204914</td>\n",
       "      <td>0.101653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.013849</td>\n",
       "      <td>0.795060</td>\n",
       "      <td>-0.722661</td>\n",
       "      <td>0.181691</td>\n",
       "      <td>0.078549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.011239</td>\n",
       "      <td>0.795060</td>\n",
       "      <td>-0.725272</td>\n",
       "      <td>0.180826</td>\n",
       "      <td>0.078076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.009016</td>\n",
       "      <td>0.795060</td>\n",
       "      <td>-0.727495</td>\n",
       "      <td>0.180091</td>\n",
       "      <td>0.077675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008900</td>\n",
       "      <td>0.795060</td>\n",
       "      <td>-0.727610</td>\n",
       "      <td>0.180053</td>\n",
       "      <td>0.077654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.017392</td>\n",
       "      <td>0.739305</td>\n",
       "      <td>-0.719118</td>\n",
       "      <td>0.165353</td>\n",
       "      <td>0.064866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.161596</td>\n",
       "      <td>0.632121</td>\n",
       "      <td>-0.574914</td>\n",
       "      <td>0.181543</td>\n",
       "      <td>0.062387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.014856</td>\n",
       "      <td>0.632121</td>\n",
       "      <td>-0.721654</td>\n",
       "      <td>0.126802</td>\n",
       "      <td>0.039922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.018530</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>-0.717981</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.256798</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>-0.479713</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014674</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>-0.721837</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014864</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>-0.721646</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.022834</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>-0.713677</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    long_description_match  short_description_match  name_match  \\\n",
       "1                        0                        0           0   \n",
       "5                        0                        1           0   \n",
       "0                        0                        0           0   \n",
       "13                       1                        1           0   \n",
       "4                        0                        1           0   \n",
       "9                        1                        0           0   \n",
       "12                       1                        1           0   \n",
       "8                        1                        0           0   \n",
       "7                        0                        1           1   \n",
       "3                        0                        0           1   \n",
       "15                       1                        1           1   \n",
       "11                       1                        0           1   \n",
       "2                        0                        0           1   \n",
       "10                       1                        0           1   \n",
       "14                       1                        1           1   \n",
       "6                        0                        1           1   \n",
       "\n",
       "    has_promotion  predicted_grade  predicted_stddev  opportunity  \\\n",
       "1               1         0.098013          0.882676    -0.638497   \n",
       "5               1         0.010549          0.912794    -0.725962   \n",
       "0               0         0.155756          0.795060    -0.580755   \n",
       "13              1         0.009011          0.882676    -0.727500   \n",
       "4               0         0.013849          0.795060    -0.722661   \n",
       "9               1         0.011239          0.795060    -0.725272   \n",
       "12              0         0.009016          0.795060    -0.727495   \n",
       "8               0         0.008900          0.795060    -0.727610   \n",
       "7               1         0.017392          0.739305    -0.719118   \n",
       "3               1         0.161596          0.632121    -0.574914   \n",
       "15              1         0.014856          0.632121    -0.721654   \n",
       "11              1         0.018530          0.000010    -0.717981   \n",
       "2               0         0.256798          0.000004    -0.479713   \n",
       "10              0         0.014674          0.000005    -0.721837   \n",
       "14              0         0.014864          0.000007    -0.721646   \n",
       "6               0         0.022834          0.000010    -0.713677   \n",
       "\n",
       "    prob_of_improvement  expected_improvement  \n",
       "1              0.234728              0.121201  \n",
       "5              0.213214              0.110633  \n",
       "0              0.232556              0.107853  \n",
       "13             0.204914              0.101653  \n",
       "4              0.181691              0.078549  \n",
       "9              0.180826              0.078076  \n",
       "12             0.180091              0.077675  \n",
       "8              0.180053              0.077654  \n",
       "7              0.165353              0.064866  \n",
       "3              0.181543              0.062387  \n",
       "15             0.126802              0.039922  \n",
       "11             0.000000              0.000000  \n",
       "2              0.000000              0.000000  \n",
       "10             0.000000              0.000000  \n",
       "14             0.000000              0.000000  \n",
       "6              0.000000              0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "improvement_data = calculate_expected_improvement(\n",
    "    logged_transformers_judgments, feature_names)\n",
    "display(improvement_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a query to fetch `explore` docs (omitted)\n",
    "\n",
    "Based on the selected features from the GaussianProcessRegressor, we create a query to fetch a doc that contains those features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_for_explore_candidate(explore_vector, query=\"\"):\n",
    "    feature_config = {\n",
    "        \"long_description_match\": {\"field\": \"long_description\", \"value\": query},\n",
    "        \"short_description_match\": {\"field\": \"short_description\", \"value\": query},\n",
    "        \"name_match\": {\"field\": \"name\", \"value\": query},\n",
    "        \"long_description_bm25\": {\"field\": \"long_description\", \"value\": query},\n",
    "        \"manufacturer_match\": {\"field\": \"manufacturer\", \"value\": query},\n",
    "        \"has_promotion\": {\"field\": \"has_promotion\", \"value\": \"true\"}\n",
    "    }\n",
    "    explore_candidates = ltr.get_explore_candidate(query, explore_vector, feature_config)\n",
    "    if explore_candidates:\n",
    "        return explore_candidates[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 12.9 - Find document to explore\n",
    "\n",
    "Here we fetch a document that matches the properties of something missing from our training set to display to the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore(query, logged_judgments, features):\n",
    "    \"\"\"Explore according to the provided explore vector, select\n",
    "       a random doc from that group.\"\"\"\n",
    "    feature_names = [f[\"name\"] for f in features]\n",
    "    prediction_data = calculate_expected_improvement(logged_judgments,\n",
    "                                                     feature_names)\n",
    "    explore_vector = prediction_data.head().iloc[0][feature_names]\n",
    "    return search_for_explore_candidate(explore_vector, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74108007469\n"
     ]
    }
   ],
   "source": [
    "#Investigate why this result changes sometimes. Should be 826663114164\n",
    "random.seed(0)\n",
    "\n",
    "explore_features = get_latest_explore_features()\n",
    "logged_judgments = get_logged_transformers_judgments(sessions,\n",
    "                                                     explore_features)\n",
    "explore_upc = explore(\"transformers dvd\", logged_judgments,\n",
    "                                          explore_features)[\"upc\"]\n",
    "print(explore_upc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New heavily clicked doc is promoted!\n",
    "\n",
    "```\n",
    "{\"upc\": \"826663114164\",\n",
    " \"name\": \"Transformers: The Complete Series [25th Anniversary Matrix of Leadership Edition] [16 Discs] - DVD\",\n",
    " \"manufacturer\": \" \",\n",
    " \"short_description\": \" \",\n",
    " \"long_description\": \" \",\n",
    " \"has_promotion\": True}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate new sessions with the new data\n",
    "\n",
    "We simulate new sessions, if the upc is in `might_purchase` or `wants_to_purchase`, we set it to 'clicked' with a given probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_simulated_exploration_sessions(query, sessions,\n",
    "                                            logged_judgments, features, n=500):\n",
    "    \"\"\"Conducts N (500) searches with the query and returns session data with\n",
    "       simulated the simulated user behavior\"\"\"\n",
    "    wants_to_purchase = [97360724240, 97360722345, 826663114164, 97360810042, 93624956037]\n",
    "    might_purchase = [97363455349, 97361312743, 97361372389,\n",
    "                      97361312804, 97363532149, 97363560449]\n",
    "    explore_on_rank = 2.0\n",
    "    with_explore_sessions = sessions.copy()\n",
    "    query_sessions = with_explore_sessions[with_explore_sessions[\"query\"] == query]\n",
    "    for i in range(0, n):\n",
    "        explore_doc = explore(query, logged_judgments, features)\n",
    "        if explore_doc:\n",
    "            explore_upc = int(explore_doc[\"upc\"])\n",
    "            sess_ids = list(set(query_sessions[\"sess_id\"].tolist()))\n",
    "            random.shuffle(sess_ids)\n",
    "            new_session = query_sessions[query_sessions[\"sess_id\"] == sess_ids[0]].copy()\n",
    "            new_session[\"sess_id\"] = 100000 + i\n",
    "            new_session.loc[new_session[\"rank\"] == explore_on_rank, \"doc_id\"] = explore_upc\n",
    "            draw = random.random()\n",
    "            click = ((explore_upc in wants_to_purchase and draw < 0.8) or\n",
    "                     (explore_upc in might_purchase and draw < 0.5) or\n",
    "                     draw < 0.01)\n",
    "            if click:\n",
    "                print(f\"Search {i} resulted in a click on {explore_upc}\")\n",
    "            new_session.loc[new_session[\"rank\"] == explore_on_rank, \"clicked\"] = click\n",
    "            \n",
    "            with_explore_sessions = pandas.concat([with_explore_sessions, new_session])\n",
    "        else:\n",
    "            print(f\"Search {i} no docs\")\n",
    "            \n",
    "    return with_explore_sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 12.10 - Update judgments from new sessions\n",
    "\n",
    "Have we added any new docs that appear to be getting more clicks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search 3 resulted in a click on 97360724240\n",
      "Search 4 resulted in a click on 826663114164\n",
      "Search 11 resulted in a click on 97360722345\n",
      "Search 13 resulted in a click on 97360724240\n",
      "Search 14 resulted in a click on 97360724240\n",
      "Search 17 resulted in a click on 826663114164\n",
      "Search 29 resulted in a click on 826663114164\n",
      "Search 32 resulted in a click on 97360724240\n",
      "Search 33 resulted in a click on 97360722345\n",
      "Search 34 resulted in a click on 826663114164\n",
      "Search 36 resulted in a click on 97360724240\n",
      "Search 44 resulted in a click on 826663114164\n",
      "Search 45 resulted in a click on 826663114164\n",
      "Search 48 resulted in a click on 826663114164\n",
      "Search 55 resulted in a click on 826663114164\n",
      "Search 56 resulted in a click on 27242815414\n",
      "Search 67 resulted in a click on 826663114164\n",
      "Search 74 resulted in a click on 97360722345\n",
      "Search 78 resulted in a click on 97360724240\n",
      "Search 89 resulted in a click on 826663114164\n",
      "Search 93 resulted in a click on 826663114164\n",
      "Search 97 resulted in a click on 97360724240\n",
      "Search 98 resulted in a click on 97360722345\n",
      "Search 102 resulted in a click on 97360724240\n",
      "Search 107 resulted in a click on 97360722345\n",
      "Search 109 resulted in a click on 826663114164\n",
      "Search 116 resulted in a click on 826663114164\n",
      "Search 117 resulted in a click on 826663114164\n",
      "Search 122 resulted in a click on 826663114164\n",
      "Search 123 resulted in a click on 826663114164\n",
      "Search 129 resulted in a click on 97360722345\n",
      "Search 136 resulted in a click on 97360724240\n",
      "Search 138 resulted in a click on 97360722345\n",
      "Search 140 resulted in a click on 97360722345\n",
      "Search 152 resulted in a click on 97360724240\n",
      "Search 155 resulted in a click on 97360722345\n",
      "Search 157 resulted in a click on 97360722345\n",
      "Search 159 resulted in a click on 97360724240\n",
      "Search 161 resulted in a click on 97360724240\n",
      "Search 163 resulted in a click on 97360722345\n",
      "Search 164 resulted in a click on 97360722345\n",
      "Search 165 resulted in a click on 97360722345\n",
      "Search 168 resulted in a click on 826663114164\n",
      "Search 190 resulted in a click on 97360722345\n",
      "Search 196 resulted in a click on 826663114164\n",
      "Search 199 resulted in a click on 97360722345\n",
      "Search 209 resulted in a click on 826663114164\n",
      "Search 211 resulted in a click on 826663114164\n",
      "Search 217 resulted in a click on 826663114164\n",
      "Search 220 resulted in a click on 97360724240\n",
      "Search 231 resulted in a click on 97360724240\n",
      "Search 234 resulted in a click on 97360724240\n",
      "Search 237 resulted in a click on 97360724240\n",
      "Search 252 resulted in a click on 97360724240\n",
      "Search 253 resulted in a click on 97360722345\n",
      "Search 260 resulted in a click on 97360724240\n",
      "Search 278 resulted in a click on 97360722345\n",
      "Search 279 resulted in a click on 97360722345\n",
      "Search 284 resulted in a click on 97360722345\n",
      "Search 291 resulted in a click on 97360722345\n",
      "Search 301 resulted in a click on 826663114164\n",
      "Search 302 resulted in a click on 97360724240\n",
      "Search 303 resulted in a click on 97360722345\n",
      "Search 305 resulted in a click on 97360722345\n",
      "Search 310 resulted in a click on 97360722345\n",
      "Search 315 resulted in a click on 97360724240\n",
      "Search 319 resulted in a click on 826663114164\n",
      "Search 320 resulted in a click on 97360722345\n",
      "Search 321 resulted in a click on 97360724240\n",
      "Search 326 resulted in a click on 826663114164\n",
      "Search 335 resulted in a click on 826663114164\n",
      "Search 343 resulted in a click on 97360722345\n",
      "Search 348 resulted in a click on 97360724240\n",
      "Search 351 resulted in a click on 97360724240\n",
      "Search 356 resulted in a click on 826663114164\n",
      "Search 358 resulted in a click on 97360722345\n",
      "Search 360 resulted in a click on 826663114164\n",
      "Search 364 resulted in a click on 97360724240\n",
      "Search 366 resulted in a click on 97360722345\n",
      "Search 373 resulted in a click on 97360722345\n",
      "Search 384 resulted in a click on 826663114164\n",
      "Search 387 resulted in a click on 826663114164\n",
      "Search 390 resulted in a click on 826663114164\n",
      "Search 394 resulted in a click on 826663114164\n",
      "Search 397 resulted in a click on 97360724240\n",
      "Search 403 resulted in a click on 97360724240\n",
      "Search 404 resulted in a click on 97360724240\n",
      "Search 432 resulted in a click on 826663114164\n",
      "Search 441 resulted in a click on 826663114164\n",
      "Search 442 resulted in a click on 826663114164\n",
      "Search 445 resulted in a click on 97360722345\n",
      "Search 448 resulted in a click on 826663114164\n",
      "Search 450 resulted in a click on 97360724240\n",
      "Search 471 resulted in a click on 826663114164\n",
      "Search 477 resulted in a click on 97360724240\n",
      "Search 481 resulted in a click on 97360722345\n",
      "Search 482 resulted in a click on 826663114164\n",
      "Search 484 resulted in a click on 97360724240\n",
      "Search 486 resulted in a click on 826663114164\n",
      "Search 489 resulted in a click on 97360722345\n",
      "Search 491 resulted in a click on 97360724240\n",
      "Search 495 resulted in a click on 97360722345\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clicked</th>\n",
       "      <th>examined</th>\n",
       "      <th>grade</th>\n",
       "      <th>beta_grade</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>97360722345</th>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.809524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826663114164</th>\n",
       "      <td>38</td>\n",
       "      <td>43</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.754717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97360724240</th>\n",
       "      <td>31</td>\n",
       "      <td>35</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97363455349</th>\n",
       "      <td>731</td>\n",
       "      <td>2117</td>\n",
       "      <td>0.345300</td>\n",
       "      <td>0.344617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97361312804</th>\n",
       "      <td>726</td>\n",
       "      <td>2107</td>\n",
       "      <td>0.344566</td>\n",
       "      <td>0.343883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97363560449</th>\n",
       "      <td>733</td>\n",
       "      <td>2133</td>\n",
       "      <td>0.343647</td>\n",
       "      <td>0.342977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97361312743</th>\n",
       "      <td>708</td>\n",
       "      <td>2078</td>\n",
       "      <td>0.340712</td>\n",
       "      <td>0.340038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97363532149</th>\n",
       "      <td>692</td>\n",
       "      <td>2098</td>\n",
       "      <td>0.329838</td>\n",
       "      <td>0.329222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97361372389</th>\n",
       "      <td>673</td>\n",
       "      <td>2091</td>\n",
       "      <td>0.321856</td>\n",
       "      <td>0.321276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27242815414</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.075000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12505525766</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27242813908</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27242799127</th>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47875842328</th>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400192926087</th>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74108007469</th>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803238004525</th>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879862003517</th>\n",
       "      <td>37</td>\n",
       "      <td>1863</td>\n",
       "      <td>0.019860</td>\n",
       "      <td>0.020822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93624995012</th>\n",
       "      <td>36</td>\n",
       "      <td>1828</td>\n",
       "      <td>0.019694</td>\n",
       "      <td>0.020675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47875842328</th>\n",
       "      <td>32</td>\n",
       "      <td>1809</td>\n",
       "      <td>0.017689</td>\n",
       "      <td>0.018692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708056579746</th>\n",
       "      <td>29</td>\n",
       "      <td>1814</td>\n",
       "      <td>0.015987</td>\n",
       "      <td>0.016996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47875332911</th>\n",
       "      <td>27</td>\n",
       "      <td>1789</td>\n",
       "      <td>0.015092</td>\n",
       "      <td>0.016120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879862003524</th>\n",
       "      <td>25</td>\n",
       "      <td>1827</td>\n",
       "      <td>0.013684</td>\n",
       "      <td>0.014698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47875819733</th>\n",
       "      <td>25</td>\n",
       "      <td>1833</td>\n",
       "      <td>0.013639</td>\n",
       "      <td>0.014650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708056579739</th>\n",
       "      <td>23</td>\n",
       "      <td>1814</td>\n",
       "      <td>0.012679</td>\n",
       "      <td>0.013706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93624974918</th>\n",
       "      <td>20</td>\n",
       "      <td>1784</td>\n",
       "      <td>0.011211</td>\n",
       "      <td>0.012263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47875839090</th>\n",
       "      <td>17</td>\n",
       "      <td>1817</td>\n",
       "      <td>0.009356</td>\n",
       "      <td>0.010400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              clicked  examined     grade  beta_grade\n",
       "doc_id                                               \n",
       "97360722345        32        32  1.000000    0.809524\n",
       "826663114164       38        43  0.883721    0.754717\n",
       "97360724240        31        35  0.885714    0.733333\n",
       "97363455349       731      2117  0.345300    0.344617\n",
       "97361312804       726      2107  0.344566    0.343883\n",
       "97363560449       733      2133  0.343647    0.342977\n",
       "97361312743       708      2078  0.340712    0.340038\n",
       "97363532149       692      2098  0.329838    0.329222\n",
       "97361372389       673      2091  0.321856    0.321276\n",
       "27242815414         1        30  0.033333    0.075000\n",
       "12505525766         0        20  0.000000    0.066667\n",
       "27242813908         0        20  0.000000    0.066667\n",
       "27242799127         0        22  0.000000    0.062500\n",
       "47875842328         0        22  0.000000    0.062500\n",
       "400192926087        0        23  0.000000    0.060606\n",
       "74108007469         0        26  0.000000    0.055556\n",
       "803238004525        0        30  0.000000    0.050000\n",
       "879862003517       37      1863  0.019860    0.020822\n",
       "93624995012        36      1828  0.019694    0.020675\n",
       "47875842328        32      1809  0.017689    0.018692\n",
       "708056579746       29      1814  0.015987    0.016996\n",
       "47875332911        27      1789  0.015092    0.016120\n",
       "879862003524       25      1827  0.013684    0.014698\n",
       "47875819733        25      1833  0.013639    0.014650\n",
       "708056579739       23      1814  0.012679    0.013706\n",
       "93624974918        20      1784  0.011211    0.012263\n",
       "47875839090        17      1817  0.009356    0.010400"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random.seed(1234)\n",
    "\n",
    "query = \"transformers dvd\"\n",
    "sessions_with_exploration = generate_simulated_exploration_sessions(\n",
    "    query, sessions, logged_transformers_judgments, explore_features)\n",
    "training_data_with_exploration = \\\n",
    "    generate_training_data(sessions_with_exploration)\n",
    "display(training_data_with_exploration.loc[\"transformers dvd\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 12.11 - Rebuild model using updated judgments\n",
    "\n",
    "After showing the new document to users, we can rebuild the model using judgments that cover this feature blindspot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'dryer': 0.12737002598513025,\n",
       " 'blue ray': 0.08461538461538462,\n",
       " 'headphones': 0.12110565745285455,\n",
       " 'dark of moon': 0.1492224251599605,\n",
       " 'transformers dvd': 0.2581038440046992}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random.seed(1234)\n",
    "\n",
    "promotion_feature_set = [\n",
    "    ltr.generate_fuzzy_query_feature(feature_name=\"name_fuzzy\",\n",
    "                                     field_name=\"name\"),\n",
    "    ltr.generate_bigram_query_feature(feature_name=\"name_bigram\",\n",
    "                                      field_name=\"name\"),\n",
    "    ltr.generate_bigram_query_feature(feature_name=\"short_description_bigram\",\n",
    "                                      field_name=\"short_description\"),\n",
    "    ltr.generate_query_feature(feature_name=\"has_promotion\",\n",
    "                               field_name=\"has_promotion\",\n",
    "                               value=\"true\",\n",
    "                               constant_score=True)]\n",
    "\n",
    "evaluation = train_and_evaluate_model(sessions_with_exploration,\n",
    "                                      \"ltr_model_variant_3\",\n",
    "                                      promotion_feature_set)\n",
    "display(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'name_fuzzy',\n",
       "  'class': 'org.apache.solr.ltr.feature.SolrFeature',\n",
       "  'params': {'q': 'name_ngram:(${keywords})'},\n",
       "  'store': 'ltr_model_variant_3'},\n",
       " {'name': 'name_bigram',\n",
       "  'class': 'org.apache.solr.ltr.feature.SolrFeature',\n",
       "  'params': {'q': '{!edismax qf=name pf2=name}(${keywords})'},\n",
       "  'store': 'ltr_model_variant_3'},\n",
       " {'name': 'short_description_bigram',\n",
       "  'class': 'org.apache.solr.ltr.feature.SolrFeature',\n",
       "  'params': {'q': '{!edismax qf=short_description pf2=short_description}(${keywords})'},\n",
       "  'store': 'ltr_model_variant_3'},\n",
       " {'name': 'has_promotion',\n",
       "  'class': 'org.apache.solr.ltr.feature.SolrFeature',\n",
       "  'params': {'q': 'has_promotion:true^=1'},\n",
       "  'store': 'ltr_model_variant_3'}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(promotion_feature_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 12.12 - Searching with the latest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Transformers/Transformers: Revenge of the Fallen: Two-Movie Mega Collection [2 Discs] - Widescreen - DVD',\n",
       " 'Transformers: Revenge of the Fallen - Widescreen - DVD',\n",
       " 'Transformers: Dark of the Moon - Original Soundtrack - CD',\n",
       " 'Transformers: The Complete Series [25th Anniversary Matrix of Leadership Edition] [16 Discs] - DVD',\n",
       " 'Transformers: Dark of the Moon Stealth Force Edition - Nintendo Wii']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = ltr.search_with_model(\"ltr_model_variant_3\",\n",
    "                                query=\"transformers dvd\",\n",
    "                                rerank_query=\"transformers dvd\",\n",
    "                                limit=5)[\"docs\"]\n",
    "display([doc[\"name\"] for doc in results])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 12.13 - Rerun A/B test on new `promotion` model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ltr_model_variant_1': 21, 'ltr_model_variant_3': 145}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random.seed(1234)\n",
    "\n",
    "results = simulate_user_a_b_test(query=\"transformers dvd\",\n",
    "                                 model_a=\"ltr_model_variant_1\",\n",
    "                                 model_b=\"ltr_model_variant_3\",\n",
    "                                 number_of_users=1000)\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 12.14 - Fully Automated LTR Loop\n",
    "\n",
    "These lines expand Listing 12.13 from the book (the book content is a truncated form of what's below). You could put this in a loop and constantly try new features to try to get closer at a generalized ranking solution of what users actually want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1234)\n",
    "ltr.delete_feature_store(\"aips_feature_store\")\n",
    "\n",
    "def get_exploit_features():\n",
    "    return [\n",
    "        ltr.generate_fuzzy_query_feature(\"name_fuzzy\", \"name\"),\n",
    "        ltr.generate_query_feature(\"long_description_bm25\", \"long_description\"),\n",
    "        ltr.generate_query_feature(\"short_description_match\", \"short_description\", True)]\n",
    "\n",
    "def gather_latest_sessions(query, sessions, model_name, features):\n",
    "    \"\"\"For the sake of the examples, returns a static list of session data.\n",
    "       In a production environment, this would the most up to date user interactions\"\"\"\n",
    "    training_data = generate_training_data(sessions)\n",
    "    logged_judgments = generate_logged_judgments(training_data, features, model_name)\n",
    "    latest_sessions = generate_simulated_exploration_sessions(query,\n",
    "                                                              sessions,\n",
    "                                                              logged_judgments,\n",
    "                                                              features)\n",
    "    return latest_sessions\n",
    "\n",
    "def is_improvement(evaluation1, evaluation2):\n",
    "    #Model comparison is stubbed out\n",
    "    return True\n",
    "    \n",
    "def wait_for_more_sessions(t):\n",
    "    time.sleep(t)\n",
    "\n",
    "def ltr_retraining_loop(latest_sessions, iterations=sys.maxsize,\n",
    "                        retrain_frequency=60 * 60 * 24):\n",
    "    for i in range(0, iterations):\n",
    "        training_data = generate_training_data(latest_sessions)\n",
    "        train, test = split_training_data(training_data)\n",
    "        if i == 0:\n",
    "            exploit_features = get_exploit_features()\n",
    "            train_and_upload_model(train,\n",
    "                                   \"exploit\",\n",
    "                                   exploit_features)\n",
    "        else:\n",
    "            previous_explore_model_name = f\"explore_variant_{i-1}\"\n",
    "            exploit_model_evaluation = evaluate_model(test, \"exploit\", training_data, log=True)\n",
    "            explore_model_evaluation = evaluate_model(test, previous_explore_model_name, training_data, log=True)\n",
    "            print(f\"Exploit evaluation: {exploit_model_evaluation}\")\n",
    "            print(f\"Explore evaluation: {explore_model_evaluation}\")\n",
    "            if is_improvement(explore_model_evaluation, exploit_model_evaluation):\n",
    "                print(\"Promoting previous explore model\")\n",
    "                train_and_upload_model(train,\n",
    "                                      \"exploit\",\n",
    "                                       explore_features)\n",
    "                \n",
    "        explore_features = get_latest_explore_features()\n",
    "        train_and_upload_model(train,\n",
    "                               f\"explore_variant_{i}\",\n",
    "                               explore_features)\n",
    "        \n",
    "        wait_for_more_sessions(retrain_frequency)\n",
    "        latest_sessions = gather_latest_sessions(\"transformers dvd\", latest_sessions,\n",
    "                                                 f\"explore_variant_{i}\", explore_features)\n",
    "\n",
    "ltr_retraining_loop(sessions, 5, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up next: [Chapter 13: Semantic Search with Dense Vectors](../ch13/1.setting-up-the-outdoors-dataset.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
