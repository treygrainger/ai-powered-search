{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A/B Testing Simulation to Active Learning\n",
    "\n",
    "In this notebook, users have a hidden preference for a single query. We use this to explore A/B testing to see whether a given LTR model actually gives the users what they want.\n",
    "\n",
    "Then we ask, much like in real life, how can we learn what the user _actually_ wants? We employe active learning to try to escape the 'echo chamber' of presentation bias we learned about at the end of chapter 11. After all users can't click on results that never show up in their search results!\n",
    "\n",
    "## ðŸš¨ We're putting it all together in this chapter\n",
    "\n",
    "As this chapter puts together everything from chapters 10 and 11, much of the setup code below wraps up a lot of chapter 11 and 10 into a 'single function' so we can very easily run through the steps in 'one liners'\n",
    "\n",
    "### Getting training data (Ch 11)\n",
    "\n",
    "Chapter 11 is all about turning raw clickstream data into search training data (aka judgments). This involves overcoming biases in how users percieve search. But here we put that in one function call `calculate_sdbn`.\n",
    "\n",
    "### Train a model (Ch 10)\n",
    "\n",
    "Chapter 10 is about training an LTR model, including interacting with Solr to extract features, how a ranking model works, how to train a model, and how to perform a good test/train split for search. But here we similarly wrap that up into a handful of function calls, `split_training_data`, and `evaluate_model`.\n",
    "\n",
    "*long story short, if you see a reference to chapter 10 and 11, it's probably omited from chapter 12* - don't expect it to be covered in chapter 12 extensively.\n",
    "\n",
    "\n",
    "## Setup - gather some sessions (omitted)\n",
    "\n",
    "To get started, we first load a set of simulated search sessions for all queries. \n",
    "\n",
    "Much of this setup is omitted from the chapter. This first part is just loading and synthesizing a bunch of clickstream sessions, like we used in chapter 11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../..')\n",
    "import glob\n",
    "import time\n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "from aips import *\n",
    "import random; random.seed(0)\n",
    "\n",
    "engine = get_engine()\n",
    "products_collection = engine.get_collection(\"products\")\n",
    "ltr = get_ltr_engine(products_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sess_id</th>\n",
       "      <th>query</th>\n",
       "      <th>rank</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>clicked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50002</td>\n",
       "      <td>blue ray</td>\n",
       "      <td>1.0</td>\n",
       "      <td>827396513927</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50002</td>\n",
       "      <td>blue ray</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24543672067</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50002</td>\n",
       "      <td>blue ray</td>\n",
       "      <td>3.0</td>\n",
       "      <td>719192580374</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50002</td>\n",
       "      <td>blue ray</td>\n",
       "      <td>4.0</td>\n",
       "      <td>885170033412</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50002</td>\n",
       "      <td>blue ray</td>\n",
       "      <td>5.0</td>\n",
       "      <td>58231300826</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74995</th>\n",
       "      <td>5001</td>\n",
       "      <td>transformers dark of the moon</td>\n",
       "      <td>10.0</td>\n",
       "      <td>47875841369</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74996</th>\n",
       "      <td>5001</td>\n",
       "      <td>transformers dark of the moon</td>\n",
       "      <td>11.0</td>\n",
       "      <td>97363560449</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74997</th>\n",
       "      <td>5001</td>\n",
       "      <td>transformers dark of the moon</td>\n",
       "      <td>12.0</td>\n",
       "      <td>93624956037</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74998</th>\n",
       "      <td>5001</td>\n",
       "      <td>transformers dark of the moon</td>\n",
       "      <td>13.0</td>\n",
       "      <td>97363532149</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74999</th>\n",
       "      <td>5001</td>\n",
       "      <td>transformers dark of the moon</td>\n",
       "      <td>14.0</td>\n",
       "      <td>400192926087</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1710000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sess_id                          query  rank        doc_id  clicked\n",
       "1        50002                       blue ray   1.0  827396513927    False\n",
       "2        50002                       blue ray   2.0   24543672067    False\n",
       "3        50002                       blue ray   3.0  719192580374    False\n",
       "4        50002                       blue ray   4.0  885170033412     True\n",
       "5        50002                       blue ray   5.0   58231300826    False\n",
       "...        ...                            ...   ...           ...      ...\n",
       "74995     5001  transformers dark of the moon  10.0   47875841369    False\n",
       "74996     5001  transformers dark of the moon  11.0   97363560449    False\n",
       "74997     5001  transformers dark of the moon  12.0   93624956037    False\n",
       "74998     5001  transformers dark of the moon  13.0   97363532149    False\n",
       "74999     5001  transformers dark of the moon  14.0  400192926087    False\n",
       "\n",
       "[1710000 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signals_upcs_to_omit = [600603132872, 600603125065, 600603141003, 600603139758,\n",
    "                        600603133237, 600603123061, 600603140631, 600603124570,\n",
    "                        600603132827, 600603135101]\n",
    "\n",
    "def all_sessions():\n",
    "    sessions = pandas.concat([pandas.read_csv(f, compression='gzip')\n",
    "                          for f in glob.glob('retrotech/sessions/*_sessions.gz')])\n",
    "    sessions = sessions.sort_values(['query', 'sess_id', 'rank'])\n",
    "    sessions = sessions.rename(columns={'clicked_doc_id': 'doc_id'})\n",
    "    return sessions[~sessions[\"doc_id\"].isin(signals_upcs_to_omit)]\n",
    "    \n",
    "sessions = all_sessions()\n",
    "sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['blue ray', 'bluray', 'dryer', 'headphones', 'ipad', 'iphone',\n",
       "       'kindle', 'lcd tv', 'macbook', 'nook', 'star trek', 'star wars',\n",
       "       'transformers dark of the moon'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sessions[\"query\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Part 2 - Add some more query sessions (omitted)\n",
    "\n",
    "Here we duplicate the simulated queries from above, but we flip a handful of the clicks. This just fills out our data a bit more, gives a bit more data to work with.\n",
    "\n",
    "## Setup Part 3 - Our test query, `transformers dvd`, with hidden, 'true' preferences\n",
    "\n",
    "We add a new query to our set of queries `transformers dvd` and we note the users' hidden preferences in the variables `desired_movies` as well as what they consider mediocre `meh_transformers_movies` and not at all relevant `irrelevant_transformers_products`. Each holds the UPC of the associated product.\n",
    "\n",
    "This simulates biased sessions in the data, as if the user never actually sees (and hence never clicks) their actual desired item. If the users desired results are shown, those results get a higher probability of click. Otherwise there is a lower probability of clicks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        sess_id     query  rank        doc_id  clicked\n",
      "1         50002  blue ray   1.0  827396513927    False\n",
      "2         50002  blue ray   2.0   24543672067    False\n",
      "3         50002  blue ray   3.0  719192580374    False\n",
      "4         50002  blue ray   4.0  885170033412     True\n",
      "5         50002  blue ray   5.0   58231300826    False\n",
      "...         ...       ...   ...           ...      ...\n",
      "149994    55001   blueray  24.0   36725617605    False\n",
      "149995    55001   blueray  25.0   22265004517    False\n",
      "149996    55001   blueray  26.0  885170038875    False\n",
      "149997    55001   blueray  27.0  786936817232    False\n",
      "149999    55001   blueray  29.0   27242815414    False\n",
      "\n",
      "[3085000 rows x 5 columns]\n",
      "Click num 4158\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sess_id</th>\n",
       "      <th>query</th>\n",
       "      <th>rank</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>clicked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50002</td>\n",
       "      <td>blue ray</td>\n",
       "      <td>1.0</td>\n",
       "      <td>827396513927</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50002</td>\n",
       "      <td>blue ray</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24543672067</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50002</td>\n",
       "      <td>blue ray</td>\n",
       "      <td>3.0</td>\n",
       "      <td>719192580374</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50002</td>\n",
       "      <td>blue ray</td>\n",
       "      <td>4.0</td>\n",
       "      <td>885170033412</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50002</td>\n",
       "      <td>blue ray</td>\n",
       "      <td>5.0</td>\n",
       "      <td>58231300826</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79995</th>\n",
       "      <td>65000</td>\n",
       "      <td>transformers dvd</td>\n",
       "      <td>11.0</td>\n",
       "      <td>47875842328</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79996</th>\n",
       "      <td>65000</td>\n",
       "      <td>transformers dvd</td>\n",
       "      <td>12.0</td>\n",
       "      <td>879862003517</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79997</th>\n",
       "      <td>65000</td>\n",
       "      <td>transformers dvd</td>\n",
       "      <td>13.0</td>\n",
       "      <td>97361372389</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79998</th>\n",
       "      <td>65000</td>\n",
       "      <td>transformers dvd</td>\n",
       "      <td>14.0</td>\n",
       "      <td>93624995012</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79999</th>\n",
       "      <td>65000</td>\n",
       "      <td>transformers dvd</td>\n",
       "      <td>15.0</td>\n",
       "      <td>47875839090</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3165000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sess_id             query  rank        doc_id  clicked\n",
       "1        50002          blue ray   1.0  827396513927    False\n",
       "2        50002          blue ray   2.0   24543672067    False\n",
       "3        50002          blue ray   3.0  719192580374    False\n",
       "4        50002          blue ray   4.0  885170033412     True\n",
       "5        50002          blue ray   5.0   58231300826    False\n",
       "...        ...               ...   ...           ...      ...\n",
       "79995    65000  transformers dvd  11.0   47875842328    False\n",
       "79996    65000  transformers dvd  12.0  879862003517    False\n",
       "79997    65000  transformers dvd  13.0   97361372389    False\n",
       "79998    65000  transformers dvd  14.0   93624995012    False\n",
       "79999    65000  transformers dvd  15.0   47875839090    False\n",
       "\n",
       "[3165000 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(0)\n",
    "numpy.random.seed(0)\n",
    "\n",
    "def copy_query_sessions(sessions, src_query, dest_query, flip=False):\n",
    "    new_sessions = sessions[sessions[\"query\"] == src_query].copy()  \n",
    "    new_sessions[\"draw\"] = numpy.random.rand(len(new_sessions), 1)\n",
    "    new_sessions.loc[new_sessions[\"clicked\"] & (new_sessions[\"draw\"] < 0.04), \"clicked\"] = False\n",
    "    new_sessions[\"query\"] = dest_query\n",
    "    return pandas.concat([sessions, new_sessions.drop(\"draw\", axis=1)])\n",
    "\n",
    "sessions = all_sessions()\n",
    "sessions = copy_query_sessions(sessions, \"transformers dark of the moon\", \"transformers dark of moon\")\n",
    "sessions = copy_query_sessions(sessions, \"transformers dark of the moon\", \"dark of moon\")\n",
    "sessions = copy_query_sessions(sessions, \"transformers dark of the moon\", \"dark of the moon\")\n",
    "sessions = copy_query_sessions(sessions, \"headphones\", \"head phones\")\n",
    "sessions = copy_query_sessions(sessions, \"lcd tv\", \"lcd television\")\n",
    "sessions = copy_query_sessions(sessions, \"lcd tv\", \"television, lcd\")\n",
    "sessions = copy_query_sessions(sessions, \"macbook\", \"apple laptop\")\n",
    "sessions = copy_query_sessions(sessions, \"iphone\", \"apple iphone\")\n",
    "sessions = copy_query_sessions(sessions, \"kindle\", \"amazon kindle\")\n",
    "sessions = copy_query_sessions(sessions, \"kindle\", \"amazon ereader\")\n",
    "sessions = copy_query_sessions(sessions, \"blue ray\", \"blueray\")\n",
    "\n",
    "print(sessions)\n",
    "\n",
    "next_sess_id = sessions[\"sess_id\"].max()\n",
    "\n",
    "# For some reason, the sessions only capture examines on the 'dubbed' transformers movies\n",
    "# ie the Japanese shows brought to an English-speaking market. But we'll see this is not what the \n",
    "# user wants (ie presentation bias). These are 'meh' mildly interesting. There are also many many\n",
    "# completely irrelevant movies.\n",
    "\n",
    "# What the user wants, but never visible! Never gets clicked!\n",
    "\n",
    "# These are the widescreen transformers dvds of the hollywood movies\n",
    "desired_transformers_movies = [\"97360724240\", \"97360722345\", \"826663114164\"]\n",
    "# Other transformer movies\n",
    "meh_transformers_movies = [\"97363455349\", \"97361312743\", \"97361372389\",\n",
    "                           \"97361312804\", \"97363532149\", \"97363560449\"]\n",
    "# Bunch of random merchandise\n",
    "irrelevant_transformers_products = [\"708056579739\", \"93624995012\", \"47875819733\", \"47875839090\", \"708056579746\",\n",
    "                                    \"47875332911\", \"47875842328\", \"879862003524\", \"879862003517\", \"93624974918\"] \n",
    "\n",
    "\n",
    "displayed_transformer_products = meh_transformers_movies + irrelevant_transformers_products\n",
    "new_sessions = []\n",
    "click = 0\n",
    "for i in range(0, 5000):\n",
    "    random.shuffle(displayed_transformer_products)\n",
    "\n",
    "    # shuffle each session\n",
    "    for rank, upc in enumerate(displayed_transformer_products):\n",
    "        draw = random.random()        \n",
    "        clicked = ((upc in meh_transformers_movies and draw < 0.13) or\n",
    "                   (upc in irrelevant_transformers_products and draw < 0.005))\n",
    "        click += (1 if clicked else 0)\n",
    "        new_sessions.append({\"sess_id\": next_sess_id + i, \n",
    "                             \"query\": \"transformers dvd\", \n",
    "                             \"rank\": rank,\n",
    "                             \"clicked\": clicked,\n",
    "                             \"doc_id\": upc})\n",
    "\n",
    "print(\"Click num \" + str(click))\n",
    "sessions = pandas.concat([sessions, pandas.DataFrame(new_sessions)])\n",
    "sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['blue ray', 'bluray', 'dryer', 'headphones', 'ipad', 'iphone',\n",
       "       'kindle', 'lcd tv', 'macbook', 'nook', 'star trek', 'star wars',\n",
       "       'transformers dark of the moon', 'transformers dark of moon',\n",
       "       'dark of moon', 'dark of the moon', 'head phones',\n",
       "       'lcd television', 'television, lcd', 'apple laptop',\n",
       "       'apple iphone', 'amazon kindle', 'amazon ereader', 'blueray',\n",
       "       'transformers dvd'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sessions[\"query\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup 4 - chapter 11 In One Function (omitted) \n",
    "\n",
    "Wrapping up Chapter 11 in a single function `generate_training_data`. \n",
    "\n",
    "This function computes a relevance grade out of raw clickstream data. Recall that the SDBN (Simplified Dynamic Bayesian Network) click model we learned about in chapter 11 helps overcome position bias. We also use a beta prior so that a single click doesn't count as much as an observation with hundreds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load -s calculate_ctr,calculate_average_rank,caclulate_examine_probability,calculate_clicked_examined,calculate_grade,calculate_prior,calculate_sdbn ../ltr/sdbn_functions.py\n",
    "def calculate_ctr(sessions):\n",
    "    click_counts = sessions.groupby(\"doc_id\")[\"clicked\"].sum()\n",
    "    sess_counts = sessions.groupby(\"doc_id\")[\"sess_id\"].nunique()\n",
    "    ctrs = click_counts / sess_counts\n",
    "    return ctrs.sort_values(ascending=False)\n",
    "\n",
    "def calculate_average_rank(sessions):\n",
    "    avg_rank = sessions.groupby(\"doc_id\")[\"rank\"].mean()\n",
    "    return avg_rank.sort_values(ascending=True)\n",
    "\n",
    "def caclulate_examine_probability(sessions):\n",
    "    last_click_per_session = sessions.groupby([\"clicked\", \"sess_id\"])[\"rank\"].max()[True]\n",
    "    sessions[\"last_click_rank\"] = last_click_per_session\n",
    "    sessions[\"examined\"] = sessions[\"rank\"] <= sessions[\"last_click_rank\"]\n",
    "    return sessions\n",
    "\n",
    "def calculate_clicked_examined(sessions):\n",
    "    sessions = caclulate_examine_probability(sessions)\n",
    "    return sessions[sessions[\"examined\"]] \\\n",
    "        .groupby(\"doc_id\")[[\"clicked\", \"examined\"]].sum()\n",
    "\n",
    "def calculate_grade(sessions):\n",
    "    sessions = calculate_clicked_examined(sessions)\n",
    "    sessions[\"grade\"] = sessions[\"clicked\"] / sessions[\"examined\"]\n",
    "    return sessions.sort_values(\"grade\", ascending=False)\n",
    "\n",
    "def calculate_prior(sessions, prior_grade, prior_weight):\n",
    "    sessions = calculate_grade(sessions)\n",
    "    sessions[\"prior_a\"] = prior_grade * prior_weight\n",
    "    sessions[\"prior_b\"] = (1 - prior_grade) * prior_weight\n",
    "    return sessions\n",
    "\n",
    "def calculate_sdbn(sessions, prior_grade, prior_weight):\n",
    "    sessions = calculate_prior(sessions, prior_grade, prior_weight)\n",
    "    sessions[\"posterior_a\"] = (sessions[\"prior_a\"] + \n",
    "                               sessions[\"clicked\"])\n",
    "    sessions[\"posterior_b\"] = (sessions[\"prior_b\"] + \n",
    "                               sessions[\"examined\"] - sessions[\"clicked\"])\n",
    "    sessions[\"beta_grade\"] = (sessions[\"posterior_a\"] /\n",
    "      (sessions[\"posterior_a\"] + sessions[\"posterior_b\"]))\n",
    "    return sessions.sort_values(\"beta_grade\", ascending=False)\n",
    "\n",
    "def generate_training_data(sessions, prior_grade=0.2, prior_weight=10):\n",
    "    all_sdbn = pandas.DataFrame()\n",
    "    for query in sessions[\"query\"].unique():        \n",
    "        query_sessions = sessions[sessions[\"query\"] == query].copy().set_index(\"sess_id\")\n",
    "        query_sessions = calculate_sdbn(query_sessions, prior_grade, prior_weight)\n",
    "        query_sessions[\"query\"] = query\n",
    "        all_sdbn = pandas.concat([all_sdbn, query_sessions])\n",
    "    return all_sdbn[[\"query\", \"clicked\", \"examined\", \"grade\", \"beta_grade\"]].reset_index().set_index([\"query\", \"doc_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 10 Functions (omitted from book)\n",
    "\n",
    "Now with the chapter 11 setup out of the way, we'll need to give Chapter 10's code a similar treatment, wrapping that LTR system into a black box.\n",
    "\n",
    "All of the following are support functions for the chapter:\n",
    "\n",
    "1. Convert the sdbn dataframe into individual `Judgment` objects needed for training the model from chapter 10\n",
    "2. Pairwise transformation of the data\n",
    "3. Normalization of the data\n",
    "4. Training the model\n",
    "5. Uploading the model to Solr\n",
    "\n",
    "All of these steps are covered in Chapter 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy\n",
    "from ltr.judgments import judgments_to_nparray\n",
    "from sklearn import svm\n",
    "import json\n",
    "from itertools import groupby\n",
    "from ltr.log import FeatureLogger\n",
    "from itertools import groupby\n",
    "from ltr.judgments import judgments_writer\n",
    "\n",
    "from ltr.judgments import Judgment\n",
    "\n",
    "def as_judgments(training_data):\n",
    "    \"\"\"Turn pandas dataframe into ltr judgments objects.\"\"\"        \n",
    "    qid_map = {}\n",
    "    judgments = []\n",
    "    next_qid = 0\n",
    "    for datum in training_data.reset_index().to_dict(orient=\"records\"):       \n",
    "        if datum[\"query\"] not in qid_map:\n",
    "            qid_map[datum[\"query\"]] = next_qid\n",
    "            next_qid += 1\n",
    "        qid = qid_map[datum[\"query\"]]\n",
    "\n",
    "        judgments.append(Judgment(doc_id=datum[\"doc_id\"],\n",
    "                        keywords=datum[\"query\"],\n",
    "                        qid=qid,\n",
    "                        grade=datum[\"beta_grade\"]))\n",
    "        \n",
    "    return judgments\n",
    "\n",
    "def normalize_features(logged_judgments):\n",
    "    num_features = len(logged_judgments[0].features)\n",
    "    means = [numpy.mean([j.features[i] for j in logged_judgments])\n",
    "             for i in range(0, num_features)]    \n",
    "    \n",
    "    std_devs = [numpy.std([j.features[i] for j in logged_judgments])\n",
    "                for i in range(0, num_features)]\n",
    "    \n",
    "    normed_judgments = copy.deepcopy(logged_judgments)\n",
    "    for j in normed_judgments:\n",
    "        for i, score in enumerate(j.features):\n",
    "            j.features[i] = (score - means[i]) / std_devs[i]\n",
    "\n",
    "    return means, std_devs, normed_judgments\n",
    "\n",
    "def pairwise_transform(normed_judgments):        \n",
    "    predictor_deltas = []\n",
    "    feature_deltas = []\n",
    "    for qid, grouped_judgments in groupby(normed_judgments, key=lambda j: j.qid):\n",
    "        query_judgments = list(grouped_judgments)\n",
    "        for judgment1 in query_judgments:\n",
    "            for judgment2 in query_judgments:\n",
    "                j1_features = numpy.array(judgment1.features)\n",
    "                j2_features = numpy.array(judgment2.features)\n",
    "                \n",
    "                if judgment1.grade > judgment2.grade:\n",
    "                    predictor_deltas.append(1)\n",
    "                    feature_deltas.append(j1_features - j2_features)\n",
    "                elif judgment1.grade < judgment2.grade:\n",
    "                    predictor_deltas.append(-1)\n",
    "                    feature_deltas.append(j1_features - j2_features)\n",
    "\n",
    "    return numpy.array(feature_deltas), numpy.array(predictor_deltas)\n",
    "\n",
    "def write_judgments(judgments, dest=\"retrotech_judgments.txt\"):\n",
    "    with judgments_writer(open(dest, \"wt\")) as writer:\n",
    "        for judgment in judgments:\n",
    "            writer.write(judgment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Also Chapter 10 - Perform a test / train split on the SDBN data (omitted)\n",
    "\n",
    "This function is broken out from the model training. It lets us train a model on one set of data (reusing the chapter 10 training code), reserving test queries for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import floor\n",
    "\n",
    "def split_training_data(training_data, train_proportion=0.8):\n",
    "    \"\"\"Split queries in training_data into train / test split with `train` proportion going to training set.\"\"\"\n",
    "    queries = training_data.index.get_level_values('query').unique().copy().tolist()\n",
    "    random.shuffle(queries)\n",
    "    num_queries = len(queries)\n",
    "    split_point = floor(num_queries * train_proportion)\n",
    "    \n",
    "    train_queries = queries[:split_point]\n",
    "    test_queries = queries[split_point:]\n",
    "    return training_data.loc[train_queries, :], training_data.loc[test_queries]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 10 - Evaluate the model on the test set (omitted)\n",
    "\n",
    "This function computes the model's performance on a set of test queries. The `test_data` is the control set not used to train the model. We compute the precision of these queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svm_model(model_name, features, logged_judgments):\n",
    "    means, std_devs, normed_judgments = normalize_features(logged_judgments)\n",
    "    feature_deltas, predictor_deltas = pairwise_transform(normed_judgments)\n",
    "\n",
    "    model = svm.LinearSVC(max_iter=10000, verbose=1)\n",
    "    model.fit(feature_deltas, predictor_deltas) \n",
    "\n",
    "    feature_names = [ftr[\"name\"] for ftr in features]\n",
    "    linear_model = ltr.generate_model(model_name, feature_names,\n",
    "                                      means, std_devs, model.coef_[0])\n",
    "\n",
    "    return linear_model\n",
    "\n",
    "def train_and_upload_model(training_data, model_name, features, log=False):\n",
    "    \"\"\"Train a RankSVM model via Solr, store in Solr.\"\"\"\n",
    "    judgments = as_judgments(training_data)\n",
    "    ltr.delete_feature_store(model_name, log=log)\n",
    "    ltr.delete_model(model_name)\n",
    "    ltr.upload_features(features, model_name, log=log)\n",
    "    ftr_logger = FeatureLogger(engine, products_collection, feature_set=model_name,\n",
    "                               id_field=\"upc\")\n",
    "            \n",
    "    for qid, query_judgments in groupby(judgments, key=lambda j: j.qid):\n",
    "        ftr_logger.log_for_qid(judgments=query_judgments, \n",
    "                               qid=qid, log=False)\n",
    "\n",
    "    linear_model = train_svm_model(model_name, features, ftr_logger.logged)\n",
    "    ltr.upload_model(linear_model, log=log)\n",
    "    return linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(test_data, model_name, training_data, limit=10, log=False):\n",
    "    queries = test_data.index.get_level_values(\"query\").unique()\n",
    "    query_results = {}\n",
    "    \n",
    "    for query in queries:\n",
    "        response = ltr.search_with_model(model_name, query=query,\n",
    "                                         limit=limit, rerank=60000, log=False)\n",
    "    \n",
    "        results = pandas.DataFrame(response[\"docs\"]).reset_index()\n",
    "        judgments = training_data.loc[query, :].copy().reset_index()\n",
    "        judgments[\"doc_id\"] = judgments[\"doc_id\"].astype(str)\n",
    "        if len(results) == 0:\n",
    "            print(f\"No Results for {query}\")\n",
    "            query_results[query] = 0\n",
    "        else:\n",
    "            graded_results = results.merge(judgments, left_on=\"upc\",\n",
    "                                           right_on=\"doc_id\", how=\"left\")\n",
    "            graded_results[[\"clicked\", \"examined\", \"grade\", \"beta_grade\"]] = graded_results[[\"clicked\", \"examined\", \"grade\", \"beta_grade\"]].fillna(0)\n",
    "            graded_results = graded_results.drop(\"doc_id\", axis=1)\n",
    "            if log:\n",
    "                print(graded_results.drop([\"index\", \"rank\", \"manufacturer\", \"short_description\",\n",
    "                                           \"long_description\", \"grade\", \"name\"], axis=1))\n",
    "\n",
    "            query_results[query] = (graded_results[\"beta_grade\"].sum() / limit)\n",
    "    return query_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 12.1 Generating the sdbn training data\n",
    "\n",
    "We kickoff with the data we left off with in chapter 11.\n",
    "\n",
    "In this listing we user our \"chapter 11 in one function\" `generate_training_data` to rebuild training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>clicked</th>\n",
       "      <th>examined</th>\n",
       "      <th>grade</th>\n",
       "      <th>beta_grade</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>query</th>\n",
       "      <th>doc_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">blue ray</th>\n",
       "      <th>27242815414</th>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.846154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827396513927</th>\n",
       "      <td>1304</td>\n",
       "      <td>3359</td>\n",
       "      <td>0.388211</td>\n",
       "      <td>0.387652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883929140855</th>\n",
       "      <td>140</td>\n",
       "      <td>506</td>\n",
       "      <td>0.276680</td>\n",
       "      <td>0.275194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885170033412</th>\n",
       "      <td>568</td>\n",
       "      <td>2147</td>\n",
       "      <td>0.264555</td>\n",
       "      <td>0.264256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24543672067</th>\n",
       "      <td>665</td>\n",
       "      <td>2763</td>\n",
       "      <td>0.240680</td>\n",
       "      <td>0.240534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">transformers dvd</th>\n",
       "      <th>47875819733</th>\n",
       "      <td>24</td>\n",
       "      <td>1679</td>\n",
       "      <td>0.014294</td>\n",
       "      <td>0.015394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708056579739</th>\n",
       "      <td>23</td>\n",
       "      <td>1659</td>\n",
       "      <td>0.013864</td>\n",
       "      <td>0.014979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879862003524</th>\n",
       "      <td>23</td>\n",
       "      <td>1685</td>\n",
       "      <td>0.013650</td>\n",
       "      <td>0.014749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93624974918</th>\n",
       "      <td>19</td>\n",
       "      <td>1653</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0.012628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47875839090</th>\n",
       "      <td>16</td>\n",
       "      <td>1669</td>\n",
       "      <td>0.009587</td>\n",
       "      <td>0.010721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>626 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               clicked  examined     grade  beta_grade\n",
       "query            doc_id                                               \n",
       "blue ray         27242815414        42        42  1.000000    0.846154\n",
       "                 827396513927     1304      3359  0.388211    0.387652\n",
       "                 883929140855      140       506  0.276680    0.275194\n",
       "                 885170033412      568      2147  0.264555    0.264256\n",
       "                 24543672067       665      2763  0.240680    0.240534\n",
       "...                                ...       ...       ...         ...\n",
       "transformers dvd 47875819733        24      1679  0.014294    0.015394\n",
       "                 708056579739       23      1659  0.013864    0.014979\n",
       "                 879862003524       23      1685  0.013650    0.014749\n",
       "                 93624974918        19      1653  0.011494    0.012628\n",
       "                 47875839090        16      1669  0.009587    0.010721\n",
       "\n",
       "[626 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = generate_training_data(sessions,\n",
    "                                       prior_weight=10,\n",
    "                                       prior_grade=0.2)\n",
    "\n",
    "training_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 12.2 - model training\n",
    "\n",
    "We wrap all the important decisions from chapter 10 in a few lines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(sessions, model_name, features, log=False):\n",
    "    training_data = generate_training_data(sessions)\n",
    "    train, test = split_training_data(training_data, 0.8)\n",
    "    train_and_upload_model(train, model_name, features=features, log=False)\n",
    "    evaluation = evaluate_model(test, model_name, training_data, log=log)\n",
    "    return evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][\n",
      "  {\n",
      "    \"name\": \"long_description_bm25\",\n",
      "    \"class\": \"org.apache.solr.ltr.feature.SolrFeature\",\n",
      "    \"params\": {\n",
      "      \"q\": \"long_description:(${keywords})\"\n",
      "    },\n",
      "    \"store\": \"ltr_model_variant_1\"\n",
      "  },\n",
      "  {\n",
      "    \"name\": \"short_description_constant\",\n",
      "    \"class\": \"org.apache.solr.ltr.feature.SolrFeature\",\n",
      "    \"params\": {\n",
      "      \"q\": \"short_description:(${keywords})^=1\"\n",
      "    },\n",
      "    \"store\": \"ltr_model_variant_1\"\n",
      "  }\n",
      "]\n",
      "{\n",
      "  \"dryer\": 0.03753076750950996,\n",
      "  \"blue ray\": 0.0,\n",
      "  \"headphones\": 0.019262295081967213,\n",
      "  \"dark of moon\": 0.0,\n",
      "  \"transformers dvd\": 0.0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "random.seed(1234)\n",
    "feature_set = [\n",
    "    ltr.generate_query_feature(feature_name=\"long_description_bm25\",\n",
    "                               field_name=\"long_description\"),\n",
    "    ltr.generate_query_feature(feature_name=\"short_description_constant\",\n",
    "                               field_name=\"short_description\",\n",
    "                               constant_score=True)]\n",
    "\n",
    "evaluation = train_and_evaluate_model(sessions, \"ltr_model_variant_1\", feature_set)\n",
    "print(json.dumps(feature_set, indent=2))\n",
    "print(json.dumps(evaluation, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 12.3\n",
    "\n",
    "Train a model that hypothetically performs better offline called `ltr_model_variant_2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    doc_id  clicked  examined     grade  beta_grade\n",
      "query                                                              \n",
      "dark of moon   97360810042      393       610  0.644262    0.637097\n",
      "dark of moon  400192926087       61       126  0.484127    0.463235\n",
      "dark of moon   97363560449       91       232  0.392241    0.384298\n",
      "dark of moon   97363532149       39       124  0.314516    0.305970\n",
      "dark of moon   93624956037       40       148  0.270270    0.265823\n",
      "dark of moon   47875842328      354      1474  0.240163    0.239892\n",
      "dark of moon   47875841420      206       915  0.225137    0.224865\n",
      "dark of moon   25192107191      168      1034  0.162476    0.162835\n",
      "dark of moon  786936817218      116       741  0.156545    0.157124\n",
      "dark of moon   47875841369       36       240  0.150000    0.152000\n",
      "dark of moon   24543701538      177      1179  0.150127    0.150547\n",
      "dark of moon   36725235564       38       264  0.143939    0.145985\n",
      "dark of moon   47875841406       76       596  0.127517    0.128713\n",
      "dark of moon   24543750949       31       300  0.103333    0.106452\n",
      "dark of moon   47875842335       51       647  0.078825    0.080670\n",
      "[LibLinear]{\n",
      "  \"dryer\": 0.07068309073137659,\n",
      "  \"blue ray\": 0.0,\n",
      "  \"headphones\": 0.06540945492120899,\n",
      "  \"dark of moon\": 0.257659200402958,\n",
      "  \"transformers dvd\": 0.10077083021678328\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "random.seed(1234)\n",
    "td = generate_training_data(sessions).reset_index().set_index(\"query\")\n",
    "print(td.loc[\"dark of moon\"])\n",
    "\n",
    "feature_set = [\n",
    "    ltr.generate_fuzzy_query_feature(feature_name=\"name_fuzzy\", \n",
    "                                     field_name=\"name\"),\n",
    "    ltr.generate_bigram_query_feature(feature_name=\"name_bigram\",\n",
    "                                      field_name=\"name\"),\n",
    "    ltr.generate_bigram_query_feature(feature_name=\"short_description_bigram\",\n",
    "                                      field_name=\"short_description\")\n",
    "]\n",
    "\n",
    "evaluation = train_and_evaluate_model(sessions, \"ltr_model_variant_2\", feature_set)\n",
    "print(json.dumps(evaluation, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate a user querying, clicking, purchasing (omitted)\n",
    "\n",
    "This function simulates a user performing a query and possibly taking an action as they scan down the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_live_user_session(query, model_name,\n",
    "                               desired_probability=0.15,\n",
    "                               indifferent_probability=0.03,\n",
    "                               uninterested_probability=0.01,\n",
    "                               quit_per_result_probability=0.2):\n",
    "    \"\"\"Simulates a user 'query' where purchase probability depends on if \n",
    "       products upc is in one of three sets.\n",
    "       \n",
    "       Users purchase a single product per session.    \n",
    "       \n",
    "       Users quit with `quit_per_result_probability` after scanning each rank\n",
    "       \n",
    "       \"\"\"   \n",
    "    desired_products = [\"97360724240\", \"97360722345\", \"826663114164\"]\n",
    "    indifferent_products = [\"97363455349\", \"97361312743\", \"97361372389\",\n",
    "                            \"97361312804\", \"97363532149\", \"97363560449\"]\n",
    "    \n",
    "    response = ltr.search_with_model(model_name, query=query, rerank=60000, limit=10)\n",
    "\n",
    "    results = pandas.DataFrame(response[\"docs\"]).reset_index()\n",
    "    for doc in results.to_dict(orient=\"records\"): \n",
    "        draw = random.random()\n",
    "        \n",
    "        if doc[\"upc\"] in desired_products:\n",
    "            if draw < desired_probability:\n",
    "                return True\n",
    "        elif doc[\"upc\"] in indifferent_products:\n",
    "            if draw < indifferent_probability:\n",
    "                return True\n",
    "        elif draw < uninterested_probability:\n",
    "            return True\n",
    "        if random.random() < quit_per_result_probability:\n",
    "            return False\n",
    "        \n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 12.4 - Simulated A/B test on just `transformers dvd` query\n",
    "\n",
    "Here we simulate 1000 users being served two rankings for `transformers dvd` and based on the hidden preferences here (`wants_to_purchase` and `might_purchase`) we see which performs better with conversions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def a_b_test(query, model_a, model_b):\n",
    "    \"\"\"Randomly assign this user to a or b\"\"\"\n",
    "    draw = random.random()\n",
    "    model_name = model_a if draw < 0.5 else model_b\n",
    "    \n",
    "    purchase_made = simulate_live_user_session(query, model_name)\n",
    "    return (model_name, purchase_made)\n",
    "\n",
    "def simulate_user_a_b_test(query, model_a, model_b, number_of_users=1000):\n",
    "    purchases = {model_a: 0, model_b: 0}\n",
    "    for _ in range(number_of_users): \n",
    "        model_name, purchase_made = a_b_test(query, model_a, model_b)\n",
    "        if purchase_made:\n",
    "            purchases[model_name] += 1\n",
    "    return purchases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ltr_model_variant_1': 21, 'ltr_model_variant_2': 17}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(1234)\n",
    "\n",
    "simulate_user_a_b_test(\"transformers dvd\",\n",
    "                       \"ltr_model_variant_1\",\n",
    "                       \"ltr_model_variant_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New helper: show the features for each SDBN entry (omitted)\n",
    "\n",
    "This function shows us the logged features of each training row for the given sdbn data for debugging.\n",
    "\n",
    "So not just\n",
    "\n",
    "| query   | doc      | grade\n",
    "|---------|----------|---------\n",
    "|transformers dvd | 1234 | 1.0\n",
    "\n",
    "But also a recording of the matches that occured\n",
    "\n",
    "| query           | doc      | grade    | short_desc_match  | long_desc_match |...\n",
    "|-----------------|----------|----------|-------------------|-----------------|---\n",
    "|transformers dvd | 1234     | 1.0      | 0.0               | 1.0             |..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_logged_judgments(training_data, features, model_name):\n",
    "    \"\"\"Log features alongside training_data into a dataframe\"\"\"\n",
    "    judgments = as_judgments(training_data)\n",
    "    ltr.delete_feature_store(model_name)\n",
    "    ltr.upload_features(features, model_name)\n",
    "\n",
    "    ftr_logger = FeatureLogger(engine, index=products_collection,\n",
    "                               feature_set=model_name, id_field=\"upc\")\n",
    "\n",
    "    for qid, query_judgments in groupby(judgments, key=lambda j: j.qid):\n",
    "        ftr_logger.log_for_qid(judgments=query_judgments,\n",
    "                               qid=qid, log=False)\n",
    "        \n",
    "    logged_judgments = ftr_logger.logged\n",
    "    feature_data, predictors, doc_ids = judgments_to_nparray(logged_judgments)\n",
    "    logged_judgments_dataframe = pandas.concat([pandas.DataFrame(predictors),\n",
    "                                                pandas.DataFrame(feature_data),\n",
    "                                                pandas.DataFrame(doc_ids)], \n",
    "                                                axis=1,\n",
    "                                                ignore_index=True)\n",
    "    \n",
    "    qid_map = {j.qid: j.keywords for j in logged_judgments}\n",
    "    qid_map = pandas.DataFrame(qid_map.values()).reset_index() \\\n",
    "                         .rename(columns={\"index\": \"qid\", 0: \"query\"})\n",
    "    \n",
    "    feature_names = [f[\"name\"] for f in features]\n",
    "    columns = {i: name for i, name in enumerate([\"grade\", \"qid\"] + feature_names + [\"doc_id\"])}\n",
    "\n",
    "    logged_judgments_dataframe = logged_judgments_dataframe.rename(columns=columns)\n",
    "    logged_judgments_dataframe = logged_judgments_dataframe.merge(qid_map, how=\"left\", on=\"qid\")\n",
    "    ordered_columns = [\"doc_id\", \"query\", \"grade\"] + feature_names\n",
    "    #logged_judgments_dataframe['grade'] = logged_judgments_dataframe['grade'] / 10.0 \n",
    "    \n",
    "    return logged_judgments_dataframe[ordered_columns].set_index(\"doc_id\").sort_values(\"grade\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 12.5 - Output matches for one feature set\n",
    "\n",
    "Another way of formulating `presentation_bias` is to look at the kinds of documents not being shown to users, so we can strategically show those to users. Below we show the value of each feature in `explore_feature_set` for each document in the sdbn judgments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_explore_features():\n",
    "    return [\n",
    "        ltr.generate_query_feature(feature_name=\"long_description_match\",\n",
    "                                   field_name=\"long_description\",\n",
    "                                   constant_score=True),\n",
    "        ltr.generate_query_feature(feature_name=\"short_description_match\",\n",
    "                                   field_name=\"short_description\",\n",
    "                                   constant_score=True),\n",
    "        ltr.generate_query_feature(feature_name=\"name_match\",\n",
    "                                   field_name=\"name\",\n",
    "                                   constant_score=True),\n",
    "        ltr.generate_query_feature(feature_name=\"has_promotion\",\n",
    "                                   field_name=\"has_promotion\",\n",
    "                                   value=\"true\",\n",
    "                                   constant_score=True)]\n",
    "\n",
    "def get_logged_transformers_judgments(sessions, features):\n",
    "    training_data = generate_training_data(sessions)\n",
    "    logged_judgments = generate_logged_judgments(training_data, features, \"explore\")\n",
    "    logged_judgments = logged_judgments[logged_judgments[\"query\"] == \"transformers dvd\"]\n",
    "    return logged_judgments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>grade</th>\n",
       "      <th>long_description_match</th>\n",
       "      <th>short_description_match</th>\n",
       "      <th>name_match</th>\n",
       "      <th>has_promotion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>97363560449</th>\n",
       "      <td>transformers dvd</td>\n",
       "      <td>0.347137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97361312804</th>\n",
       "      <td>transformers dvd</td>\n",
       "      <td>0.344041</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97361312743</th>\n",
       "      <td>transformers dvd</td>\n",
       "      <td>0.342160</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97363455349</th>\n",
       "      <td>transformers dvd</td>\n",
       "      <td>0.342065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97361372389</th>\n",
       "      <td>transformers dvd</td>\n",
       "      <td>0.323484</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97363532149</th>\n",
       "      <td>transformers dvd</td>\n",
       "      <td>0.322664</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879862003517</th>\n",
       "      <td>transformers dvd</td>\n",
       "      <td>0.022834</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93624995012</th>\n",
       "      <td>transformers dvd</td>\n",
       "      <td>0.020202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47875842328</th>\n",
       "      <td>transformers dvd</td>\n",
       "      <td>0.018530</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708056579746</th>\n",
       "      <td>transformers dvd</td>\n",
       "      <td>0.016726</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47875332911</th>\n",
       "      <td>transformers dvd</td>\n",
       "      <td>0.015854</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47875819733</th>\n",
       "      <td>transformers dvd</td>\n",
       "      <td>0.015394</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708056579739</th>\n",
       "      <td>transformers dvd</td>\n",
       "      <td>0.014979</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879862003524</th>\n",
       "      <td>transformers dvd</td>\n",
       "      <td>0.014749</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93624974918</th>\n",
       "      <td>transformers dvd</td>\n",
       "      <td>0.012628</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47875839090</th>\n",
       "      <td>transformers dvd</td>\n",
       "      <td>0.010721</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         query     grade  long_description_match  \\\n",
       "doc_id                                                             \n",
       "97363560449   transformers dvd  0.347137                     0.0   \n",
       "97361312804   transformers dvd  0.344041                     0.0   \n",
       "97361312743   transformers dvd  0.342160                     0.0   \n",
       "97363455349   transformers dvd  0.342065                     0.0   \n",
       "97361372389   transformers dvd  0.323484                     0.0   \n",
       "97363532149   transformers dvd  0.322664                     0.0   \n",
       "879862003517  transformers dvd  0.022834                     0.0   \n",
       "93624995012   transformers dvd  0.020202                     0.0   \n",
       "47875842328   transformers dvd  0.018530                     1.0   \n",
       "708056579746  transformers dvd  0.016726                     1.0   \n",
       "47875332911   transformers dvd  0.015854                     1.0   \n",
       "47875819733   transformers dvd  0.015394                     1.0   \n",
       "708056579739  transformers dvd  0.014979                     1.0   \n",
       "879862003524  transformers dvd  0.014749                     1.0   \n",
       "93624974918   transformers dvd  0.012628                     0.0   \n",
       "47875839090   transformers dvd  0.010721                     1.0   \n",
       "\n",
       "              short_description_match  name_match  has_promotion  \n",
       "doc_id                                                            \n",
       "97363560449                       0.0         1.0            0.0  \n",
       "97361312804                       0.0         1.0            0.0  \n",
       "97361312743                       0.0         1.0            0.0  \n",
       "97363455349                       0.0         1.0            0.0  \n",
       "97361372389                       0.0         1.0            0.0  \n",
       "97363532149                       0.0         1.0            0.0  \n",
       "879862003517                      1.0         1.0            0.0  \n",
       "93624995012                       0.0         1.0            0.0  \n",
       "47875842328                       0.0         1.0            1.0  \n",
       "708056579746                      0.0         1.0            0.0  \n",
       "47875332911                       0.0         1.0            0.0  \n",
       "47875819733                       0.0         1.0            0.0  \n",
       "708056579739                      1.0         1.0            0.0  \n",
       "879862003524                      1.0         1.0            0.0  \n",
       "93624974918                       0.0         1.0            0.0  \n",
       "47875839090                       0.0         1.0            0.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explore_features = get_latest_explore_features()\n",
    "logged_transformers_judgments = get_logged_transformers_judgments(sessions, explore_features)\n",
    "logged_transformers_judgments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 12.6 - Train Gaussian Process Regressor\n",
    "\n",
    "We train data on just the `transformers_training_data`. \n",
    "\n",
    "NOTE we could also train on the full sdbn training data, and see globally what's missing. However it's often convenient to zero in on specific queries to round out their training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "\n",
    "def train_gpr(logged_judgments, feature_names):\n",
    "    feature_data = logged_judgments[feature_names]\n",
    "    grades = logged_judgments[\"grade\"]\n",
    "    gpr = GaussianProcessRegressor()\n",
    "    gpr.fit(feature_data, grades)\n",
    "    return gpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianProcessRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianProcessRegressor</label><div class=\"sk-toggleable__content\"><pre>GaussianProcessRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianProcessRegressor()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = [f[\"name\"] for f in explore_features]\n",
    "train_gpr(logged_transformers_judgments, feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 12.7: Predict on every value\n",
    "\n",
    "Here `gpr` predicts on every possible feature value. This lets us analyze which set of feature values to use when exploring with users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_prediction_std_dev(logged_judgments, feature_names):\n",
    "    index = pandas.MultiIndex.from_product([[0, 1]] * 4, names=feature_names)\n",
    "    with_prediction = pandas.DataFrame(index=index).reset_index()\n",
    "\n",
    "    gpr = train_gpr(logged_judgments, feature_names)\n",
    "    predictions_with_std = gpr.predict(\n",
    "        with_prediction[feature_names], return_std=True)\n",
    "    with_prediction[\"predicted_grade\"] = predictions_with_std[0]\n",
    "    with_prediction[\"predicted_stddev\"] = predictions_with_std[1]\n",
    "   \n",
    "    return  with_prediction.sort_values(\"predicted_stddev\", ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>long_description_match</th>\n",
       "      <th>short_description_match</th>\n",
       "      <th>name_match</th>\n",
       "      <th>has_promotion</th>\n",
       "      <th>predicted_grade</th>\n",
       "      <th>predicted_stddev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.256798</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014674</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014864</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.022834</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.018530</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.161596</td>\n",
       "      <td>0.632121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.014856</td>\n",
       "      <td>0.632121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.017392</td>\n",
       "      <td>0.739305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.155756</td>\n",
       "      <td>0.795060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008900</td>\n",
       "      <td>0.795060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.009016</td>\n",
       "      <td>0.795060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.013849</td>\n",
       "      <td>0.795060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.011239</td>\n",
       "      <td>0.795060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.098013</td>\n",
       "      <td>0.882676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009011</td>\n",
       "      <td>0.882676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010549</td>\n",
       "      <td>0.912794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    long_description_match  short_description_match  name_match  \\\n",
       "2                        0                        0           1   \n",
       "10                       1                        0           1   \n",
       "14                       1                        1           1   \n",
       "6                        0                        1           1   \n",
       "11                       1                        0           1   \n",
       "3                        0                        0           1   \n",
       "15                       1                        1           1   \n",
       "7                        0                        1           1   \n",
       "0                        0                        0           0   \n",
       "8                        1                        0           0   \n",
       "12                       1                        1           0   \n",
       "4                        0                        1           0   \n",
       "9                        1                        0           0   \n",
       "1                        0                        0           0   \n",
       "13                       1                        1           0   \n",
       "5                        0                        1           0   \n",
       "\n",
       "    has_promotion  predicted_grade  predicted_stddev  \n",
       "2               0         0.256798          0.000004  \n",
       "10              0         0.014674          0.000005  \n",
       "14              0         0.014864          0.000007  \n",
       "6               0         0.022834          0.000010  \n",
       "11              1         0.018530          0.000010  \n",
       "3               1         0.161596          0.632121  \n",
       "15              1         0.014856          0.632121  \n",
       "7               1         0.017392          0.739305  \n",
       "0               0         0.155756          0.795060  \n",
       "8               0         0.008900          0.795060  \n",
       "12              0         0.009016          0.795060  \n",
       "4               0         0.013849          0.795060  \n",
       "9               1         0.011239          0.795060  \n",
       "1               1         0.098013          0.882676  \n",
       "13              1         0.009011          0.882676  \n",
       "5               1         0.010549          0.912794  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_prediction_std_dev(logged_transformers_judgments, feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 12.8 - Calculate Expected Improvement\n",
    "\n",
    "\n",
    "We use [Expected Improvement](https://distill.pub/2020/bayesian-optimization/) scoring to select candidates for exploration within the `transformers dvd` query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "def calculate_expected_improvement(logged_judgments, feature_names, theta=0.6):\n",
    "    data = calculate_prediction_std_dev(logged_judgments, feature_names)\n",
    "    data[\"opportunity\"] = (data[\"predicted_grade\"] -\n",
    "                           logged_judgments[\"grade\"].mean() - theta)\n",
    "    data[\"prob_of_improvement\"] = (\n",
    "        norm.cdf(data[\"opportunity\"] /\n",
    "                 data[\"predicted_stddev\"]))\n",
    "    data[\"expected_improvement\"] = (\n",
    "        data[\"opportunity\"] * data[\"prob_of_improvement\"] + \n",
    "        data[\"predicted_stddev\"] *\n",
    "        norm.pdf(data[\"opportunity\"] /\n",
    "                 data[\"predicted_stddev\"]))    \n",
    "    return data.sort_values(\"expected_improvement\",\n",
    "                            ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>long_description_match</th>\n",
       "      <th>short_description_match</th>\n",
       "      <th>name_match</th>\n",
       "      <th>has_promotion</th>\n",
       "      <th>predicted_grade</th>\n",
       "      <th>predicted_stddev</th>\n",
       "      <th>opportunity</th>\n",
       "      <th>prob_of_improvement</th>\n",
       "      <th>expected_improvement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.098013</td>\n",
       "      <td>0.882676</td>\n",
       "      <td>-0.638497</td>\n",
       "      <td>0.234728</td>\n",
       "      <td>0.121201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010549</td>\n",
       "      <td>0.912794</td>\n",
       "      <td>-0.725962</td>\n",
       "      <td>0.213214</td>\n",
       "      <td>0.110633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.155756</td>\n",
       "      <td>0.795060</td>\n",
       "      <td>-0.580755</td>\n",
       "      <td>0.232556</td>\n",
       "      <td>0.107853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009011</td>\n",
       "      <td>0.882676</td>\n",
       "      <td>-0.727500</td>\n",
       "      <td>0.204914</td>\n",
       "      <td>0.101653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.013849</td>\n",
       "      <td>0.795060</td>\n",
       "      <td>-0.722661</td>\n",
       "      <td>0.181691</td>\n",
       "      <td>0.078549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.011239</td>\n",
       "      <td>0.795060</td>\n",
       "      <td>-0.725272</td>\n",
       "      <td>0.180826</td>\n",
       "      <td>0.078076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.009016</td>\n",
       "      <td>0.795060</td>\n",
       "      <td>-0.727495</td>\n",
       "      <td>0.180091</td>\n",
       "      <td>0.077675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008900</td>\n",
       "      <td>0.795060</td>\n",
       "      <td>-0.727610</td>\n",
       "      <td>0.180053</td>\n",
       "      <td>0.077654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.017392</td>\n",
       "      <td>0.739305</td>\n",
       "      <td>-0.719118</td>\n",
       "      <td>0.165353</td>\n",
       "      <td>0.064866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.161596</td>\n",
       "      <td>0.632121</td>\n",
       "      <td>-0.574914</td>\n",
       "      <td>0.181543</td>\n",
       "      <td>0.062387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.014856</td>\n",
       "      <td>0.632121</td>\n",
       "      <td>-0.721654</td>\n",
       "      <td>0.126802</td>\n",
       "      <td>0.039922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.256798</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>-0.479713</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014674</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>-0.721837</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014864</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>-0.721646</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.022834</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>-0.713677</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.018530</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>-0.717981</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    long_description_match  short_description_match  name_match  \\\n",
       "1                        0                        0           0   \n",
       "5                        0                        1           0   \n",
       "0                        0                        0           0   \n",
       "13                       1                        1           0   \n",
       "4                        0                        1           0   \n",
       "9                        1                        0           0   \n",
       "12                       1                        1           0   \n",
       "8                        1                        0           0   \n",
       "7                        0                        1           1   \n",
       "3                        0                        0           1   \n",
       "15                       1                        1           1   \n",
       "2                        0                        0           1   \n",
       "10                       1                        0           1   \n",
       "14                       1                        1           1   \n",
       "6                        0                        1           1   \n",
       "11                       1                        0           1   \n",
       "\n",
       "    has_promotion  predicted_grade  predicted_stddev  opportunity  \\\n",
       "1               1         0.098013          0.882676    -0.638497   \n",
       "5               1         0.010549          0.912794    -0.725962   \n",
       "0               0         0.155756          0.795060    -0.580755   \n",
       "13              1         0.009011          0.882676    -0.727500   \n",
       "4               0         0.013849          0.795060    -0.722661   \n",
       "9               1         0.011239          0.795060    -0.725272   \n",
       "12              0         0.009016          0.795060    -0.727495   \n",
       "8               0         0.008900          0.795060    -0.727610   \n",
       "7               1         0.017392          0.739305    -0.719118   \n",
       "3               1         0.161596          0.632121    -0.574914   \n",
       "15              1         0.014856          0.632121    -0.721654   \n",
       "2               0         0.256798          0.000004    -0.479713   \n",
       "10              0         0.014674          0.000005    -0.721837   \n",
       "14              0         0.014864          0.000007    -0.721646   \n",
       "6               0         0.022834          0.000010    -0.713677   \n",
       "11              1         0.018530          0.000010    -0.717981   \n",
       "\n",
       "    prob_of_improvement  expected_improvement  \n",
       "1              0.234728              0.121201  \n",
       "5              0.213214              0.110633  \n",
       "0              0.232556              0.107853  \n",
       "13             0.204914              0.101653  \n",
       "4              0.181691              0.078549  \n",
       "9              0.180826              0.078076  \n",
       "12             0.180091              0.077675  \n",
       "8              0.180053              0.077654  \n",
       "7              0.165353              0.064866  \n",
       "3              0.181543              0.062387  \n",
       "15             0.126802              0.039922  \n",
       "2              0.000000              0.000000  \n",
       "10             0.000000              0.000000  \n",
       "14             0.000000              0.000000  \n",
       "6              0.000000              0.000000  \n",
       "11             0.000000              0.000000  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_expected_improvement(logged_transformers_judgments, feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a query to fetch `explore` docs (omitted)\n",
    "\n",
    "Based on the selected features from the GaussianProcessRegressor, we create a query to fetch a doc that contains those features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_for_explore_candidate(explore_vector, query=\"\"):\n",
    "    feature_config = {\n",
    "        \"long_description_match\": {\"field\": \"long_description\", \"value\": query},\n",
    "        \"short_description_match\": {\"field\": \"short_description\", \"value\": query},\n",
    "        \"name_match\": {\"field\": \"name\", \"value\": query},\n",
    "        \"long_description_bm25\": {\"field\": \"long_description\", \"value\": query},\n",
    "        \"manufacturer_match\": {\"field\": \"manufacturer\", \"value\": query},\n",
    "        \"has_promotion\": {\"field\": \"has_promotion\", \"value\": \"true\"}\n",
    "    }\n",
    "    explore_candidates = ltr.get_explore_candidate(query, explore_vector, feature_config)\n",
    "    if explore_candidates:\n",
    "        return explore_candidates[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 12.9 - Find document to explore from Solr\n",
    "\n",
    "Here we fetch a document that matches the properties of something missing from our training set to display to the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore(query, logged_judgments, features):\n",
    "    \"\"\"Explore according to the provided explore vector, select\n",
    "       a random doc from that group.\"\"\"\n",
    "    feature_names = [f[\"name\"] for f in features]\n",
    "    prediction_data = calculate_expected_improvement(logged_judgments, feature_names)\n",
    "    explore_vector = prediction_data.head().iloc[0][feature_names]\n",
    "    return search_for_explore_candidate(explore_vector, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27242813908\n"
     ]
    }
   ],
   "source": [
    "#for i in range(100):\n",
    "#    print(i)\n",
    "\n",
    "random.seed(0)\n",
    "explore_features = get_latest_explore_features()\n",
    "logged_judgments = get_logged_transformers_judgments(sessions, explore_features)\n",
    "print(explore(\"transformers dvd\", logged_judgments, explore_features)[\"upc\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New heavily clicked doc is promoted!\n",
    "\n",
    "```\n",
    "{\"upc\": \"826663114164\",\n",
    " \"name\": \"Transformers: The Complete Series [25th Anniversary Matrix of Leadership Edition] [16 Discs] - DVD\",\n",
    " \"manufacturer\": \" \",\n",
    " \"short_description\": \" \",\n",
    " \"long_description\": \" \",\n",
    " \"has_promotion\": True}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate new sessions with the new data\n",
    "\n",
    "We simulate new sessions, if the upc is in `might_purchase` or `wants_to_purchase`, we set it to 'clicked' with a given probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_simulated_exploration_sessions(query, sessions,\n",
    "                                            logged_judgments, features, n=500):\n",
    "    \"\"\"Conducts N (500) searches with the query and returns session data with\n",
    "       simulated the simulated user behavior\"\"\"\n",
    "    wants_to_purchase = [97360724240, 97360722345, 826663114164, 97360810042, 93624956037]\n",
    "    might_purchase = [97363455349, 97361312743, 97361372389,\n",
    "                      97361312804, 97363532149, 97363560449]\n",
    "    explore_on_rank = 2.0\n",
    "    with_explore_sessions = sessions.copy()\n",
    "    query_sessions = with_explore_sessions[with_explore_sessions[\"query\"] == query]\n",
    "    for i in range(0, n):\n",
    "        explore_doc = explore(query, logged_judgments, features)\n",
    "        if explore_doc:\n",
    "            explore_upc = int(explore_doc[\"upc\"])\n",
    "            sess_ids = list(set(query_sessions[\"sess_id\"].tolist()))\n",
    "            random.shuffle(sess_ids)\n",
    "            new_session = query_sessions[query_sessions[\"sess_id\"] == sess_ids[0]].copy()\n",
    "            new_session[\"sess_id\"] = 100000 + i\n",
    "            new_session.loc[new_session[\"rank\"] == explore_on_rank, \"doc_id\"] = explore_upc\n",
    "            draw = random.random()\n",
    "            click = ((explore_upc in wants_to_purchase and draw < 0.8) or\n",
    "                     (explore_upc in might_purchase and draw < 0.5) or\n",
    "                     draw < 0.01)\n",
    "            if click:\n",
    "                print(f\"Search {i} resulted in a click on {explore_upc}\")\n",
    "            new_session.loc[new_session[\"rank\"] == explore_on_rank, \"clicked\"] = click\n",
    "            \n",
    "            with_explore_sessions = pandas.concat([with_explore_sessions, new_session])\n",
    "        else:\n",
    "            print(f\"Search {i} no docs\")\n",
    "            \n",
    "    return with_explore_sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 12.10 - Update judgments from new sessions\n",
    "\n",
    "Have we added any new docs that appear to be getting more clicks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search 0 resulted in a click on 97360722345\n",
      "Search 2 resulted in a click on 97360724240\n",
      "Search 4 resulted in a click on 27242799127\n",
      "Search 10 resulted in a click on 826663114164\n",
      "Search 14 resulted in a click on 97360722345\n",
      "Search 17 resulted in a click on 97360724240\n",
      "Search 20 resulted in a click on 97360724240\n",
      "Search 31 resulted in a click on 97360722345\n",
      "Search 36 resulted in a click on 47875842328\n",
      "Search 37 resulted in a click on 97360722345\n",
      "Search 43 resulted in a click on 97360724240\n",
      "Search 47 resulted in a click on 97360724240\n",
      "Search 49 resulted in a click on 826663114164\n",
      "Search 50 resulted in a click on 826663114164\n",
      "Search 51 resulted in a click on 97360722345\n",
      "Search 52 resulted in a click on 826663114164\n",
      "Search 56 resulted in a click on 47875842328\n",
      "Search 60 resulted in a click on 97360722345\n",
      "Search 61 resulted in a click on 97360724240\n",
      "Search 65 resulted in a click on 97360722345\n",
      "Search 71 resulted in a click on 826663114164\n",
      "Search 80 resulted in a click on 97360722345\n",
      "Search 81 resulted in a click on 97360722345\n",
      "Search 83 resulted in a click on 826663114164\n",
      "Search 86 resulted in a click on 97360724240\n",
      "Search 90 resulted in a click on 97360722345\n",
      "Search 95 resulted in a click on 826663114164\n",
      "Search 103 resulted in a click on 826663114164\n",
      "Search 106 resulted in a click on 97360722345\n",
      "Search 117 resulted in a click on 97360722345\n",
      "Search 121 resulted in a click on 97360722345\n",
      "Search 122 resulted in a click on 826663114164\n",
      "Search 127 resulted in a click on 97360722345\n",
      "Search 135 resulted in a click on 826663114164\n",
      "Search 138 resulted in a click on 97360722345\n",
      "Search 142 resulted in a click on 97360724240\n",
      "Search 147 resulted in a click on 826663114164\n",
      "Search 148 resulted in a click on 826663114164\n",
      "Search 149 resulted in a click on 97360724240\n",
      "Search 152 resulted in a click on 12505525766\n",
      "Search 153 resulted in a click on 97360724240\n",
      "Search 157 resulted in a click on 826663114164\n",
      "Search 159 resulted in a click on 97360724240\n",
      "Search 161 resulted in a click on 97360724240\n",
      "Search 165 resulted in a click on 826663114164\n",
      "Search 166 resulted in a click on 97360722345\n",
      "Search 168 resulted in a click on 826663114164\n",
      "Search 173 resulted in a click on 97360724240\n",
      "Search 175 resulted in a click on 97360724240\n",
      "Search 177 resulted in a click on 826663114164\n",
      "Search 178 resulted in a click on 826663114164\n",
      "Search 180 resulted in a click on 826663114164\n",
      "Search 186 resulted in a click on 826663114164\n",
      "Search 190 resulted in a click on 826663114164\n",
      "Search 193 resulted in a click on 97360722345\n",
      "Search 196 resulted in a click on 826663114164\n",
      "Search 197 resulted in a click on 97360722345\n",
      "Search 206 resulted in a click on 97360722345\n",
      "Search 208 resulted in a click on 826663114164\n",
      "Search 211 resulted in a click on 97360722345\n",
      "Search 219 resulted in a click on 826663114164\n",
      "Search 221 resulted in a click on 826663114164\n",
      "Search 226 resulted in a click on 97360724240\n",
      "Search 240 resulted in a click on 826663114164\n",
      "Search 241 resulted in a click on 97360724240\n",
      "Search 243 resulted in a click on 826663114164\n",
      "Search 244 resulted in a click on 97360724240\n",
      "Search 250 resulted in a click on 97360722345\n",
      "Search 259 resulted in a click on 97360724240\n",
      "Search 260 resulted in a click on 97360722345\n",
      "Search 262 resulted in a click on 97360724240\n",
      "Search 266 resulted in a click on 97360722345\n",
      "Search 268 resulted in a click on 97360724240\n",
      "Search 272 resulted in a click on 97360724240\n",
      "Search 276 resulted in a click on 97360722345\n",
      "Search 279 resulted in a click on 826663114164\n",
      "Search 291 resulted in a click on 97360722345\n",
      "Search 298 resulted in a click on 97360722345\n",
      "Search 302 resulted in a click on 826663114164\n",
      "Search 304 resulted in a click on 97360722345\n",
      "Search 305 resulted in a click on 97360724240\n",
      "Search 307 resulted in a click on 97360722345\n",
      "Search 309 resulted in a click on 826663114164\n",
      "Search 316 resulted in a click on 97360724240\n",
      "Search 321 resulted in a click on 97360724240\n",
      "Search 323 resulted in a click on 97360722345\n",
      "Search 334 resulted in a click on 97360724240\n",
      "Search 338 resulted in a click on 97360722345\n",
      "Search 342 resulted in a click on 97360722345\n",
      "Search 349 resulted in a click on 826663114164\n",
      "Search 365 resulted in a click on 97360724240\n",
      "Search 369 resulted in a click on 97360724240\n",
      "Search 372 resulted in a click on 97360722345\n",
      "Search 373 resulted in a click on 97360722345\n",
      "Search 395 resulted in a click on 826663114164\n",
      "Search 402 resulted in a click on 97360722345\n",
      "Search 403 resulted in a click on 826663114164\n",
      "Search 404 resulted in a click on 97360722345\n",
      "Search 405 resulted in a click on 97360722345\n",
      "Search 408 resulted in a click on 97360722345\n",
      "Search 414 resulted in a click on 826663114164\n",
      "Search 415 resulted in a click on 97360724240\n",
      "Search 421 resulted in a click on 97360722345\n",
      "Search 422 resulted in a click on 826663114164\n",
      "Search 425 resulted in a click on 826663114164\n",
      "Search 426 resulted in a click on 97360724240\n",
      "Search 427 resulted in a click on 97360724240\n",
      "Search 435 resulted in a click on 826663114164\n",
      "Search 438 resulted in a click on 97360724240\n",
      "Search 441 resulted in a click on 826663114164\n",
      "Search 442 resulted in a click on 826663114164\n",
      "Search 448 resulted in a click on 826663114164\n",
      "Search 449 resulted in a click on 97360724240\n",
      "Search 453 resulted in a click on 826663114164\n",
      "Search 457 resulted in a click on 97360722345\n",
      "Search 461 resulted in a click on 97360722345\n",
      "Search 467 resulted in a click on 97360724240\n",
      "Search 474 resulted in a click on 826663114164\n",
      "Search 475 resulted in a click on 97360724240\n",
      "Search 477 resulted in a click on 97360722345\n",
      "Search 479 resulted in a click on 97360724240\n",
      "Search 482 resulted in a click on 826663114164\n",
      "Search 486 resulted in a click on 97360722345\n",
      "Search 488 resulted in a click on 826663114164\n",
      "Search 491 resulted in a click on 826663114164\n",
      "Search 495 resulted in a click on 97360724240\n",
      "Search 497 resulted in a click on 97360722345\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clicked</th>\n",
       "      <th>examined</th>\n",
       "      <th>grade</th>\n",
       "      <th>beta_grade</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>826663114164</th>\n",
       "      <td>44</td>\n",
       "      <td>49</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>0.779661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97360724240</th>\n",
       "      <td>36</td>\n",
       "      <td>39</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.775510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97360722345</th>\n",
       "      <td>43</td>\n",
       "      <td>49</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.762712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97363455349</th>\n",
       "      <td>731</td>\n",
       "      <td>2120</td>\n",
       "      <td>0.344811</td>\n",
       "      <td>0.344131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97361312804</th>\n",
       "      <td>726</td>\n",
       "      <td>2109</td>\n",
       "      <td>0.344239</td>\n",
       "      <td>0.343558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97363560449</th>\n",
       "      <td>733</td>\n",
       "      <td>2131</td>\n",
       "      <td>0.343970</td>\n",
       "      <td>0.343298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97361312743</th>\n",
       "      <td>708</td>\n",
       "      <td>2080</td>\n",
       "      <td>0.340385</td>\n",
       "      <td>0.339713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97363532149</th>\n",
       "      <td>692</td>\n",
       "      <td>2096</td>\n",
       "      <td>0.330153</td>\n",
       "      <td>0.329535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97361372389</th>\n",
       "      <td>673</td>\n",
       "      <td>2092</td>\n",
       "      <td>0.321702</td>\n",
       "      <td>0.321123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47875842328</th>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12505525766</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400192926087</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27242799127</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.081081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27242813908</th>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27242815414</th>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74108007469</th>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803238004525</th>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879862003517</th>\n",
       "      <td>37</td>\n",
       "      <td>1863</td>\n",
       "      <td>0.019860</td>\n",
       "      <td>0.020822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93624995012</th>\n",
       "      <td>36</td>\n",
       "      <td>1830</td>\n",
       "      <td>0.019672</td>\n",
       "      <td>0.020652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47875842328</th>\n",
       "      <td>32</td>\n",
       "      <td>1807</td>\n",
       "      <td>0.017709</td>\n",
       "      <td>0.018712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708056579746</th>\n",
       "      <td>29</td>\n",
       "      <td>1814</td>\n",
       "      <td>0.015987</td>\n",
       "      <td>0.016996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47875332911</th>\n",
       "      <td>27</td>\n",
       "      <td>1792</td>\n",
       "      <td>0.015067</td>\n",
       "      <td>0.016093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879862003524</th>\n",
       "      <td>25</td>\n",
       "      <td>1828</td>\n",
       "      <td>0.013676</td>\n",
       "      <td>0.014690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47875819733</th>\n",
       "      <td>25</td>\n",
       "      <td>1836</td>\n",
       "      <td>0.013617</td>\n",
       "      <td>0.014626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708056579739</th>\n",
       "      <td>23</td>\n",
       "      <td>1824</td>\n",
       "      <td>0.012610</td>\n",
       "      <td>0.013631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93624974918</th>\n",
       "      <td>20</td>\n",
       "      <td>1788</td>\n",
       "      <td>0.011186</td>\n",
       "      <td>0.012236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47875839090</th>\n",
       "      <td>17</td>\n",
       "      <td>1819</td>\n",
       "      <td>0.009346</td>\n",
       "      <td>0.010388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              clicked  examined     grade  beta_grade\n",
       "doc_id                                               \n",
       "826663114164       44        49  0.897959    0.779661\n",
       "97360724240        36        39  0.923077    0.775510\n",
       "97360722345        43        49  0.877551    0.762712\n",
       "97363455349       731      2120  0.344811    0.344131\n",
       "97361312804       726      2109  0.344239    0.343558\n",
       "97363560449       733      2131  0.343970    0.343298\n",
       "97361312743       708      2080  0.340385    0.339713\n",
       "97363532149       692      2096  0.330153    0.329535\n",
       "97361372389       673      2092  0.321702    0.321123\n",
       "47875842328         2        22  0.090909    0.125000\n",
       "12505525766         1        26  0.038462    0.083333\n",
       "400192926087        0        14  0.000000    0.083333\n",
       "27242799127         1        27  0.037037    0.081081\n",
       "27242813908         0        18  0.000000    0.071429\n",
       "27242815414         0        22  0.000000    0.062500\n",
       "74108007469         0        23  0.000000    0.060606\n",
       "803238004525        0        29  0.000000    0.051282\n",
       "879862003517       37      1863  0.019860    0.020822\n",
       "93624995012        36      1830  0.019672    0.020652\n",
       "47875842328        32      1807  0.017709    0.018712\n",
       "708056579746       29      1814  0.015987    0.016996\n",
       "47875332911        27      1792  0.015067    0.016093\n",
       "879862003524       25      1828  0.013676    0.014690\n",
       "47875819733        25      1836  0.013617    0.014626\n",
       "708056579739       23      1824  0.012610    0.013631\n",
       "93624974918        20      1788  0.011186    0.012236\n",
       "47875839090        17      1819  0.009346    0.010388"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(1234)\n",
    "\n",
    "query = \"transformers dvd\"\n",
    "sessions_with_exploration = generate_simulated_exploration_sessions(\n",
    "    query, sessions, logged_transformers_judgments, explore_features)\n",
    "training_data_with_exploration = \\\n",
    "    generate_training_data(sessions_with_exploration)\n",
    "training_data_with_exploration.loc[\"transformers dvd\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 12.11 - Rebuild model using updated judgments\n",
    "\n",
    "After showing the new document to users, we can rebuild the model using judgments that cover this feature blindspot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"name\": \"name_fuzzy\",\n",
      "    \"class\": \"org.apache.solr.ltr.feature.SolrFeature\",\n",
      "    \"params\": {\n",
      "      \"q\": \"name_ngram:(${keywords})\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"name\": \"name_bigram\",\n",
      "    \"class\": \"org.apache.solr.ltr.feature.SolrFeature\",\n",
      "    \"params\": {\n",
      "      \"q\": \"{!edismax qf=name pf2=name}(${keywords})\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"name\": \"short_description_bigram\",\n",
      "    \"class\": \"org.apache.solr.ltr.feature.SolrFeature\",\n",
      "    \"params\": {\n",
      "      \"q\": \"{!edismax qf=short_description pf2=short_description}(${keywords})\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"name\": \"has_promotion\",\n",
      "    \"class\": \"org.apache.solr.ltr.feature.SolrFeature\",\n",
      "    \"params\": {\n",
      "      \"q\": \"has_promotion:true^=1\"\n",
      "    }\n",
      "  }\n",
      "]\n",
      "[LibLinear]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'dryer': 0.12737002598513025,\n",
       " 'blue ray': 0.08461538461538462,\n",
       " 'headphones': 0.12110565745285455,\n",
       " 'dark of moon': 0.1492224251599605,\n",
       " 'transformers dvd': 0.26788571531053584}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(1234)\n",
    "\n",
    "promotion_feature_set = [\n",
    "    ltr.generate_fuzzy_query_feature(feature_name=\"name_fuzzy\",\n",
    "                                     field_name=\"name\"),\n",
    "    ltr.generate_bigram_query_feature(feature_name=\"name_bigram\",\n",
    "                                      field_name=\"name\"),\n",
    "    ltr.generate_bigram_query_feature(feature_name=\"short_description_bigram\",\n",
    "                                      field_name=\"short_description\"),\n",
    "    ltr.generate_query_feature(feature_name=\"has_promotion\",\n",
    "                               field_name=\"has_promotion\",\n",
    "                               value=\"true\",\n",
    "                               constant_score=True)]\n",
    "\n",
    "print(json.dumps(promotion_feature_set, indent=2))\n",
    "train_and_evaluate_model(sessions_with_exploration, \"ltr_model_variant_3\",\n",
    "                         promotion_feature_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Transformers/Transformers: Revenge of the Fallen: Two-Movie Mega Collection [2 Discs] - Widescreen - DVD',\n",
       " 'Transformers: Revenge of the Fallen - Widescreen - DVD',\n",
       " 'Transformers: Dark of the Moon - Original Soundtrack - CD',\n",
       " 'Transformers: The Complete Series [25th Anniversary Matrix of Leadership Edition] [16 Discs] - DVD',\n",
       " 'Transformers: Dark of the Moon Stealth Force Edition - Nintendo Wii']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resulsts = ltr.search_with_model(\"ltr_model_variant_3\",\n",
    "                                 query=\"transformers dvd\",\n",
    "                                 rerank=60000,\n",
    "                                 limit=5)[\"docs\"]\n",
    "[doc[\"name\"] for doc in resulsts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 12.12 - Rerun A/B test on new `promotion` model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ltr_model_variant_1': 21, 'ltr_model_variant_3': 145}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(1234)\n",
    "\n",
    "simulate_user_a_b_test(query=\"transformers dvd\",\n",
    "                       model_a=\"ltr_model_variant_1\",\n",
    "                       model_b=\"ltr_model_variant_3\",\n",
    "                       number_of_users=1000) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 12.13 - Fully Automated LTR Loop\n",
    "\n",
    "These lines expand Listing 12.13 from the book (the book content is a truncated form of what's below). You could put this in a loop and constantly try new features to try to get closer at a generalized ranking solution of what users actually want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear]Search 0 no docs\n",
      "Search 1 no docs\n",
      "Search 2 no docs\n",
      "Search 3 no docs\n",
      "Search 4 no docs\n",
      "Search 5 no docs\n",
      "Search 6 no docs\n",
      "Search 7 no docs\n",
      "Search 8 no docs\n",
      "Search 9 no docs\n",
      "Search 10 no docs\n",
      "Search 11 no docs\n",
      "Search 12 no docs\n",
      "Search 13 no docs\n",
      "Search 14 no docs\n",
      "Search 15 no docs\n",
      "Search 16 no docs\n",
      "Search 17 no docs\n",
      "Search 18 no docs\n",
      "Search 19 no docs\n",
      "Search 20 no docs\n",
      "Search 21 no docs\n",
      "Search 22 no docs\n",
      "Search 23 no docs\n",
      "Search 24 no docs\n",
      "Search 25 no docs\n",
      "Search 26 no docs\n",
      "Search 27 no docs\n",
      "Search 28 no docs\n",
      "Search 29 no docs\n",
      "Search 30 no docs\n",
      "Search 31 no docs\n",
      "Search 32 no docs\n",
      "Search 33 no docs\n",
      "Search 34 no docs\n",
      "Search 35 no docs\n",
      "Search 36 no docs\n",
      "Search 37 no docs\n",
      "Search 38 no docs\n",
      "Search 39 no docs\n",
      "Search 40 no docs\n",
      "Search 41 no docs\n",
      "Search 42 no docs\n",
      "Search 43 no docs\n",
      "Search 44 no docs\n",
      "Search 45 no docs\n",
      "Search 46 no docs\n",
      "Search 47 no docs\n",
      "Search 48 no docs\n",
      "Search 49 no docs\n",
      "Search 50 no docs\n",
      "Search 51 no docs\n",
      "Search 52 no docs\n",
      "Search 53 no docs\n",
      "Search 54 no docs\n",
      "Search 55 no docs\n",
      "Search 56 no docs\n",
      "Search 57 no docs\n",
      "Search 58 no docs\n",
      "Search 59 no docs\n",
      "Search 60 no docs\n",
      "Search 61 no docs\n",
      "Search 62 no docs\n",
      "Search 63 no docs\n",
      "Search 64 no docs\n",
      "Search 65 no docs\n",
      "Search 66 no docs\n",
      "Search 67 no docs\n",
      "Search 68 no docs\n",
      "Search 69 no docs\n",
      "Search 70 no docs\n",
      "Search 71 no docs\n",
      "Search 72 no docs\n",
      "Search 73 no docs\n",
      "Search 74 no docs\n",
      "Search 75 no docs\n",
      "Search 76 no docs\n",
      "Search 77 no docs\n",
      "Search 78 no docs\n",
      "Search 79 no docs\n",
      "Search 80 no docs\n",
      "Search 81 no docs\n",
      "Search 82 no docs\n",
      "Search 83 no docs\n",
      "Search 84 no docs\n",
      "Search 85 no docs\n",
      "Search 86 no docs\n",
      "Search 87 no docs\n",
      "Search 88 no docs\n",
      "Search 89 no docs\n",
      "Search 90 no docs\n",
      "Search 91 no docs\n",
      "Search 92 no docs\n",
      "Search 93 no docs\n",
      "Search 94 no docs\n",
      "Search 95 no docs\n",
      "Search 96 no docs\n",
      "Search 97 no docs\n",
      "Search 98 no docs\n",
      "Search 99 no docs\n",
      "Search 100 no docs\n",
      "Search 101 no docs\n",
      "Search 102 no docs\n",
      "Search 103 no docs\n",
      "Search 104 no docs\n",
      "Search 105 no docs\n",
      "Search 106 no docs\n",
      "Search 107 no docs\n",
      "Search 108 no docs\n",
      "Search 109 no docs\n",
      "Search 110 no docs\n",
      "Search 111 no docs\n",
      "Search 112 no docs\n",
      "Search 113 no docs\n",
      "Search 114 no docs\n",
      "Search 115 no docs\n",
      "Search 116 no docs\n",
      "Search 117 no docs\n",
      "Search 118 no docs\n",
      "Search 119 no docs\n",
      "Search 120 no docs\n",
      "Search 121 no docs\n",
      "Search 122 no docs\n",
      "Search 123 no docs\n",
      "Search 124 no docs\n",
      "Search 125 no docs\n",
      "Search 126 no docs\n",
      "Search 127 no docs\n",
      "Search 128 no docs\n",
      "Search 129 no docs\n",
      "Search 130 no docs\n",
      "Search 131 no docs\n",
      "Search 132 no docs\n",
      "Search 133 no docs\n",
      "Search 134 no docs\n",
      "Search 135 no docs\n",
      "Search 136 no docs\n",
      "Search 137 no docs\n",
      "Search 138 no docs\n",
      "Search 139 no docs\n",
      "Search 140 no docs\n",
      "Search 141 no docs\n",
      "Search 142 no docs\n",
      "Search 143 no docs\n",
      "Search 144 no docs\n",
      "Search 145 no docs\n",
      "Search 146 no docs\n",
      "Search 147 no docs\n",
      "Search 148 no docs\n",
      "Search 149 no docs\n",
      "Search 150 no docs\n",
      "Search 151 no docs\n",
      "Search 152 no docs\n",
      "Search 153 no docs\n",
      "Search 154 no docs\n",
      "Search 155 no docs\n",
      "Search 156 no docs\n",
      "Search 157 no docs\n",
      "Search 158 no docs\n",
      "Search 159 no docs\n",
      "Search 160 no docs\n",
      "Search 161 no docs\n",
      "Search 162 no docs\n",
      "Search 163 no docs\n",
      "Search 164 no docs\n",
      "Search 165 no docs\n",
      "Search 166 no docs\n",
      "Search 167 no docs\n",
      "Search 168 no docs\n",
      "Search 169 no docs\n",
      "Search 170 no docs\n",
      "Search 171 no docs\n",
      "Search 172 no docs\n",
      "Search 173 no docs\n",
      "Search 174 no docs\n",
      "Search 175 no docs\n",
      "Search 176 no docs\n",
      "Search 177 no docs\n",
      "Search 178 no docs\n",
      "Search 179 no docs\n",
      "Search 180 no docs\n",
      "Search 181 no docs\n",
      "Search 182 no docs\n",
      "Search 183 no docs\n",
      "Search 184 no docs\n",
      "Search 185 no docs\n",
      "Search 186 no docs\n",
      "Search 187 no docs\n",
      "Search 188 no docs\n",
      "Search 189 no docs\n",
      "Search 190 no docs\n",
      "Search 191 no docs\n",
      "Search 192 no docs\n",
      "Search 193 no docs\n",
      "Search 194 no docs\n",
      "Search 195 no docs\n",
      "Search 196 no docs\n",
      "Search 197 no docs\n",
      "Search 198 no docs\n",
      "Search 199 no docs\n",
      "Search 200 no docs\n",
      "Search 201 no docs\n",
      "Search 202 no docs\n",
      "Search 203 no docs\n",
      "Search 204 no docs\n",
      "Search 205 no docs\n",
      "Search 206 no docs\n",
      "Search 207 no docs\n",
      "Search 208 no docs\n",
      "Search 209 no docs\n",
      "Search 210 no docs\n",
      "Search 211 no docs\n",
      "Search 212 no docs\n",
      "Search 213 no docs\n",
      "Search 214 no docs\n",
      "Search 215 no docs\n",
      "Search 216 no docs\n",
      "Search 217 no docs\n",
      "Search 218 no docs\n",
      "Search 219 no docs\n",
      "Search 220 no docs\n",
      "Search 221 no docs\n",
      "Search 222 no docs\n",
      "Search 223 no docs\n",
      "Search 224 no docs\n",
      "Search 225 no docs\n",
      "Search 226 no docs\n",
      "Search 227 no docs\n",
      "Search 228 no docs\n",
      "Search 229 no docs\n",
      "Search 230 no docs\n",
      "Search 231 no docs\n",
      "Search 232 no docs\n",
      "Search 233 no docs\n",
      "Search 234 no docs\n",
      "Search 235 no docs\n",
      "Search 236 no docs\n",
      "Search 237 no docs\n",
      "Search 238 no docs\n",
      "Search 239 no docs\n",
      "Search 240 no docs\n",
      "Search 241 no docs\n",
      "Search 242 no docs\n",
      "Search 243 no docs\n",
      "Search 244 no docs\n",
      "Search 245 no docs\n",
      "Search 246 no docs\n",
      "Search 247 no docs\n",
      "Search 248 no docs\n",
      "Search 249 no docs\n",
      "Search 250 no docs\n",
      "Search 251 no docs\n",
      "Search 252 no docs\n",
      "Search 253 no docs\n",
      "Search 254 no docs\n",
      "Search 255 no docs\n",
      "Search 256 no docs\n",
      "Search 257 no docs\n",
      "Search 258 no docs\n",
      "Search 259 no docs\n",
      "Search 260 no docs\n",
      "Search 261 no docs\n",
      "Search 262 no docs\n",
      "Search 263 no docs\n",
      "Search 264 no docs\n",
      "Search 265 no docs\n",
      "Search 266 no docs\n",
      "Search 267 no docs\n",
      "Search 268 no docs\n",
      "Search 269 no docs\n",
      "Search 270 no docs\n",
      "Search 271 no docs\n",
      "Search 272 no docs\n",
      "Search 273 no docs\n",
      "Search 274 no docs\n",
      "Search 275 no docs\n",
      "Search 276 no docs\n",
      "Search 277 no docs\n",
      "Search 278 no docs\n",
      "Search 279 no docs\n",
      "Search 280 no docs\n",
      "Search 281 no docs\n",
      "Search 282 no docs\n",
      "Search 283 no docs\n",
      "Search 284 no docs\n",
      "Search 285 no docs\n",
      "Search 286 no docs\n",
      "Search 287 no docs\n",
      "Search 288 no docs\n",
      "Search 289 no docs\n",
      "Search 290 no docs\n",
      "Search 291 no docs\n",
      "Search 292 no docs\n",
      "Search 293 no docs\n",
      "Search 294 no docs\n",
      "Search 295 no docs\n",
      "Search 296 no docs\n",
      "Search 297 no docs\n",
      "Search 298 no docs\n",
      "Search 299 no docs\n",
      "Search 300 no docs\n",
      "Search 301 no docs\n",
      "Search 302 no docs\n",
      "Search 303 no docs\n",
      "Search 304 no docs\n",
      "Search 305 no docs\n",
      "Search 306 no docs\n",
      "Search 307 no docs\n",
      "Search 308 no docs\n",
      "Search 309 no docs\n",
      "Search 310 no docs\n",
      "Search 311 no docs\n",
      "Search 312 no docs\n",
      "Search 313 no docs\n",
      "Search 314 no docs\n",
      "Search 315 no docs\n",
      "Search 316 no docs\n",
      "Search 317 no docs\n",
      "Search 318 no docs\n",
      "Search 319 no docs\n",
      "Search 320 no docs\n",
      "Search 321 no docs\n",
      "Search 322 no docs\n",
      "Search 323 no docs\n",
      "Search 324 no docs\n",
      "Search 325 no docs\n",
      "Search 326 no docs\n",
      "Search 327 no docs\n",
      "Search 328 no docs\n",
      "Search 329 no docs\n",
      "Search 330 no docs\n",
      "Search 331 no docs\n",
      "Search 332 no docs\n",
      "Search 333 no docs\n",
      "Search 334 no docs\n",
      "Search 335 no docs\n",
      "Search 336 no docs\n",
      "Search 337 no docs\n",
      "Search 338 no docs\n",
      "Search 339 no docs\n",
      "Search 340 no docs\n",
      "Search 341 no docs\n",
      "Search 342 no docs\n",
      "Search 343 no docs\n",
      "Search 344 no docs\n",
      "Search 345 no docs\n",
      "Search 346 no docs\n",
      "Search 347 no docs\n",
      "Search 348 no docs\n",
      "Search 349 no docs\n",
      "Search 350 no docs\n",
      "Search 351 no docs\n",
      "Search 352 no docs\n",
      "Search 353 no docs\n",
      "Search 354 no docs\n",
      "Search 355 no docs\n",
      "Search 356 no docs\n",
      "Search 357 no docs\n",
      "Search 358 no docs\n",
      "Search 359 no docs\n",
      "Search 360 no docs\n",
      "Search 361 no docs\n",
      "Search 362 no docs\n",
      "Search 363 no docs\n",
      "Search 364 no docs\n",
      "Search 365 no docs\n",
      "Search 366 no docs\n",
      "Search 367 no docs\n",
      "Search 368 no docs\n",
      "Search 369 no docs\n",
      "Search 370 no docs\n",
      "Search 371 no docs\n",
      "Search 372 no docs\n",
      "Search 373 no docs\n",
      "Search 374 no docs\n",
      "Search 375 no docs\n",
      "Search 376 no docs\n",
      "Search 377 no docs\n",
      "Search 378 no docs\n",
      "Search 379 no docs\n",
      "Search 380 no docs\n",
      "Search 381 no docs\n",
      "Search 382 no docs\n",
      "Search 383 no docs\n",
      "Search 384 no docs\n",
      "Search 385 no docs\n",
      "Search 386 no docs\n",
      "Search 387 no docs\n",
      "Search 388 no docs\n",
      "Search 389 no docs\n",
      "Search 390 no docs\n",
      "Search 391 no docs\n",
      "Search 392 no docs\n",
      "Search 393 no docs\n",
      "Search 394 no docs\n",
      "Search 395 no docs\n",
      "Search 396 no docs\n",
      "Search 397 no docs\n",
      "Search 398 no docs\n",
      "Search 399 no docs\n",
      "Search 400 no docs\n",
      "Search 401 no docs\n",
      "Search 402 no docs\n",
      "Search 403 no docs\n",
      "Search 404 no docs\n",
      "Search 405 no docs\n",
      "Search 406 no docs\n",
      "Search 407 no docs\n",
      "Search 408 no docs\n",
      "Search 409 no docs\n",
      "Search 410 no docs\n",
      "Search 411 no docs\n",
      "Search 412 no docs\n",
      "Search 413 no docs\n",
      "Search 414 no docs\n",
      "Search 415 no docs\n",
      "Search 416 no docs\n",
      "Search 417 no docs\n",
      "Search 418 no docs\n",
      "Search 419 no docs\n",
      "Search 420 no docs\n",
      "Search 421 no docs\n",
      "Search 422 no docs\n",
      "Search 423 no docs\n",
      "Search 424 no docs\n",
      "Search 425 no docs\n",
      "Search 426 no docs\n",
      "Search 427 no docs\n",
      "Search 428 no docs\n",
      "Search 429 no docs\n",
      "Search 430 no docs\n",
      "Search 431 no docs\n",
      "Search 432 no docs\n",
      "Search 433 no docs\n",
      "Search 434 no docs\n",
      "Search 435 no docs\n",
      "Search 436 no docs\n",
      "Search 437 no docs\n",
      "Search 438 no docs\n",
      "Search 439 no docs\n",
      "Search 440 no docs\n",
      "Search 441 no docs\n",
      "Search 442 no docs\n",
      "Search 443 no docs\n",
      "Search 444 no docs\n",
      "Search 445 no docs\n",
      "Search 446 no docs\n",
      "Search 447 no docs\n",
      "Search 448 no docs\n",
      "Search 449 no docs\n",
      "Search 450 no docs\n",
      "Search 451 no docs\n",
      "Search 452 no docs\n",
      "Search 453 no docs\n",
      "Search 454 no docs\n",
      "Search 455 no docs\n",
      "Search 456 no docs\n",
      "Search 457 no docs\n",
      "Search 458 no docs\n",
      "Search 459 no docs\n",
      "Search 460 no docs\n",
      "Search 461 no docs\n",
      "Search 462 no docs\n",
      "Search 463 no docs\n",
      "Search 464 no docs\n",
      "Search 465 no docs\n",
      "Search 466 no docs\n",
      "Search 467 no docs\n",
      "Search 468 no docs\n",
      "Search 469 no docs\n",
      "Search 470 no docs\n",
      "Search 471 no docs\n",
      "Search 472 no docs\n",
      "Search 473 no docs\n",
      "Search 474 no docs\n",
      "Search 475 no docs\n",
      "Search 476 no docs\n",
      "Search 477 no docs\n",
      "Search 478 no docs\n",
      "Search 479 no docs\n",
      "Search 480 no docs\n",
      "Search 481 no docs\n",
      "Search 482 no docs\n",
      "Search 483 no docs\n",
      "Search 484 no docs\n",
      "Search 485 no docs\n",
      "Search 486 no docs\n",
      "Search 487 no docs\n",
      "Search 488 no docs\n",
      "Search 489 no docs\n",
      "Search 490 no docs\n",
      "Search 491 no docs\n",
      "Search 492 no docs\n",
      "Search 493 no docs\n",
      "Search 494 no docs\n",
      "Search 495 no docs\n",
      "Search 496 no docs\n",
      "Search 497 no docs\n",
      "Search 498 no docs\n",
      "Search 499 no docs\n",
      "No Results for bluray\n",
      "            upc  score  clicked  examined  beta_grade\n",
      "0   24543771807      1      0.0       0.0         0.0\n",
      "1   97361455143      1      0.0       0.0         0.0\n",
      "2  786936817294      1      0.0       0.0         0.0\n",
      "3   13132383590      1      0.0       0.0         0.0\n",
      "4  786936791068      1      0.0       0.0         0.0\n",
      "5  786936810936      1      0.0       0.0         0.0\n",
      "6  883929137114      1      0.0       0.0         0.0\n",
      "7  786936808827      1      0.0       0.0         0.0\n",
      "8   25192100734      1      0.0       0.0         0.0\n",
      "9   65935837770      1      0.0       0.0         0.0\n",
      "            upc  score  clicked  examined  beta_grade\n",
      "0  650530017506      1      0.0       0.0         0.0\n",
      "1   17229117198      1      0.0       0.0         0.0\n",
      "2   17229118119      1      0.0       0.0         0.0\n",
      "3   17229120242      1      0.0       0.0         0.0\n",
      "4   27242718449      1      0.0       0.0         0.0\n",
      "5  885038024712      1      0.0       0.0         0.0\n",
      "6   27242718470      1      0.0       0.0         0.0\n",
      "7   50644556647      1      0.0       0.0         0.0\n",
      "8   44476064920      1      0.0       0.0         0.0\n",
      "9   25192099915      1      0.0       0.0         0.0\n",
      "            upc  score  clicked  examined  beta_grade\n",
      "0  851326003028      1      0.0       0.0         0.0\n",
      "1  851326003066      1      0.0       0.0         0.0\n",
      "            upc  score  clicked  examined  beta_grade\n",
      "0  885909437023      1      129       434    0.295045\n",
      "1  885909432257      1      102       308    0.327044\n",
      "2  885909436705      1      633      1263    0.498822\n",
      "3  885909436002      1      222       757    0.292047\n",
      "4  885909431618      1       96       277    0.341463\n",
      "5  885909464036      1      159       548    0.288530\n",
      "6  885909464043      1      116       274    0.415493\n",
      "7  885909463626      1      175       637    0.273570\n",
      "8  885909282883      1       59       293    0.201320\n",
      "9  885909398577      1      107       392    0.271144\n",
      "No Results for bluray\n",
      "             upc  score  clicked  examined  beta_grade\n",
      "0    74108007469      1      0.0       0.0    0.000000\n",
      "1    27242815414      1     42.0      42.0    0.846154\n",
      "2    27242813908      1      0.0       0.0    0.000000\n",
      "3   846154073763      1      0.0       0.0    0.000000\n",
      "4   843124001955      1      0.0       0.0    0.000000\n",
      "5    43396292260      1      0.0       0.0    0.000000\n",
      "6   887090028400      1      0.0       0.0    0.000000\n",
      "7  5027035005430      1      0.0       0.0    0.000000\n",
      "8   786936813722      1      0.0       0.0    0.000000\n",
      "9    43396261129      1      0.0       0.0    0.000000\n",
      "             upc  score  clicked  examined  beta_grade\n",
      "0   843404074426      1      0.0       0.0         0.0\n",
      "1    81227819828      1      0.0       0.0         0.0\n",
      "2   872967002119      1      0.0       0.0         0.0\n",
      "3   724596944226      1      0.0       0.0         0.0\n",
      "4  4988002447060      1      0.0       0.0         0.0\n",
      "5  5099969422515      1      0.0       0.0         0.0\n",
      "6    29521557534      1      0.0       0.0         0.0\n",
      "7   845519001458      1      0.0       0.0         0.0\n",
      "8    98787091519      1      0.0       0.0         0.0\n",
      "9   660543008774      1      0.0       0.0         0.0\n",
      "            upc  score  clicked  examined  beta_grade\n",
      "0  851326003028      1      0.0       0.0         0.0\n",
      "1  851326003066      1      0.0       0.0         0.0\n",
      "            upc  score  clicked  examined  beta_grade\n",
      "0  885909398577      1      107       392    0.271144\n",
      "1  885909398584      1       74       440    0.168889\n",
      "2  885909437023      1      129       434    0.295045\n",
      "3  885909432257      1      102       308    0.327044\n",
      "4  885909464043      1      116       274    0.415493\n",
      "5  885909464036      1      159       548    0.288530\n",
      "6  885909463626      1      175       637    0.273570\n",
      "7  885909436705      1      633      1263    0.498822\n",
      "8  885909436002      1      222       757    0.292047\n",
      "9  885909431618      1       96       277    0.341463\n",
      "Exploit evaluation: {'bluray': 0, 'blue ray': 0.0, 'head phones': 0.0, 'blueray': 0.0, 'macbook': 0.3204479260910926}\n",
      "Explore evaluation: {'bluray': 0, 'blue ray': 0.08461538461538462, 'head phones': 0.0, 'blueray': 0.0, 'macbook': 0.31720480177866145}\n",
      "Promoting previous explore model\n",
      "[LibLinear][LibLinear]Search 0 no docs\n",
      "Search 1 no docs\n",
      "Search 2 no docs\n",
      "Search 3 no docs\n",
      "Search 4 no docs\n",
      "Search 5 no docs\n",
      "Search 6 no docs\n",
      "Search 7 no docs\n",
      "Search 8 no docs\n",
      "Search 9 no docs\n",
      "Search 10 no docs\n",
      "Search 11 no docs\n",
      "Search 12 no docs\n",
      "Search 13 no docs\n",
      "Search 14 no docs\n",
      "Search 15 no docs\n",
      "Search 16 no docs\n",
      "Search 17 no docs\n",
      "Search 18 no docs\n",
      "Search 19 no docs\n",
      "Search 20 no docs\n",
      "Search 21 no docs\n",
      "Search 22 no docs\n",
      "Search 23 no docs\n",
      "Search 24 no docs\n",
      "Search 25 no docs\n",
      "Search 26 no docs\n",
      "Search 27 no docs\n",
      "Search 28 no docs\n",
      "Search 29 no docs\n",
      "Search 30 no docs\n",
      "Search 31 no docs\n",
      "Search 32 no docs\n",
      "Search 33 no docs\n",
      "Search 34 no docs\n",
      "Search 35 no docs\n",
      "Search 36 no docs\n",
      "Search 37 no docs\n",
      "Search 38 no docs\n",
      "Search 39 no docs\n",
      "Search 40 no docs\n",
      "Search 41 no docs\n",
      "Search 42 no docs\n",
      "Search 43 no docs\n",
      "Search 44 no docs\n",
      "Search 45 no docs\n",
      "Search 46 no docs\n",
      "Search 47 no docs\n",
      "Search 48 no docs\n",
      "Search 49 no docs\n",
      "Search 50 no docs\n",
      "Search 51 no docs\n",
      "Search 52 no docs\n",
      "Search 53 no docs\n",
      "Search 54 no docs\n",
      "Search 55 no docs\n",
      "Search 56 no docs\n",
      "Search 57 no docs\n",
      "Search 58 no docs\n",
      "Search 59 no docs\n",
      "Search 60 no docs\n",
      "Search 61 no docs\n",
      "Search 62 no docs\n",
      "Search 63 no docs\n",
      "Search 64 no docs\n",
      "Search 65 no docs\n",
      "Search 66 no docs\n",
      "Search 67 no docs\n",
      "Search 68 no docs\n",
      "Search 69 no docs\n",
      "Search 70 no docs\n",
      "Search 71 no docs\n",
      "Search 72 no docs\n",
      "Search 73 no docs\n",
      "Search 74 no docs\n",
      "Search 75 no docs\n",
      "Search 76 no docs\n",
      "Search 77 no docs\n",
      "Search 78 no docs\n",
      "Search 79 no docs\n",
      "Search 80 no docs\n",
      "Search 81 no docs\n",
      "Search 82 no docs\n",
      "Search 83 no docs\n",
      "Search 84 no docs\n",
      "Search 85 no docs\n",
      "Search 86 no docs\n",
      "Search 87 no docs\n",
      "Search 88 no docs\n",
      "Search 89 no docs\n",
      "Search 90 no docs\n",
      "Search 91 no docs\n",
      "Search 92 no docs\n",
      "Search 93 no docs\n",
      "Search 94 no docs\n",
      "Search 95 no docs\n",
      "Search 96 no docs\n",
      "Search 97 no docs\n",
      "Search 98 no docs\n",
      "Search 99 no docs\n",
      "Search 100 no docs\n",
      "Search 101 no docs\n",
      "Search 102 no docs\n",
      "Search 103 no docs\n",
      "Search 104 no docs\n",
      "Search 105 no docs\n",
      "Search 106 no docs\n",
      "Search 107 no docs\n",
      "Search 108 no docs\n",
      "Search 109 no docs\n",
      "Search 110 no docs\n",
      "Search 111 no docs\n",
      "Search 112 no docs\n",
      "Search 113 no docs\n",
      "Search 114 no docs\n",
      "Search 115 no docs\n",
      "Search 116 no docs\n",
      "Search 117 no docs\n",
      "Search 118 no docs\n",
      "Search 119 no docs\n",
      "Search 120 no docs\n",
      "Search 121 no docs\n",
      "Search 122 no docs\n",
      "Search 123 no docs\n",
      "Search 124 no docs\n",
      "Search 125 no docs\n",
      "Search 126 no docs\n",
      "Search 127 no docs\n",
      "Search 128 no docs\n",
      "Search 129 no docs\n",
      "Search 130 no docs\n",
      "Search 131 no docs\n",
      "Search 132 no docs\n",
      "Search 133 no docs\n",
      "Search 134 no docs\n",
      "Search 135 no docs\n",
      "Search 136 no docs\n",
      "Search 137 no docs\n",
      "Search 138 no docs\n",
      "Search 139 no docs\n",
      "Search 140 no docs\n",
      "Search 141 no docs\n",
      "Search 142 no docs\n",
      "Search 143 no docs\n",
      "Search 144 no docs\n",
      "Search 145 no docs\n",
      "Search 146 no docs\n",
      "Search 147 no docs\n",
      "Search 148 no docs\n",
      "Search 149 no docs\n",
      "Search 150 no docs\n",
      "Search 151 no docs\n",
      "Search 152 no docs\n",
      "Search 153 no docs\n",
      "Search 154 no docs\n",
      "Search 155 no docs\n",
      "Search 156 no docs\n",
      "Search 157 no docs\n",
      "Search 158 no docs\n",
      "Search 159 no docs\n",
      "Search 160 no docs\n",
      "Search 161 no docs\n",
      "Search 162 no docs\n",
      "Search 163 no docs\n",
      "Search 164 no docs\n",
      "Search 165 no docs\n",
      "Search 166 no docs\n",
      "Search 167 no docs\n",
      "Search 168 no docs\n",
      "Search 169 no docs\n",
      "Search 170 no docs\n",
      "Search 171 no docs\n",
      "Search 172 no docs\n",
      "Search 173 no docs\n",
      "Search 174 no docs\n",
      "Search 175 no docs\n",
      "Search 176 no docs\n",
      "Search 177 no docs\n",
      "Search 178 no docs\n",
      "Search 179 no docs\n",
      "Search 180 no docs\n",
      "Search 181 no docs\n",
      "Search 182 no docs\n",
      "Search 183 no docs\n",
      "Search 184 no docs\n",
      "Search 185 no docs\n",
      "Search 186 no docs\n",
      "Search 187 no docs\n",
      "Search 188 no docs\n",
      "Search 189 no docs\n",
      "Search 190 no docs\n",
      "Search 191 no docs\n",
      "Search 192 no docs\n",
      "Search 193 no docs\n",
      "Search 194 no docs\n",
      "Search 195 no docs\n",
      "Search 196 no docs\n",
      "Search 197 no docs\n",
      "Search 198 no docs\n",
      "Search 199 no docs\n",
      "Search 200 no docs\n",
      "Search 201 no docs\n",
      "Search 202 no docs\n",
      "Search 203 no docs\n",
      "Search 204 no docs\n",
      "Search 205 no docs\n",
      "Search 206 no docs\n",
      "Search 207 no docs\n",
      "Search 208 no docs\n",
      "Search 209 no docs\n",
      "Search 210 no docs\n",
      "Search 211 no docs\n",
      "Search 212 no docs\n",
      "Search 213 no docs\n",
      "Search 214 no docs\n",
      "Search 215 no docs\n",
      "Search 216 no docs\n",
      "Search 217 no docs\n",
      "Search 218 no docs\n",
      "Search 219 no docs\n",
      "Search 220 no docs\n",
      "Search 221 no docs\n",
      "Search 222 no docs\n",
      "Search 223 no docs\n",
      "Search 224 no docs\n",
      "Search 225 no docs\n",
      "Search 226 no docs\n",
      "Search 227 no docs\n",
      "Search 228 no docs\n",
      "Search 229 no docs\n",
      "Search 230 no docs\n",
      "Search 231 no docs\n",
      "Search 232 no docs\n",
      "Search 233 no docs\n",
      "Search 234 no docs\n",
      "Search 235 no docs\n",
      "Search 236 no docs\n",
      "Search 237 no docs\n",
      "Search 238 no docs\n",
      "Search 239 no docs\n",
      "Search 240 no docs\n",
      "Search 241 no docs\n",
      "Search 242 no docs\n",
      "Search 243 no docs\n",
      "Search 244 no docs\n",
      "Search 245 no docs\n",
      "Search 246 no docs\n",
      "Search 247 no docs\n",
      "Search 248 no docs\n",
      "Search 249 no docs\n",
      "Search 250 no docs\n",
      "Search 251 no docs\n",
      "Search 252 no docs\n",
      "Search 253 no docs\n",
      "Search 254 no docs\n",
      "Search 255 no docs\n",
      "Search 256 no docs\n",
      "Search 257 no docs\n",
      "Search 258 no docs\n",
      "Search 259 no docs\n",
      "Search 260 no docs\n",
      "Search 261 no docs\n",
      "Search 262 no docs\n",
      "Search 263 no docs\n",
      "Search 264 no docs\n",
      "Search 265 no docs\n",
      "Search 266 no docs\n",
      "Search 267 no docs\n",
      "Search 268 no docs\n",
      "Search 269 no docs\n",
      "Search 270 no docs\n",
      "Search 271 no docs\n",
      "Search 272 no docs\n",
      "Search 273 no docs\n",
      "Search 274 no docs\n",
      "Search 275 no docs\n",
      "Search 276 no docs\n",
      "Search 277 no docs\n",
      "Search 278 no docs\n",
      "Search 279 no docs\n",
      "Search 280 no docs\n",
      "Search 281 no docs\n",
      "Search 282 no docs\n",
      "Search 283 no docs\n",
      "Search 284 no docs\n",
      "Search 285 no docs\n",
      "Search 286 no docs\n",
      "Search 287 no docs\n",
      "Search 288 no docs\n",
      "Search 289 no docs\n",
      "Search 290 no docs\n",
      "Search 291 no docs\n",
      "Search 292 no docs\n",
      "Search 293 no docs\n",
      "Search 294 no docs\n",
      "Search 295 no docs\n",
      "Search 296 no docs\n",
      "Search 297 no docs\n",
      "Search 298 no docs\n",
      "Search 299 no docs\n",
      "Search 300 no docs\n",
      "Search 301 no docs\n",
      "Search 302 no docs\n",
      "Search 303 no docs\n",
      "Search 304 no docs\n",
      "Search 305 no docs\n",
      "Search 306 no docs\n",
      "Search 307 no docs\n",
      "Search 308 no docs\n",
      "Search 309 no docs\n",
      "Search 310 no docs\n",
      "Search 311 no docs\n",
      "Search 312 no docs\n",
      "Search 313 no docs\n",
      "Search 314 no docs\n",
      "Search 315 no docs\n",
      "Search 316 no docs\n",
      "Search 317 no docs\n",
      "Search 318 no docs\n",
      "Search 319 no docs\n",
      "Search 320 no docs\n",
      "Search 321 no docs\n",
      "Search 322 no docs\n",
      "Search 323 no docs\n",
      "Search 324 no docs\n",
      "Search 325 no docs\n",
      "Search 326 no docs\n",
      "Search 327 no docs\n",
      "Search 328 no docs\n",
      "Search 329 no docs\n",
      "Search 330 no docs\n",
      "Search 331 no docs\n",
      "Search 332 no docs\n",
      "Search 333 no docs\n",
      "Search 334 no docs\n",
      "Search 335 no docs\n",
      "Search 336 no docs\n",
      "Search 337 no docs\n",
      "Search 338 no docs\n",
      "Search 339 no docs\n",
      "Search 340 no docs\n",
      "Search 341 no docs\n",
      "Search 342 no docs\n",
      "Search 343 no docs\n",
      "Search 344 no docs\n",
      "Search 345 no docs\n",
      "Search 346 no docs\n",
      "Search 347 no docs\n",
      "Search 348 no docs\n",
      "Search 349 no docs\n",
      "Search 350 no docs\n",
      "Search 351 no docs\n",
      "Search 352 no docs\n",
      "Search 353 no docs\n",
      "Search 354 no docs\n",
      "Search 355 no docs\n",
      "Search 356 no docs\n",
      "Search 357 no docs\n",
      "Search 358 no docs\n",
      "Search 359 no docs\n",
      "Search 360 no docs\n",
      "Search 361 no docs\n",
      "Search 362 no docs\n",
      "Search 363 no docs\n",
      "Search 364 no docs\n",
      "Search 365 no docs\n",
      "Search 366 no docs\n",
      "Search 367 no docs\n",
      "Search 368 no docs\n",
      "Search 369 no docs\n",
      "Search 370 no docs\n",
      "Search 371 no docs\n",
      "Search 372 no docs\n",
      "Search 373 no docs\n",
      "Search 374 no docs\n",
      "Search 375 no docs\n",
      "Search 376 no docs\n",
      "Search 377 no docs\n",
      "Search 378 no docs\n",
      "Search 379 no docs\n",
      "Search 380 no docs\n",
      "Search 381 no docs\n",
      "Search 382 no docs\n",
      "Search 383 no docs\n",
      "Search 384 no docs\n",
      "Search 385 no docs\n",
      "Search 386 no docs\n",
      "Search 387 no docs\n",
      "Search 388 no docs\n",
      "Search 389 no docs\n",
      "Search 390 no docs\n",
      "Search 391 no docs\n",
      "Search 392 no docs\n",
      "Search 393 no docs\n",
      "Search 394 no docs\n",
      "Search 395 no docs\n",
      "Search 396 no docs\n",
      "Search 397 no docs\n",
      "Search 398 no docs\n",
      "Search 399 no docs\n",
      "Search 400 no docs\n",
      "Search 401 no docs\n",
      "Search 402 no docs\n",
      "Search 403 no docs\n",
      "Search 404 no docs\n",
      "Search 405 no docs\n",
      "Search 406 no docs\n",
      "Search 407 no docs\n",
      "Search 408 no docs\n",
      "Search 409 no docs\n",
      "Search 410 no docs\n",
      "Search 411 no docs\n",
      "Search 412 no docs\n",
      "Search 413 no docs\n",
      "Search 414 no docs\n",
      "Search 415 no docs\n",
      "Search 416 no docs\n",
      "Search 417 no docs\n",
      "Search 418 no docs\n",
      "Search 419 no docs\n",
      "Search 420 no docs\n",
      "Search 421 no docs\n",
      "Search 422 no docs\n",
      "Search 423 no docs\n",
      "Search 424 no docs\n",
      "Search 425 no docs\n",
      "Search 426 no docs\n",
      "Search 427 no docs\n",
      "Search 428 no docs\n",
      "Search 429 no docs\n",
      "Search 430 no docs\n",
      "Search 431 no docs\n",
      "Search 432 no docs\n",
      "Search 433 no docs\n",
      "Search 434 no docs\n",
      "Search 435 no docs\n",
      "Search 436 no docs\n",
      "Search 437 no docs\n",
      "Search 438 no docs\n",
      "Search 439 no docs\n",
      "Search 440 no docs\n",
      "Search 441 no docs\n",
      "Search 442 no docs\n",
      "Search 443 no docs\n",
      "Search 444 no docs\n",
      "Search 445 no docs\n",
      "Search 446 no docs\n",
      "Search 447 no docs\n",
      "Search 448 no docs\n",
      "Search 449 no docs\n",
      "Search 450 no docs\n",
      "Search 451 no docs\n",
      "Search 452 no docs\n",
      "Search 453 no docs\n",
      "Search 454 no docs\n",
      "Search 455 no docs\n",
      "Search 456 no docs\n",
      "Search 457 no docs\n",
      "Search 458 no docs\n",
      "Search 459 no docs\n",
      "Search 460 no docs\n",
      "Search 461 no docs\n",
      "Search 462 no docs\n",
      "Search 463 no docs\n",
      "Search 464 no docs\n",
      "Search 465 no docs\n",
      "Search 466 no docs\n",
      "Search 467 no docs\n",
      "Search 468 no docs\n",
      "Search 469 no docs\n",
      "Search 470 no docs\n",
      "Search 471 no docs\n",
      "Search 472 no docs\n",
      "Search 473 no docs\n",
      "Search 474 no docs\n",
      "Search 475 no docs\n",
      "Search 476 no docs\n",
      "Search 477 no docs\n",
      "Search 478 no docs\n",
      "Search 479 no docs\n",
      "Search 480 no docs\n",
      "Search 481 no docs\n",
      "Search 482 no docs\n",
      "Search 483 no docs\n",
      "Search 484 no docs\n",
      "Search 485 no docs\n",
      "Search 486 no docs\n",
      "Search 487 no docs\n",
      "Search 488 no docs\n",
      "Search 489 no docs\n",
      "Search 490 no docs\n",
      "Search 491 no docs\n",
      "Search 492 no docs\n",
      "Search 493 no docs\n",
      "Search 494 no docs\n",
      "Search 495 no docs\n",
      "Search 496 no docs\n",
      "Search 497 no docs\n",
      "Search 498 no docs\n",
      "Search 499 no docs\n",
      "            upc  score  clicked  examined  beta_grade\n",
      "0   25192122224      1      0.0       0.0    0.000000\n",
      "1   13132247991      1      0.0       0.0    0.000000\n",
      "2  631364508231      1      0.0       0.0    0.000000\n",
      "3   25192122224      1      0.0       0.0    0.000000\n",
      "4  814916011872      1    438.0    1552.0    0.281690\n",
      "5  814916010233      1    165.0     967.0    0.170931\n",
      "6  814916011896      1    205.0     443.0    0.456954\n",
      "7  814916010202      1     85.0     345.0    0.245070\n",
      "8  814916010240      1    144.0     617.0    0.232855\n",
      "9  814916010219      1    135.0     654.0    0.206325\n",
      "            upc  score  clicked  examined  beta_grade\n",
      "0   97360722345      1      0.0       0.0    0.000000\n",
      "1  826663114164      1      0.0       0.0    0.000000\n",
      "2  400192926087      1     62.0     129.0    0.460432\n",
      "3   97360724240      1      0.0       0.0    0.000000\n",
      "4   47875842328      1    367.0    1531.0    0.239455\n",
      "5   74108007469      1      0.0       0.0    0.000000\n",
      "6   27242815414      1      0.0       0.0    0.000000\n",
      "7   27242813908      1      0.0       0.0    0.000000\n",
      "8  678149167924      1      0.0       0.0    0.000000\n",
      "9   31398235934      1      0.0       0.0    0.000000\n",
      "            upc  score  clicked  examined  beta_grade\n",
      "0   27242815414      1      0.0       0.0    0.000000\n",
      "1   27242813908      1      0.0       0.0    0.000000\n",
      "2  735541201080      1      0.0       0.0    0.000000\n",
      "3  856195002073      1      0.0       0.0    0.000000\n",
      "4  812491010310      1     29.0     205.0    0.144186\n",
      "5  719192580916      1      0.0       0.0    0.000000\n",
      "6  719192579996      1      0.0      91.0    0.019802\n",
      "7  719192580930      1      0.0       0.0    0.000000\n",
      "8  883393001423      1      0.0       0.0    0.000000\n",
      "9  615798396640      1      0.0       0.0    0.000000\n",
      "            upc  score  clicked  examined  beta_grade\n",
      "0   97360722345      1      0.0       0.0    0.000000\n",
      "1  826663114164      1      0.0       0.0    0.000000\n",
      "2  400192926087      1     60.0     126.0    0.455882\n",
      "3   97360724240      1      0.0       0.0    0.000000\n",
      "4   47875842328      1    352.0    1484.0    0.236948\n",
      "5   74108007469      1      0.0       0.0    0.000000\n",
      "6   27242815414      1      0.0       0.0    0.000000\n",
      "7   27242813908      1      0.0       0.0    0.000000\n",
      "8   97368855748      1      0.0       0.0    0.000000\n",
      "9  883929024919      1      0.0       0.0    0.000000\n",
      "            upc  score  clicked  examined  beta_grade\n",
      "0  885909398577      1      107       392    0.271144\n",
      "1  885909398584      1       74       440    0.168889\n",
      "2  885909437023      1      129       434    0.295045\n",
      "3  885909432257      1      102       308    0.327044\n",
      "4  885909464043      1      116       274    0.415493\n",
      "5  885909464036      1      159       548    0.288530\n",
      "6  885909463626      1      175       637    0.273570\n",
      "7  885909436705      1      633      1263    0.498822\n",
      "8  885909436002      1      222       757    0.292047\n",
      "9  885909431618      1       96       277    0.341463\n",
      "            upc  score  clicked  examined  beta_grade\n",
      "0   25192122224      1      0.0       0.0    0.000000\n",
      "1   13132247991      1      0.0       0.0    0.000000\n",
      "2  631364508231      1      0.0       0.0    0.000000\n",
      "3   25192122224      1      0.0       0.0    0.000000\n",
      "4  814916011872      1    438.0    1552.0    0.281690\n",
      "5  814916010233      1    165.0     967.0    0.170931\n",
      "6  814916011896      1    205.0     443.0    0.456954\n",
      "7  814916010202      1     85.0     345.0    0.245070\n",
      "8  814916010240      1    144.0     617.0    0.232855\n",
      "9  814916010219      1    135.0     654.0    0.206325\n",
      "            upc  score  clicked  examined  beta_grade\n",
      "0   97360722345      1      0.0       0.0    0.000000\n",
      "1  826663114164      1      0.0       0.0    0.000000\n",
      "2  400192926087      1     62.0     129.0    0.460432\n",
      "3   97360724240      1      0.0       0.0    0.000000\n",
      "4   47875842328      1    367.0    1531.0    0.239455\n",
      "5   74108007469      1      0.0       0.0    0.000000\n",
      "6   27242815414      1      0.0       0.0    0.000000\n",
      "7   27242813908      1      0.0       0.0    0.000000\n",
      "8  678149167924      1      0.0       0.0    0.000000\n",
      "9   31398235934      1      0.0       0.0    0.000000\n",
      "            upc  score  clicked  examined  beta_grade\n",
      "0   27242815414      1      0.0       0.0    0.000000\n",
      "1   27242813908      1      0.0       0.0    0.000000\n",
      "2  735541201080      1      0.0       0.0    0.000000\n",
      "3  856195002073      1      0.0       0.0    0.000000\n",
      "4  812491010310      1     29.0     205.0    0.144186\n",
      "5  719192580916      1      0.0       0.0    0.000000\n",
      "6  719192579996      1      0.0      91.0    0.019802\n",
      "7  719192580930      1      0.0       0.0    0.000000\n",
      "8  883393001423      1      0.0       0.0    0.000000\n",
      "9  615798396640      1      0.0       0.0    0.000000\n",
      "            upc  score  clicked  examined  beta_grade\n",
      "0   97360722345      1      0.0       0.0    0.000000\n",
      "1  826663114164      1      0.0       0.0    0.000000\n",
      "2  400192926087      1     60.0     126.0    0.455882\n",
      "3   97360724240      1      0.0       0.0    0.000000\n",
      "4   47875842328      1    352.0    1484.0    0.236948\n",
      "5   74108007469      1      0.0       0.0    0.000000\n",
      "6   27242815414      1      0.0       0.0    0.000000\n",
      "7   27242813908      1      0.0       0.0    0.000000\n",
      "8   97368855748      1      0.0       0.0    0.000000\n",
      "9  883929024919      1      0.0       0.0    0.000000\n",
      "            upc  score  clicked  examined  beta_grade\n",
      "0  885909398577      1      107       392    0.271144\n",
      "1  885909398584      1       74       440    0.168889\n",
      "2  885909437023      1      129       434    0.295045\n",
      "3  885909432257      1      102       308    0.327044\n",
      "4  885909464043      1      116       274    0.415493\n",
      "5  885909464036      1      159       548    0.288530\n",
      "6  885909463626      1      175       637    0.273570\n",
      "7  885909436705      1      633      1263    0.498822\n",
      "8  885909436002      1      222       757    0.292047\n",
      "9  885909431618      1       96       277    0.341463\n",
      "Exploit evaluation: {'amazon kindle': 0.1593825794125639, 'transformers dark of the moon': 0.06998865540922226, 'lcd tv': 0.01639880267096477, 'transformers dark of moon': 0.06928301441058352, 'macbook': 0.31720480177866145}\n",
      "Explore evaluation: {'amazon kindle': 0.1593825794125639, 'transformers dark of the moon': 0.06998865540922226, 'lcd tv': 0.01639880267096477, 'transformers dark of moon': 0.06928301441058352, 'macbook': 0.31720480177866145}\n",
      "Promoting previous explore model\n",
      "[LibLinear][LibLinear]Search 0 no docs\n",
      "Search 1 no docs\n",
      "Search 2 no docs\n",
      "Search 3 no docs\n",
      "Search 4 no docs\n",
      "Search 5 no docs\n",
      "Search 6 no docs\n",
      "Search 7 no docs\n",
      "Search 8 no docs\n",
      "Search 9 no docs\n",
      "Search 10 no docs\n",
      "Search 11 no docs\n",
      "Search 12 no docs\n",
      "Search 13 no docs\n",
      "Search 14 no docs\n",
      "Search 15 no docs\n",
      "Search 16 no docs\n",
      "Search 17 no docs\n",
      "Search 18 no docs\n",
      "Search 19 no docs\n",
      "Search 20 no docs\n",
      "Search 21 no docs\n",
      "Search 22 no docs\n",
      "Search 23 no docs\n",
      "Search 24 no docs\n",
      "Search 25 no docs\n",
      "Search 26 no docs\n",
      "Search 27 no docs\n",
      "Search 28 no docs\n",
      "Search 29 no docs\n",
      "Search 30 no docs\n",
      "Search 31 no docs\n",
      "Search 32 no docs\n",
      "Search 33 no docs\n",
      "Search 34 no docs\n",
      "Search 35 no docs\n",
      "Search 36 no docs\n",
      "Search 37 no docs\n",
      "Search 38 no docs\n",
      "Search 39 no docs\n",
      "Search 40 no docs\n",
      "Search 41 no docs\n",
      "Search 42 no docs\n",
      "Search 43 no docs\n",
      "Search 44 no docs\n",
      "Search 45 no docs\n",
      "Search 46 no docs\n",
      "Search 47 no docs\n",
      "Search 48 no docs\n",
      "Search 49 no docs\n",
      "Search 50 no docs\n",
      "Search 51 no docs\n",
      "Search 52 no docs\n",
      "Search 53 no docs\n",
      "Search 54 no docs\n",
      "Search 55 no docs\n",
      "Search 56 no docs\n",
      "Search 57 no docs\n",
      "Search 58 no docs\n",
      "Search 59 no docs\n",
      "Search 60 no docs\n",
      "Search 61 no docs\n",
      "Search 62 no docs\n",
      "Search 63 no docs\n",
      "Search 64 no docs\n",
      "Search 65 no docs\n",
      "Search 66 no docs\n",
      "Search 67 no docs\n",
      "Search 68 no docs\n",
      "Search 69 no docs\n",
      "Search 70 no docs\n",
      "Search 71 no docs\n",
      "Search 72 no docs\n",
      "Search 73 no docs\n",
      "Search 74 no docs\n",
      "Search 75 no docs\n",
      "Search 76 no docs\n",
      "Search 77 no docs\n",
      "Search 78 no docs\n",
      "Search 79 no docs\n",
      "Search 80 no docs\n",
      "Search 81 no docs\n",
      "Search 82 no docs\n",
      "Search 83 no docs\n",
      "Search 84 no docs\n",
      "Search 85 no docs\n",
      "Search 86 no docs\n",
      "Search 87 no docs\n",
      "Search 88 no docs\n",
      "Search 89 no docs\n",
      "Search 90 no docs\n",
      "Search 91 no docs\n",
      "Search 92 no docs\n",
      "Search 93 no docs\n",
      "Search 94 no docs\n",
      "Search 95 no docs\n",
      "Search 96 no docs\n",
      "Search 97 no docs\n",
      "Search 98 no docs\n",
      "Search 99 no docs\n",
      "Search 100 no docs\n",
      "Search 101 no docs\n",
      "Search 102 no docs\n",
      "Search 103 no docs\n",
      "Search 104 no docs\n",
      "Search 105 no docs\n",
      "Search 106 no docs\n",
      "Search 107 no docs\n",
      "Search 108 no docs\n",
      "Search 109 no docs\n",
      "Search 110 no docs\n",
      "Search 111 no docs\n",
      "Search 112 no docs\n",
      "Search 113 no docs\n",
      "Search 114 no docs\n",
      "Search 115 no docs\n",
      "Search 116 no docs\n",
      "Search 117 no docs\n",
      "Search 118 no docs\n",
      "Search 119 no docs\n",
      "Search 120 no docs\n",
      "Search 121 no docs\n",
      "Search 122 no docs\n",
      "Search 123 no docs\n",
      "Search 124 no docs\n",
      "Search 125 no docs\n",
      "Search 126 no docs\n",
      "Search 127 no docs\n",
      "Search 128 no docs\n",
      "Search 129 no docs\n",
      "Search 130 no docs\n",
      "Search 131 no docs\n",
      "Search 132 no docs\n",
      "Search 133 no docs\n",
      "Search 134 no docs\n",
      "Search 135 no docs\n",
      "Search 136 no docs\n",
      "Search 137 no docs\n",
      "Search 138 no docs\n",
      "Search 139 no docs\n",
      "Search 140 no docs\n",
      "Search 141 no docs\n",
      "Search 142 no docs\n",
      "Search 143 no docs\n",
      "Search 144 no docs\n",
      "Search 145 no docs\n",
      "Search 146 no docs\n",
      "Search 147 no docs\n",
      "Search 148 no docs\n",
      "Search 149 no docs\n",
      "Search 150 no docs\n",
      "Search 151 no docs\n",
      "Search 152 no docs\n",
      "Search 153 no docs\n",
      "Search 154 no docs\n",
      "Search 155 no docs\n",
      "Search 156 no docs\n",
      "Search 157 no docs\n",
      "Search 158 no docs\n",
      "Search 159 no docs\n",
      "Search 160 no docs\n",
      "Search 161 no docs\n",
      "Search 162 no docs\n",
      "Search 163 no docs\n",
      "Search 164 no docs\n",
      "Search 165 no docs\n",
      "Search 166 no docs\n",
      "Search 167 no docs\n",
      "Search 168 no docs\n",
      "Search 169 no docs\n",
      "Search 170 no docs\n",
      "Search 171 no docs\n",
      "Search 172 no docs\n",
      "Search 173 no docs\n",
      "Search 174 no docs\n",
      "Search 175 no docs\n",
      "Search 176 no docs\n",
      "Search 177 no docs\n",
      "Search 178 no docs\n",
      "Search 179 no docs\n",
      "Search 180 no docs\n",
      "Search 181 no docs\n",
      "Search 182 no docs\n",
      "Search 183 no docs\n",
      "Search 184 no docs\n",
      "Search 185 no docs\n",
      "Search 186 no docs\n",
      "Search 187 no docs\n",
      "Search 188 no docs\n",
      "Search 189 no docs\n",
      "Search 190 no docs\n",
      "Search 191 no docs\n",
      "Search 192 no docs\n",
      "Search 193 no docs\n",
      "Search 194 no docs\n",
      "Search 195 no docs\n",
      "Search 196 no docs\n",
      "Search 197 no docs\n",
      "Search 198 no docs\n",
      "Search 199 no docs\n",
      "Search 200 no docs\n",
      "Search 201 no docs\n",
      "Search 202 no docs\n",
      "Search 203 no docs\n",
      "Search 204 no docs\n",
      "Search 205 no docs\n",
      "Search 206 no docs\n",
      "Search 207 no docs\n",
      "Search 208 no docs\n",
      "Search 209 no docs\n",
      "Search 210 no docs\n",
      "Search 211 no docs\n",
      "Search 212 no docs\n",
      "Search 213 no docs\n",
      "Search 214 no docs\n",
      "Search 215 no docs\n",
      "Search 216 no docs\n",
      "Search 217 no docs\n",
      "Search 218 no docs\n",
      "Search 219 no docs\n",
      "Search 220 no docs\n",
      "Search 221 no docs\n",
      "Search 222 no docs\n",
      "Search 223 no docs\n",
      "Search 224 no docs\n",
      "Search 225 no docs\n",
      "Search 226 no docs\n",
      "Search 227 no docs\n",
      "Search 228 no docs\n",
      "Search 229 no docs\n",
      "Search 230 no docs\n",
      "Search 231 no docs\n",
      "Search 232 no docs\n",
      "Search 233 no docs\n",
      "Search 234 no docs\n",
      "Search 235 no docs\n",
      "Search 236 no docs\n",
      "Search 237 no docs\n",
      "Search 238 no docs\n",
      "Search 239 no docs\n",
      "Search 240 no docs\n",
      "Search 241 no docs\n",
      "Search 242 no docs\n",
      "Search 243 no docs\n",
      "Search 244 no docs\n",
      "Search 245 no docs\n",
      "Search 246 no docs\n",
      "Search 247 no docs\n",
      "Search 248 no docs\n",
      "Search 249 no docs\n",
      "Search 250 no docs\n",
      "Search 251 no docs\n",
      "Search 252 no docs\n",
      "Search 253 no docs\n",
      "Search 254 no docs\n",
      "Search 255 no docs\n",
      "Search 256 no docs\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 59\u001b[0m\n\u001b[1;32m     55\u001b[0m         wait_for_more_sessions(retrain_frequency)\n\u001b[1;32m     56\u001b[0m         latest_sessions \u001b[38;5;241m=\u001b[39m gather_latest_sessions(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransformers dvd\u001b[39m\u001b[38;5;124m\"\u001b[39m, latest_sessions,\n\u001b[1;32m     57\u001b[0m                                                  \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexplore_variant_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, explore_features)\n\u001b[0;32m---> 59\u001b[0m \u001b[43mltr_retraining_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43msessions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[35], line 56\u001b[0m, in \u001b[0;36mltr_retraining_loop\u001b[0;34m(latest_sessions, iterations, retrain_frequency)\u001b[0m\n\u001b[1;32m     51\u001b[0m train_and_upload_model(train,\n\u001b[1;32m     52\u001b[0m                        \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexplore_variant_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     53\u001b[0m                        explore_features)\n\u001b[1;32m     55\u001b[0m wait_for_more_sessions(retrain_frequency)\n\u001b[0;32m---> 56\u001b[0m latest_sessions \u001b[38;5;241m=\u001b[39m \u001b[43mgather_latest_sessions\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtransformers dvd\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatest_sessions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m                                         \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexplore_variant_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexplore_features\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[35], line 15\u001b[0m, in \u001b[0;36mgather_latest_sessions\u001b[0;34m(query, sessions, model_name, features)\u001b[0m\n\u001b[1;32m     13\u001b[0m training_data \u001b[38;5;241m=\u001b[39m generate_training_data(sessions)\n\u001b[1;32m     14\u001b[0m logged_judgments \u001b[38;5;241m=\u001b[39m generate_logged_judgments(training_data, features, model_name)\n\u001b[0;32m---> 15\u001b[0m latest_sessions \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_simulated_exploration_sessions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                                                          \u001b[49m\u001b[43msessions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                                                          \u001b[49m\u001b[43mlogged_judgments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                                                          \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m latest_sessions\n",
      "Cell \u001b[0;32mIn[30], line 12\u001b[0m, in \u001b[0;36mgenerate_simulated_exploration_sessions\u001b[0;34m(query, sessions, logged_judgments, features, n)\u001b[0m\n\u001b[1;32m     10\u001b[0m query_sessions \u001b[38;5;241m=\u001b[39m with_explore_sessions[with_explore_sessions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m query]\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, n):\n\u001b[0;32m---> 12\u001b[0m     explore_doc \u001b[38;5;241m=\u001b[39m \u001b[43mexplore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogged_judgments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m explore_doc:\n\u001b[1;32m     14\u001b[0m         explore_upc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(explore_doc[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupc\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "Cell \u001b[0;32mIn[28], line 5\u001b[0m, in \u001b[0;36mexplore\u001b[0;34m(query, logged_judgments, features)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Explore according to the provided explore vector, select\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m   a random doc from that group.\"\"\"\u001b[39;00m\n\u001b[1;32m      4\u001b[0m feature_names \u001b[38;5;241m=\u001b[39m [f[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m features]\n\u001b[0;32m----> 5\u001b[0m prediction_data \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_expected_improvement\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogged_judgments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m explore_vector \u001b[38;5;241m=\u001b[39m prediction_data\u001b[38;5;241m.\u001b[39mhead()\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m][feature_names]\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m search_for_explore_candidate(explore_vector, query)\n",
      "Cell \u001b[0;32mIn[25], line 4\u001b[0m, in \u001b[0;36mcalculate_expected_improvement\u001b[0;34m(logged_judgments, feature_names, theta)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_expected_improvement\u001b[39m(logged_judgments, feature_names, theta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.6\u001b[39m):\n\u001b[0;32m----> 4\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_prediction_std_dev\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogged_judgments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopportunity\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m (data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredicted_grade\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m-\u001b[39m\n\u001b[1;32m      6\u001b[0m                            logged_judgments[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrade\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mmean() \u001b[38;5;241m-\u001b[39m theta)\n\u001b[1;32m      7\u001b[0m     data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprob_of_improvement\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m      8\u001b[0m         norm\u001b[38;5;241m.\u001b[39mcdf(data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopportunity\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m/\u001b[39m\n\u001b[1;32m      9\u001b[0m                  data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredicted_stddev\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n",
      "Cell \u001b[0;32mIn[23], line 5\u001b[0m, in \u001b[0;36mcalculate_prediction_std_dev\u001b[0;34m(logged_judgments, feature_names)\u001b[0m\n\u001b[1;32m      2\u001b[0m index \u001b[38;5;241m=\u001b[39m pandas\u001b[38;5;241m.\u001b[39mMultiIndex\u001b[38;5;241m.\u001b[39mfrom_product([[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m]] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m4\u001b[39m, names\u001b[38;5;241m=\u001b[39mfeature_names)\n\u001b[1;32m      3\u001b[0m with_prediction \u001b[38;5;241m=\u001b[39m pandas\u001b[38;5;241m.\u001b[39mDataFrame(index\u001b[38;5;241m=\u001b[39mindex)\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[0;32m----> 5\u001b[0m gpr \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_gpr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogged_judgments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m predictions_with_std \u001b[38;5;241m=\u001b[39m gpr\u001b[38;5;241m.\u001b[39mpredict(\n\u001b[1;32m      7\u001b[0m     with_prediction[feature_names], return_std\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m with_prediction[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredicted_grade\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m predictions_with_std[\u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[0;32mIn[21], line 7\u001b[0m, in \u001b[0;36mtrain_gpr\u001b[0;34m(logged_judgments, feature_names)\u001b[0m\n\u001b[1;32m      5\u001b[0m grades \u001b[38;5;241m=\u001b[39m logged_judgments[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrade\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      6\u001b[0m gpr \u001b[38;5;241m=\u001b[39m GaussianProcessRegressor()\n\u001b[0;32m----> 7\u001b[0m \u001b[43mgpr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrades\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m gpr\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/gaussian_process/_gpr.py:237\u001b[0m, in \u001b[0;36mGaussianProcessRegressor.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    236\u001b[0m     dtype, ensure_2d \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 237\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;66;03m# Normalize target value\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalize_y:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    563\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    564\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 565\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1122\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1103\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1104\u001b[0m     )\n\u001b[1;32m   1106\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[1;32m   1107\u001b[0m     X,\n\u001b[1;32m   1108\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1119\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1120\u001b[0m )\n\u001b[0;32m-> 1122\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43m_check_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_numeric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1124\u001b[0m check_consistent_length(X, y)\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1132\u001b[0m, in \u001b[0;36m_check_y\u001b[0;34m(y, multi_output, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1130\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Isolated part of check_X_y dedicated to y validation\"\"\"\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m multi_output:\n\u001b[0;32m-> 1132\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1133\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1134\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1135\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1136\u001b[0m \u001b[43m        \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1137\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1138\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1140\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1141\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1142\u001b[0m     estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:861\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    845\u001b[0m     array \u001b[38;5;241m=\u001b[39m _ensure_sparse_format(\n\u001b[1;32m    846\u001b[0m         array,\n\u001b[1;32m    847\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    853\u001b[0m         input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[1;32m    854\u001b[0m     )\n\u001b[1;32m    855\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;66;03m# If np.array(..) gives ComplexWarning, then we convert the warning\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;66;03m# to an error. This is needed because specifying a non complex\u001b[39;00m\n\u001b[1;32m    858\u001b[0m     \u001b[38;5;66;03m# dtype to the function converts complex to real dtype,\u001b[39;00m\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# thereby passing the test made in the lines following the scope\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# of warnings context manager.\u001b[39;00m\n\u001b[0;32m--> 861\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[1;32m    862\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    863\u001b[0m             warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m, ComplexWarning)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/warnings.py:467\u001b[0m, in \u001b[0;36mcatch_warnings.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_showwarning \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_module\u001b[38;5;241m.\u001b[39mshowwarning\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_showwarnmsg_impl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_module\u001b[38;5;241m.\u001b[39m_showwarnmsg_impl\n\u001b[0;32m--> 467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_record:\n\u001b[1;32m    468\u001b[0m     log \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_module\u001b[38;5;241m.\u001b[39m_showwarnmsg_impl \u001b[38;5;241m=\u001b[39m log\u001b[38;5;241m.\u001b[39mappend\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "random.seed(1234)\n",
    "ltr.delete_feature_store(\"aips_feature_store\")\n",
    "\n",
    "def get_exploit_features():\n",
    "    return [\n",
    "        ltr.generate_fuzzy_query_feature(\"name_fuzzy\", \"name\"),\n",
    "        ltr.generate_query_feature(\"long_description_bm25\", \"long_description\"),\n",
    "        ltr.generate_query_feature(\"short_description_match\", \"short_description\", True)]\n",
    "\n",
    "def gather_latest_sessions(query, sessions, model_name, features):\n",
    "    \"\"\"For the sake of the examples, returns a static list of session data.\n",
    "       In a production environment, this would the most up to date user interactions\"\"\"\n",
    "    training_data = generate_training_data(sessions)\n",
    "    logged_judgments = generate_logged_judgments(training_data, features, model_name)\n",
    "    latest_sessions = generate_simulated_exploration_sessions(query,\n",
    "                                                              sessions,\n",
    "                                                              logged_judgments,\n",
    "                                                              features)\n",
    "    return latest_sessions\n",
    "\n",
    "def is_improvement(evaluation1, evaluation2):\n",
    "    #Model comparison is stubbed out\n",
    "    return True\n",
    "    \n",
    "def wait_for_more_sessions(t):\n",
    "    time.sleep(t)\n",
    "\n",
    "def ltr_retraining_loop(latest_sessions, iterations=sys.maxsize,\n",
    "                        retrain_frequency=60 * 60 * 24):\n",
    "    for i in range(0, iterations):\n",
    "        training_data = generate_training_data(latest_sessions)\n",
    "        train, test = split_training_data(training_data)\n",
    "        if i == 0:\n",
    "            exploit_features = get_exploit_features()\n",
    "            train_and_upload_model(train,\n",
    "                                   \"exploit\",\n",
    "                                   exploit_features)\n",
    "        else:\n",
    "            previous_explore_model_name = f\"explore_variant_{i-1}\"\n",
    "            exploit_model_evaluation = evaluate_model(test, \"exploit\", training_data, log=True)\n",
    "            explore_model_evaluation = evaluate_model(test, previous_explore_model_name, training_data, log=True)\n",
    "            print(f\"Exploit evaluation: {exploit_model_evaluation}\")\n",
    "            print(f\"Explore evaluation: {explore_model_evaluation}\")\n",
    "            if is_improvement(explore_model_evaluation, exploit_model_evaluation):\n",
    "                print(\"Promoting previous explore model\")\n",
    "                train_and_upload_model(train,\n",
    "                                      \"exploit\",\n",
    "                                       explore_features)\n",
    "                \n",
    "        explore_features = get_latest_explore_features()\n",
    "        train_and_upload_model(train,\n",
    "                               f\"explore_variant_{i}\",\n",
    "                               explore_features)\n",
    "        \n",
    "        wait_for_more_sessions(retrain_frequency)\n",
    "        latest_sessions = gather_latest_sessions(\"transformers dvd\", latest_sessions,\n",
    "                                                 f\"explore_variant_{i}\", explore_features)\n",
    "\n",
    "ltr_retraining_loop(sessions, 5, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up next: [Chapter 13: Semantic Search with Dense Vectors](../ch13/1.setting-up-the-outdoors-dataset.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
