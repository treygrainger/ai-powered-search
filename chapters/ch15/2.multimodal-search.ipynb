{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "from aips import get_engine\n",
    "from IPython.display import display, HTML\n",
    "from pyspark.sql import SparkSession\n",
    "import ipywidgets as widgets\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import requests\n",
    "import numpy\n",
    "import torch\n",
    "import clip\n",
    "from io import BytesIO\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "engine = get_engine()\n",
    "spark = SparkSession.builder.appName(\"AIPS\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\n",
      "movies_with_image_embeddings.pickle\n"
     ]
    }
   ],
   "source": [
    "![ ! -d 'tmdb' ] && git clone --depth 1 https://github.com/ai-powered-search/tmdb.git\n",
    "! cd tmdb && git pull\n",
    "! cd tmdb && mkdir -p '../../../data/tmdb/' && tar -xvf movies_with_image_embeddings.tgz -C '../../../data/tmdb/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wiping \"tmdb\" collection\n",
      "Creating \"tmdb\" collection\n",
      "Status: Success\n",
      "Adding LTR QParser for tmdb collection\n",
      "Adding LTR Doc Transformer for tmdb collection\n",
      "../../data/judgments.tgz already exists\n",
      "../../data/movies.tgz already exists\n",
      "Successfully written 65616 documents\n"
     ]
    }
   ],
   "source": [
    "%run ../ch10/1.setup-the-movie-db.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 15.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aips.spark import create_view_from_collection\n",
    "from aips.spark.dataframe import from_sql\n",
    "from pyspark.sql.functions import split, regexp_replace, col\n",
    "\n",
    "def normalize_embedding(embedding):\n",
    "    return numpy.divide(embedding,\n",
    "      numpy.linalg.norm(embedding,axis=0)).tolist()\n",
    "\n",
    "def read(cache_name):\n",
    "    cache_file_name = f\"../../data/tmdb/{cache_name}.pickle\"\n",
    "    with open(cache_file_name, \"rb\") as fd:\n",
    "        return pickle.load(fd)\n",
    "\n",
    "def tmdb_with_embeddings_dataframe():\n",
    "    movies = read(\"movies_with_image_embeddings\")\n",
    "    embeddings = movies[\"image_embeddings\"]\n",
    "    normalized_embeddings = [normalize_embedding(e) for e in embeddings]\n",
    "    movies_dataframe = spark.createDataFrame(\n",
    "        zip(movies[\"movie_ids\"], movies[\"titles\"], \n",
    "            movies[\"image_ids\"], normalized_embeddings),\n",
    "        schema=[\"movie_id\", \"title\", \"image_id\", \"image_embedding\"])\n",
    "    return movies_dataframe\n",
    "\n",
    "def tmdb_lexical_embeddings_dataframe():\n",
    "    lexical_tmdb_collection = engine.get_collection(\"tmdb\")\n",
    "    create_view_from_collection(lexical_tmdb_collection, \"tmdb_lexical\")\n",
    "    embeddings_tmdb_collection = engine.get_collection(\"tmdb_with_embeddings\")\n",
    "    create_view_from_collection(embeddings_tmdb_collection, \"tmdb_with_embeddings\")\n",
    "    \n",
    "    joined_collection_sql = f\"\"\"    \n",
    "    SELECT lexical.id id, embeddings.movie_id movie_id, lexical.title title, lexical.overview overview, embeddings.image_embedding, embeddings.image_id\n",
    "    FROM tmdb_with_embeddings embeddings\n",
    "    INNER JOIN (SELECT DISTINCT image_id from (SELECT movie_id, MIN(image_id) image_id from tmdb_with_embeddings GROUP BY movie_id ORDER BY image_id ASC)) distinct_images on embeddings.image_id = distinct_images.image_id\n",
    "    INNER JOIN tmdb_lexical lexical ON lexical.id = embeddings.movie_id\n",
    "    ORDER by lexical.id asc\n",
    "    \"\"\"\n",
    "    #collection = engine.create_collection(\"tmdb_lexical_plus_embeddings\")\n",
    "    joined_dataframe = from_sql(joined_collection_sql) \n",
    "    joined_dataframe = joined_dataframe.withColumn(\"image_embedding\", split(regexp_replace(col(\"image_embedding\"),\"\\\"\",\"\"), \",\"))\n",
    "    return joined_dataframe\n",
    "    \n",
    "def create_embedding_indexes():\n",
    "    embeddings_dataframe = tmdb_with_embeddings_dataframe()\n",
    "    embeddings_collection = engine.create_collection(\"tmdb_with_embeddings\")\n",
    "    embeddings_collection.write(embeddings_dataframe)\n",
    "    \n",
    "    lexical_embeddings = tmdb_lexical_embeddings_dataframe()\n",
    "    lexical_collection = engine.create_collection(\"tmdb_lexical_plus_embeddings\")\n",
    "    lexical_collection.write(lexical_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wiping \"tmdb_with_embeddings\" collection\n",
      "Creating \"tmdb_with_embeddings\" collection\n",
      "Status: Success\n",
      "Successfully written 7549 documents\n",
      "Wiping \"tmdb_lexical_plus_embeddings\" collection\n",
      "Creating \"tmdb_lexical_plus_embeddings\" collection\n",
      "Status: Success\n",
      "Successfully written 908 documents\n"
     ]
    }
   ],
   "source": [
    "create_embedding_indexes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 15.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(full_path, log=False):   \n",
    "    try:\n",
    "        if full_path.startswith(\"http\"):\n",
    "            response = requests.get(full_path)\n",
    "            image = Image.open(BytesIO(response.content))\n",
    "        else:\n",
    "            image = Image.open(full_path)\n",
    "        if log: print(\"File Found\")\n",
    "        return image\n",
    "    except:\n",
    "        if log: print(f\"No Image Available {full_path}\")\n",
    "        return []\n",
    "\n",
    "def movie_search(query_embedding, limit=8):\n",
    "    collection = engine.get_collection(\"tmdb_with_embeddings\")\n",
    "    request = {\n",
    "        \"query\": query_embedding,\n",
    "        \"query_fields\": [\"image_embedding\"],\n",
    "        \"return_fields\": [\"movie_id\", \"title\", \"image_id\", \"score\"],\n",
    "        \"limit\": limit,\n",
    "        \"quantization_size\": \"FLOAT32\"}\n",
    "    return collection.search(**request)\n",
    "    \n",
    "def encode_text(text, normalize=True):\n",
    "    text = clip.tokenize([text]).to(device)    \n",
    "    text_features = model.encode_text(text)\n",
    "    embedding = text_features.tolist()[0] \n",
    "    if normalize:\n",
    "        embedding = normalize_embedding(embedding)\n",
    "    return embedding\n",
    "    \n",
    "def encode_image(image_file, normalize=True):\n",
    "    image = load_image(image_file)\n",
    "    inputs = preprocess(image).unsqueeze(0).to(device)\n",
    "    embedding = model.encode_image(inputs).tolist()[0]\n",
    "    if normalize:\n",
    "        embedding = normalize_embedding(embedding)\n",
    "    return embedding\n",
    "\n",
    "def encode_text_and_image(text_query, image_file):    \n",
    "    text_embedding = encode_text(text_query, True)\n",
    "    image_embedding = encode_image(image_file, True)  \n",
    "    return numpy.average((normalize_embedding(\n",
    "        [text_embedding, image_embedding])), axis=0).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 15.16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_html(search_results, show_fields=True):\n",
    "    css = \"\"\"\n",
    "      <style type=\"text/css\">\n",
    "        .results { \n",
    "          margin-top: 15px; \n",
    "          display: flex; \n",
    "          flex-wrap: wrap; \n",
    "          justify-content: space-evenly; }\n",
    "        .field { font-size: 24px; position: relative; float: left; }\n",
    "        .title { font-size:32px; font-weight:bold; max-width:450px; word-wrap:break-all; line-height:32px; display: table-cell; vertical-align: bottom;}\n",
    "        .results .result { height: 250px; margin-bottom: 5px; }\n",
    "        .fields {height: 100%; }\n",
    "      </style>\"\"\"\n",
    "    \n",
    "    results_html = \"\"\n",
    "    for movie in search_results[\"docs\"]:\n",
    "        image_file = f\"http://image.tmdb.org/t/p/w780/{movie['image_id']}.jpg\"\n",
    "        movie_link = f\"https://www.themoviedb.org/movie/{movie['movie_id']}\"\n",
    "        img_html = f\"<img title='{movie['title']}' class='result' src='{image_file}'>\"\n",
    "        if show_fields: results_html += f\"<div class='fields'><div class='title' style='height:65px;'>{movie['title']}</div><div class='field'>( score: {movie['score']} )</div>\"\n",
    "        results_html += f\"<div style='clear:left'><a class='title' href='{movie_link}' target='_blank'>{img_html}</a></div>\"\n",
    "        if show_fields: results_html += \"</div>\"\n",
    "    return f\"{css}<div class='results'>{results_html}</div>\"\n",
    "   \n",
    "def display_results(search_results, show_fields=True):    \n",
    "    output = widgets.Output()\n",
    "    with output:\n",
    "        display(HTML(get_html(search_results, show_fields=show_fields))) \n",
    "    display(widgets.HBox(layout=widgets.Layout(justify_content=\"center\")), output)   \n",
    "\n",
    "def search_and_display(text_query=\"\", image_query=None):\n",
    "    if image_query:\n",
    "        if text_query:\n",
    "            query_embedding = encode_text_and_image(text_query, image_query)\n",
    "        else:\n",
    "            query_embedding = encode_image(image_query)\n",
    "    else:\n",
    "        query_embedding = encode_text(text_query)\n",
    "    display_results(movie_search(query_embedding), show_fields=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 15.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bbb92783aa84f0e88b7ffec692cbcf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(layout=Layout(justify_content='center'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08496ae6016e4a8290bcaec550125878",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "search_and_display(text_query=\"singing in the rain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dc27d8788cf44d69907f527c38d77ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(layout=Layout(justify_content='center'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a5097a2ccd4458488e7722e3dd00ef5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "search_and_display(text_query=\"superhero flying\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 15.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f922cbc339e3476fb587db720a86d928",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(layout=Layout(justify_content='center'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "216de976c9384be0936765ccfe4f9df8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "search_and_display(text_query=\"superheroes flying\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 15.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2fb9b1e0c8d43f9a79071c838249181",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(layout=Layout(justify_content='center'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b60b049b55a4abd81f00d4d39f034e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "search_and_display(image_query=\"delorean-query.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 15.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c8b46495e7e4a119cb01af8675bf32c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(layout=Layout(justify_content='center'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "944cce7d35c048abb23e2a547085e826",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "search_and_display(text_query=\"superhero\", image_query=\"delorean-query.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Listing 15.17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lexical Query: \"singin' in the rain\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfc7f7db271b49989247ca2727cc525c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(layout=Layout(justify_content='center'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6b6eb8256914d32a90ece0caf98afec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector Query: [0.048921154115761124, 0.024482925930009714, -0.031112272428365038] ... [-0.007682671294861557, 0.04709745232698743, -0.07469630569368296]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f875a6d49f04128ac350bef59517f45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(layout=Layout(justify_content='center'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56b133f2b0ce4245a718c3bfe8f7c7ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = '\"' + \"singin' in the rain\" + '\"'\n",
    "\n",
    "def base_search():\n",
    "    over_request_limit = 15\n",
    "    return {\n",
    "            \"return_fields\": [\"id\", \"title\", \"id\", \"image_id\", \"movie_id\", \"score\", \"image_embedding\"],\n",
    "            \"limit\": over_request_limit,\n",
    "            \"order_by\": [(\"score\", \"desc\"), (\"title\", \"asc\")]\n",
    "    }\n",
    "\n",
    "def lexical_search_from_text_query(query_text):\n",
    "    return { \"query\": query_text, \n",
    "             \"query_fields\": [\"title\",\"overview\"],\n",
    "             \"default_operator\": \"OR\",\n",
    "             **base_search() }\n",
    "\n",
    "def vector_search_from_embedding(query_embedding):\n",
    "    return { \"query\": query_embedding, \n",
    "             \"query_fields\": [\"image_embedding\"],\n",
    "             \"quantization_size\": \"FLOAT32\",\n",
    "            **base_search() }\n",
    "\n",
    "\n",
    "def display_lexical_search_results(query_text):\n",
    "    collection = engine.get_collection(\"tmdb_lexical_plus_embeddings\")\n",
    "    lexical_search = lexical_search_from_text_query(query_text)\n",
    "    lexical_search_results = collection.search(**lexical_search)\n",
    "    \n",
    "    print(f\"Lexical Query: {query_text}\")\n",
    "    display_results(lexical_search_results)\n",
    "    \n",
    "def display_vector_search_results(query_text):\n",
    "    collection = engine.get_collection(\"tmdb_lexical_plus_embeddings\")\n",
    "    query_embedding = encode_text(query_text)\n",
    "    vector_search = vector_search_from_embedding(query_embedding)\n",
    "    vector_search_results = collection.search(**vector_search)\n",
    "\n",
    "    print(f\"Vector Query: {query_embedding[0:3]} ... {query_embedding[-3:]}\")\n",
    "    display_results(vector_search_results)\n",
    "\n",
    "display_lexical_search_results(query)\n",
    "display_vector_search_results(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 15.17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "self = collection = engine.get_collection(\"tmdb_lexical_plus_embeddings\") #temporary until functions are moved into collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reciprocal_rank_fusion(k, *search_results):\n",
    "    scores = {}\n",
    "    for ranked_docs in search_results:\n",
    "        for rank, doc in enumerate(ranked_docs, 1):\n",
    "            scores[doc[\"id\"]] = scores.get(doc[\"id\"], 0)  + (1.0 / (k + rank))\n",
    "    sorted_scores = dict(sorted(scores.items(), key=lambda x: x[1], reverse=True))\n",
    "    return sorted_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def merge_hybrid_results(hybrid_search_scores, *search_results):\n",
    "    merged_results = {}\n",
    "    for ranked_docs in search_results:\n",
    "        for doc in ranked_docs:\n",
    "            doc_id = doc[\"id\"]\n",
    "            if doc_id in hybrid_search_scores: #only process docs we need\n",
    "                merged_result = merged_results.get(doc_id, {})\n",
    "                merged_results[doc_id] = { **doc, **merged_result }\n",
    "    scored_results = []\n",
    "    for id in hybrid_search_scores:\n",
    "        scored_results.append({ **merged_results[id], \"score\":hybrid_search_scores[id] })\n",
    "\n",
    "    return {\"docs\": scored_results }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reciprocal_rank_fusion_hybrid_search(searches=[], limit=None, algorithm_params={}):\n",
    "    k = 60\n",
    "    if \"k\" in algorithm_params: k = algorithm_params[\"k\"]\n",
    "\n",
    "    search_results = []\n",
    "    for search in searches:\n",
    "        search_results.append(self.search(**search)[\"docs\"])\n",
    "\n",
    "    hybrid_search_scores = reciprocal_rank_fusion(k, *search_results)      \n",
    "    scored_docs = merge_hybrid_results( \\\n",
    "        hybrid_search_scores, *search_results)\n",
    "\n",
    "    if limit and limit < len(scored_docs[\"docs\"]): \n",
    "        scored_docs[\"docs\"] = scored_docs[\"docs\"][:limit] \n",
    "        \n",
    "    return scored_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def hybrid_search(searches=[], limit=None, algorithm=\"rrf\", algorithm_params={}):\n",
    "    hybrid_search_results = None\n",
    "    match algorithm:\n",
    "        case \"rrf\":\n",
    "            hybrid_search_results = reciprocal_rank_fusion_hybrid_search(\n",
    "                                      searches=searches, limit=limit, \n",
    "                                      algorithm_params=algorithm_params)\n",
    "        case \"rerank\":\n",
    "            pass #need rerank implemented on collection.search(...)\n",
    "    return hybrid_search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid Results:\n",
      "  --Lexical Query: \"singin' in the rain\"\n",
      "  --Vector Query: [0.048921154115761124, 0.024482925930009714, -0.031112272428365038] ... [-0.007682671294861557, 0.04709745232698743, -0.07469630569368296]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58d34a201a0b4e02a78f28f089a041bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(layout=Layout(justify_content='center'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a28125c72d224438a2bc14d93b21dda2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def display_hybrid_search_results(text_query, limit=8):\n",
    "    lexical_search = lexical_search_from_text_query(text_query)\n",
    "    vector_search = vector_search_from_embedding(encode_text(text_query))\n",
    "    \n",
    "    hybrid_search_results = hybrid_search([lexical_search, vector_search], limit=limit)\n",
    "    \n",
    "    print(\"Hybrid Results:\")\n",
    "    print(f\"  --Lexical Query: {lexical_search['query']}\")\n",
    "    print(f\"  --Vector Query: {vector_search['query'][0:3]} ... {vector_search['query'][-3:]}\")\n",
    "    display_results(hybrid_search_results)\n",
    "    \n",
    "display_hybrid_search_results(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lexical Query: the hobbit\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27e05eaf07a14f1889e8743bd7f1c99c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(layout=Layout(justify_content='center'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf0eeba883544823ae0660883ffd03d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector Query: [-0.016278795212303375, -0.014356400471339553, 0.02106510739181545] ... [0.03989862136590401, -0.004453835087666024, -0.02110762217111629]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff0e9089fef0400aabc54a775b6da9fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(layout=Layout(justify_content='center'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcc40e94f5714eb88e15ff8aa2eb2777",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid Results:\n",
      "  --Lexical Query: the hobbit\n",
      "  --Vector Query: [-0.016278795212303375, -0.014356400471339553, 0.02106510739181545] ... [0.03989862136590401, -0.004453835087666024, -0.02110762217111629]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d6b9593d9e4462f980517f1722e1ff1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(layout=Layout(justify_content='center'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6101f4c4789c4503aeedcc83468c6a99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query=\"the hobbit\"\n",
    "display_lexical_search_results(query)\n",
    "display_vector_search_results(query)\n",
    "display_hybrid_search_results(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
