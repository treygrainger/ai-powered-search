{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "from aips import get_engine\n",
    "from IPython.display import display, HTML\n",
    "from pyspark.sql import SparkSession]\n",
    "import ipywidgets as widgets\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import requests\n",
    "import numpy\n",
    "import torch\n",
    "import clip\n",
    "from io import BytesIO\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "engine = get_engine()\n",
    "spark = SparkSession.builder.appName(\"AIPS\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\n",
      "movies_with_image_embeddings.pickle\n"
     ]
    }
   ],
   "source": [
    "![ ! -d 'tmdb' ] && git clone --depth 1 https://github.com/ai-powered-search/tmdb.git\n",
    "! cd tmdb && git pull\n",
    "! cd tmdb && mkdir -p '../../../data/tmdb/' && tar -xvf movies_with_image_embeddings.tgz -C '../../../data/tmdb/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wiping \"tmdb\" collection\n",
      "Creating \"tmdb\" collection\n",
      "Status: Success\n",
      "Adding LTR QParser for tmdb collection\n",
      "Adding LTR Doc Transformer for tmdb collection\n",
      "../../data/judgments.tgz already exists\n",
      "../../data/movies.tgz already exists\n",
      "Successfully written 65616 documents\n"
     ]
    }
   ],
   "source": [
    "%run ../ch10/1.setup-the-movie-db.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 15.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aips.spark import create_view_from_collection\n",
    "from aips.spark.dataframe import from_sql\n",
    "\n",
    "def normalize_embedding(embedding):\n",
    "    return numpy.divide(embedding,\n",
    "      numpy.linalg.norm(embedding,axis=0)).tolist()\n",
    "\n",
    "def read(cache_name):\n",
    "    cache_file_name = f\"../../data/tmdb/{cache_name}.pickle\"\n",
    "    with open(cache_file_name, \"rb\") as fd:\n",
    "        return pickle.load(fd)\n",
    "\n",
    "def tmdb_with_embeddings_dataframe():\n",
    "    movies = read(\"movies_with_image_embeddings\")\n",
    "    embeddings = movies[\"image_embeddings\"]\n",
    "    normalized_embeddings = [normalize_embedding(e) for e in embeddings]\n",
    "    movies_dataframe = spark.createDataFrame(\n",
    "        zip(movies[\"movie_ids\"], movies[\"titles\"], \n",
    "            movies[\"image_ids\"], normalized_embeddings),\n",
    "        schema=[\"movie_id\", \"title\", \"image_id\", \"image_embedding\"])\n",
    "    return movies_dataframe\n",
    "\n",
    "def tmdb_lexical_embeddings_dataframe():\n",
    "    lexical_tmdb_collection = engine.get_collection(\"tmdb\")\n",
    "    create_view_from_collection(lexical_tmdb_collection, \"tmdb\")\n",
    "    movies_dataframe = from_sql(\"SELECT id, overview, poster_file, poster_path FROM tmdb\")\n",
    "    embeddings_dataframe = tmdb_with_embeddings_dataframe()\n",
    "    columns = [\"id\", \"title\", \"movie_id\", \"image_embedding\", \n",
    "               \"overview\", \"poster_file\", \"poster_path\"]\n",
    "    joined = movies_dataframe.join(embeddings_dataframe, on=movies_dataframe.id == embeddings_dataframe.movie_id,\n",
    "                          how=\"left\").select(*columns)\n",
    "    return joined\n",
    "    \n",
    "def create_embedding_indexes():\n",
    "    embeddings_dataframe = tmdb_with_embeddings_dataframe()\n",
    "    embeddings_collection = engine.create_collection(\"tmdb_with_embeddings\")\n",
    "    embeddings_collection.write(embeddings_dataframe)\n",
    "    \n",
    "    lexical_embeddings = tmdb_lexical_embeddings_dataframe()\n",
    "    lexical_collection = engine.create_collection(\"tmdb_lexical_plus_embeddings\")\n",
    "    lexical_collection.write(lexical_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wiping \"tmdb_with_embeddings\" collection\n",
      "Creating \"tmdb_with_embeddings\" collection\n",
      "Status: Success\n",
      "Successfully written 7549 documents\n",
      "Wiping \"tmdb_lexical_plus_embeddings\" collection\n",
      "Creating \"tmdb_lexical_plus_embeddings\" collection\n",
      "Status: Success\n",
      "Successfully written 72257 documents\n"
     ]
    }
   ],
   "source": [
    "create_embedding_indexes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 15.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(full_path, log=False):   \n",
    "    try:\n",
    "        if full_path.startswith(\"http\"):\n",
    "            response = requests.get(full_path)\n",
    "            image = Image.open(BytesIO(response.content))\n",
    "        else:\n",
    "            image = Image.open(full_path)\n",
    "        if log: print(\"File Found\")\n",
    "        return image\n",
    "    except:\n",
    "        if log: print(f\"No Image Available {full_path}\")\n",
    "        return []\n",
    "\n",
    "def movie_search(query_embedding, limit=8):\n",
    "    collection = engine.get_collection(\"tmdb_with_embeddings\")\n",
    "    request = {\n",
    "        \"query\": query_embedding,\n",
    "        \"query_fields\": \"image_embedding\",\n",
    "        \"return_fields\": [\"movie_id\", \"title\", \"image_id\", \"score\"],\n",
    "        \"limit\": limit,\n",
    "        \"quantization_size\": \"FLOAT32\"}\n",
    "    return collection.search(**request)\n",
    "    \n",
    "def encode_text(text, normalize=True):\n",
    "    text = clip.tokenize([text]).to(device)    \n",
    "    text_features = model.encode_text(text)\n",
    "    embedding = text_features.tolist()[0] \n",
    "    if normalize:\n",
    "        embedding = normalize_embedding(embedding)\n",
    "    return embedding\n",
    "    \n",
    "def encode_image(image_file, normalize=True):\n",
    "    image = load_image(image_file)\n",
    "    inputs = preprocess(image).unsqueeze(0).to(device)\n",
    "    embedding = model.encode_image(inputs).tolist()[0]\n",
    "    if normalize:\n",
    "        embedding = normalize_embedding(embedding)\n",
    "    return embedding\n",
    "\n",
    "def encode_text_and_image(text_query, image_file):    \n",
    "    text_embedding = encode_text(text_query, False)\n",
    "    image_embedding = encode_image(image_file, False)  \n",
    "    return numpy.average((normalize_embedding(\n",
    "        [text_embedding, image_embedding])), axis=0).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 15.16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_html(search_results):\n",
    "    css = \"\"\"\n",
    "      <style type=\"text/css\">\n",
    "        .results { \n",
    "          margin-top: 15px; \n",
    "          display: flex; \n",
    "          flex-wrap: wrap; \n",
    "          justify-content: space-evenly; }\n",
    "        .results .result { height: 250px; margin-bottom: 5px; }\n",
    "      </style>\"\"\"\n",
    "    \n",
    "    results_html = \"\"\n",
    "    for movie in search_results[\"docs\"]:\n",
    "        image_file = f\"http://image.tmdb.org/t/p/w780/{movie['image_id']}.jpg\"\n",
    "        movie_link = f\"https://www.themoviedb.org/movie/{movie['movie_id']}\"\n",
    "        img_html = f\"<img title='{movie['title']}' class='result' src='{image_file}'>\"\n",
    "        results_html += f\"<div>{movie['title']}<br/>(score: {movie['score']})<br/>\"\n",
    "        results_html += f\"<a href='{movie_link}' target='_blank'>{img_html}</a></div>\"\n",
    "    return f\"{css}<div class='results'>{results_html}</div>\"\n",
    "   \n",
    "def display_results(search_results):    \n",
    "    output = widgets.Output()\n",
    "    with output:\n",
    "        display(HTML(get_html(search_results))) \n",
    "    display(widgets.HBox(layout=widgets.Layout(justify_content=\"center\")), output)   \n",
    "\n",
    "def search_and_display(text_query=\"\", image_query=None):\n",
    "    if image_query:\n",
    "        if text_query:\n",
    "            query_embedding = encode_text_and_image(text_query, image_query)\n",
    "        else:\n",
    "            query_embedding = encode_image(image_query)\n",
    "    else:\n",
    "        query_embedding = encode_text(text_query)\n",
    "    display_results(movie_search(query_embedding))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 15.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c7b3392ef1a4652970720a1c7972d28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(layout=Layout(justify_content='center'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7494900c57b0438fa94dac6f03fac680",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "search_and_display(text_query=\"singing in the rain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da1011fbf3384335a2455b40f031c2f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(layout=Layout(justify_content='center'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2942a785fba4c43994d2b266479f83b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "search_and_display(text_query=\"superhero flying\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 15.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc80d65004874f4082c23422f3685d48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(layout=Layout(justify_content='center'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "375ceb8643b740c2a1c2af2f2c502c00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "search_and_display(text_query=\"superheroes flying\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 15.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac334bc8f7464935b6639f0ce6502f59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(layout=Layout(justify_content='center'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b45bd14a7fb48a69b068826ae9768b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "search_and_display(image_query=\"delorean-query.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 15.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf3b99d6f88a4d27993881abe552b71f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(layout=Layout(justify_content='center'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c3fdda04cd646ec9718f7655c948471",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "search_and_display(text_query=\"superhero\", image_query=\"delorean-query.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Listing 15.17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lexical Query: singing in the rain\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f95afc8ad4749e58081c0271a9d0455",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(layout=Layout(justify_content='center'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc4c368e54a94111bb10a994efb90d93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector Query: [0.04053346811188779, 0.026027961337741636, -0.03153954410778869] ... [-0.0342272163116795, 0.050831037711545714, -0.08007933128422229]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b20522991894ce78df0cb7ba777b0d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(layout=Layout(justify_content='center'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f9466c88d0247fd9d18514d78f4c1bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lexical_collection = engine.get_collection(\"tmdb_lexical_plus_embeddings\")\n",
    "collection = engine.get_collection(\"tmdb_with_embeddings\")\n",
    "\n",
    "query = \"singing in the rain\"\n",
    "limit = 9\n",
    "\n",
    "lexical_query = query\n",
    "lexical_search = {\n",
    "        \"query\": lexical_query,\n",
    "        \"query_fields\": [\"title\", \"overview\"],\n",
    "        \"return_fields\": [\"title\", \"movie_id\", \"image_id\", \"score\", \"overview\"],\n",
    "        \"limit\": limit,\n",
    "        \"query_parser\": \"edismax\"\n",
    "}\n",
    "lexical_search_results = lexical_collection.search(**lexical_search) \n",
    "\n",
    "query_embedding = encode_text(query)\n",
    "vector_search = {\n",
    "        \"query\": query_embedding,\n",
    "        \"query_fields\": \"image_embedding\",\n",
    "        \"return_fields\": [\"movie_id\", \"title\", \"image_id\", \"score\"],\n",
    "        \"limit\": limit,\n",
    "        \"quantization_size\": \"FLOAT32\"}\n",
    "\n",
    "vector_search_results = collection.search(**vector_search)\n",
    "\n",
    "print(f\"Lexical Query: {lexical_query}\")\n",
    "display_results(lexical_search_results)\n",
    "\n",
    "print(f\"Vector Query: {query_embedding[0:3]} ... {query_embedding[-3:]}\")\n",
    "display_results(vector_search_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "self = collection\n",
    "def hybrid_search(lexical_search_args, vector_search_args, algorithm={\"name\": \"rrf\"}, limit=10):\n",
    "    hybrid_search_results = None\n",
    "    match algorithm.get(\"name\"):\n",
    "        case \"rrf\":\n",
    "            k = 60\n",
    "            if algorithm[\"k\"]: k = algorithm[\"k\"]\n",
    "            lexical_search_results = self.search(**lexical_search_args)\n",
    "            vector_search_results = self.search(**vector_search_args)\n",
    "            hybrid_search_scores = reciprocal_rank_fusion(k, \n",
    "                                       vector_search_results, \n",
    "                                       lexical_search_results)\n",
    "            \n",
    "            lexical_fields = {item[\"movie_id\"]: item for item in lexical_search_results[\"docs\"]}\n",
    "            vector_fields = {item[\"movie_id\"]: item for item in vector_search_results[\"docs\"]}\n",
    "            \n",
    "            merged_search_docs = sorted([\n",
    "                dict(lexical_fields[id], score=hybrid_search_scores[id]) \\\n",
    "                if id in lexical_fields \\\n",
    "                else dict(vector_fields[id], score=hybrid_search_scores[id]) \\\n",
    "                for id in hybrid_search_scores], key=lambda x: x[\"score\"], reverse=True)\n",
    "            \n",
    "            #sorted(orig_list, key=lambda x: x.count, reverse=True)\n",
    "\n",
    "            hybrid_search_results = {\"docs\": merged_search_docs}\n",
    "        case \"rerank_lexical_with_vector\":\n",
    "            pass #need rerank implemented on coll\n",
    "    return hybrid_search_results\n",
    "\n",
    "def reciprocal_rank_fusion(k, *search_results):\n",
    "    rrf_scores = Counter()\n",
    "    for ranked_docs in search_results:\n",
    "        rank = 0\n",
    "        for doc in ranked_docs:\n",
    "            rank += 1\n",
    "            rrf_scores[doc[\"movie_id\"]] = rrf_scores[doc[\"movie_id\"]] + (1.0 / (k + rank))\n",
    "    return dict(rrf_scores)\n",
    "    \n",
    "# where\n",
    "# k is a ranking constant\n",
    "# q is a query in the set of queries\n",
    "# d is a document in the result set of q\n",
    "# result(q) is the result set of q\n",
    "# rank( result(q), d ) is d's rank within the result(q) starting from 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'k'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m hybrid_search_results \u001b[38;5;241m=\u001b[39m \u001b[43mhybrid_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlexical_search\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvector_search\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malgorithm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mname\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrrf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLexical Query: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlexical_search[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVector Query: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvector_search[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m3\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ... \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvector_search[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m:]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[30], line 9\u001b[0m, in \u001b[0;36mhybrid_search\u001b[0;34m(lexical_search_args, vector_search_args, algorithm, limit)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mcase\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrrf\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m      8\u001b[0m     k \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m60\u001b[39m\n\u001b[0;32m----> 9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43malgorithm\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mk\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m: k \u001b[38;5;241m=\u001b[39m algorithm[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     10\u001b[0m     lexical_search_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlexical_search_args)\n\u001b[1;32m     11\u001b[0m     vector_search_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mvector_search_args)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'k'"
     ]
    }
   ],
   "source": [
    "hybrid_search_results = hybrid_search(lexical_search, vector_search, algorithm={\"name\": \"rrf\"})\n",
    "print(f\"Lexical Query: {lexical_search['query']}\")\n",
    "print(f\"Vector Query: {vector_search['query'][0:3]} ... {vector_search['query'][-3:]}\")\n",
    "display_results(hybrid_search_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
