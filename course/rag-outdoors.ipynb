{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic Search with Dense Vector Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy\n",
    "import pandas\n",
    "from aips import *\n",
    "from aips.spark import create_view_from_collection, get_spark_session\n",
    "import aips.indexer\n",
    "from aips.data_loaders.outdoors import load_dataframe\n",
    "import sentence_transformers\n",
    "import torch\n",
    "\n",
    "aips.set_engine(\"opensearch\")\n",
    "engine = get_engine()\n",
    "spark = get_spark_session()\n",
    "outdoors_collection = aips.indexer.build_collection(engine, \"outdoors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load and clean the Outdoors dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "transformer = SentenceTransformer(\"roberta-base-nli-stsb-mean-tokens\")\n",
    "cache_name = \"outdoors_semantic_search_embeddings\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(texts, cache_name, ignore_cache=False):\n",
    "    cache_file_name = f\"data/embeddings/{cache_name}.pickle\"\n",
    "    if ignore_cache or not os.path.isfile(cache_file_name):\n",
    "        embeddings = transformer.encode(texts)\n",
    "        os.makedirs(os.path.dirname(cache_file_name), exist_ok=True)\n",
    "        with open(cache_file_name, \"wb\") as fd:\n",
    "            pickle.dump(embeddings, fd)\n",
    "    else:\n",
    "        with open(cache_file_name, \"rb\") as fd:\n",
    "            embeddings = pickle.load(fd)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_similarities(phrases, similarities, name=None):\n",
    "    a_phrases = []\n",
    "    b_phrases = []\n",
    "    scores = []\n",
    "    for a in range(len(similarities) - 1):\n",
    "        for b in range(a + 1, len(similarities)):\n",
    "            a_phrases.append(phrases[a])\n",
    "            b_phrases.append(phrases[b])\n",
    "            scores.append(float(similarities[a][b]))\n",
    "    dataframe = pandas.DataFrame({\"score\": scores,\n",
    "                                  \"phrase a\": a_phrases, \"phrase b\": b_phrases})\n",
    "    dataframe = dataframe.sort_values(by=[\"score\"], ascending=False,\n",
    "                                    ignore_index=True)\n",
    "    dataframe[\"idx\"] = dataframe.index\n",
    "    return dataframe.reindex(columns=[\"idx\", \"score\", \"phrase a\", \"phrase b\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 13.16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdoors_dataframe = load_dataframe(\"data/outdoors/posts.csv\")\n",
    "titles = outdoors_dataframe.rdd.map(lambda x: x.title).collect()\n",
    "titles = list(filter(None, titles))\n",
    "embeddings = get_embeddings(titles, cache_name)\n",
    "\n",
    "print(f\"Number of embeddings: {len(embeddings)}\")\n",
    "print(f\"Dimensions per embedding: {len(embeddings[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the top similarities for the titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_embedding(embedding):\n",
    "    normalized = numpy.divide(embedding, numpy.linalg.norm(embedding))\n",
    "    return list(map(float, normalized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the pairs with the highest dot product scores\n",
    "normalized_embeddings = list(map(normalize_embedding, embeddings))\n",
    "similarities = sentence_transformers.util.dot_score(normalized_embeddings[0:100], normalized_embeddings[0:100])\n",
    "\n",
    "comparisons = rank_similarities(titles, similarities)\n",
    "display(HTML(comparisons[:10].to_html(index=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 13.19\n",
    "Perform vector search utilizing our configured search engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_name = \"all_outdoors_title_embeddings\"\n",
    "\n",
    "def display_results(query, search_results):    \n",
    "    display(HTML(f\"<h4>Results for: <em>{query}</em></h4>\"))\n",
    "    fields = [(d[\"title\"], d[\"body\"], d[\"score\"]) for d in search_results]\n",
    "    for l, b, d in fields:\n",
    "        print(str(int(d * 1000) / 1000), \"|\", l, b)\n",
    "    \n",
    "def index_outdoor_title_embeddings():\n",
    "    create_view_from_collection(engine.get_collection(\"outdoors\"),\n",
    "                                \"outdoors\")\n",
    "    outdoors_dataframe = spark.sql(\"\"\"SELECT id, title, body FROM outdoors\n",
    "                                      WHERE title IS NOT NULL\"\"\")\n",
    "    print(f\"Calculating embeddings for {outdoors_dataframe.count()} docs.\")\n",
    "    ids = outdoors_dataframe.rdd.map(lambda x: x.id).collect()\n",
    "    titles = outdoors_dataframe.rdd.map(lambda x: x.title).collect()\n",
    "    body = outdoors_dataframe.rdd.map(lambda x: x.body).collect()\n",
    "    embeddings = list(map(normalize_embedding,\n",
    "                          get_embeddings(titles, cache_name)))\n",
    "    embeddings_dataframe = spark.createDataFrame(zip(ids, titles, body, embeddings),\n",
    "                                   schema=[\"id\", \"title\", \"body\", \"title_embedding\"])\n",
    "    \n",
    "    collection = engine.create_collection(\"outdoors_with_embeddings\")\n",
    "    print(f\"Writing {embeddings_dataframe.count()} docs to \\\"{collection.name}\\\" collection\")\n",
    "    collection.write(embeddings_dataframe)\n",
    "    return collection\n",
    "        \n",
    "def semantic_search_with_engine(collection, query, limit=10):\n",
    "    query_vector = transformer.encode(query)\n",
    "    query_vector = normalize_embedding(query_vector)\n",
    "    request = {\"query\": query_vector,\n",
    "               \"query_fields\": [\"title_embedding\"],\n",
    "               \"return_fields\": [\"title\", \"body\", \"score\", \"title_embedding\"],\n",
    "               \"quantization_size\": \"FLOAT32\",\n",
    "               \"limit\": limit}\n",
    "    response = collection.search(**request)    \n",
    "    return response[\"docs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_collection = index_outdoor_title_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"what are minimal shoes?\"\n",
    "search_results = semantic_search_with_engine(embeddings_collection, query)\n",
    "display_results(query, search_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actually RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install openai==2.8 markdown2==2.5.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import markdown2\n",
    "import openai\n",
    "gpt = openai.OpenAI(api_key=\"YOUR_KEY_HERE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_prompt(query,search_results,k=5):\n",
    "\n",
    "    context = [f\"\"\"[{idx+1}] {r[\"title\"]}: {r[\"body\"]}\\n\\n\"\"\" for idx,r in enumerate(search_results[:k])]\n",
    "    \n",
    "    return f\"\"\"# Instructions\n",
    "\n",
    "For the given user query and search results, create a helpful summary of the results relevant to the query.\n",
    "    \n",
    "## User Query: {query}\n",
    "\n",
    "## Search Results:\n",
    "{context}\n",
    "\n",
    "## Summary Generation :\n",
    "- Generate a comprehensive summary of the user's query topic using the provided search results.\n",
    "- Use the reference tags (e.g., [1], [2]) to cite specific information from the search results in the summary.\n",
    "- Ensure all information is cross-referenced for consistency. Avoid including contradictory statements.\n",
    "- Prioritize factual accuracy, grounding the summary in the content of the provided search results.\n",
    "- Structure the summary with an introductory overview, detailed exploration of key points, and a concluding statement.\n",
    "\n",
    "Please create a summary following these guidelines to ensure consistency and accuracy.\n",
    "\n",
    "ANSWER:\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def RAG(query,embeddings_collection,k=5):\n",
    "\n",
    "    #Run the search\n",
    "    search_results = semantic_search_with_engine(embeddings_collection, query)\n",
    "\n",
    "    #Get the prompt with the search results\n",
    "    prompt = get_prompt(query,search_results)\n",
    "\n",
    "    #Get the summary from OpenAI with the prompt\n",
    "    gpt_res = gpt.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ],\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    #We get the summary back from GPT.\n",
    "    #print(gpt_res)\n",
    "    summary = gpt_res.choices[0].message.content\n",
    "    summary_html = markdown2.markdown(summary)\n",
    "    \n",
    "    # Show the Summary and Results with some HTML\n",
    "    html_str = f'<div style=\"color:#339;border:1px solid #333;\"><h3>Summary by GPT-4o-mini</h3>{summary_html}</div>'\n",
    "\n",
    "    html_str += f\"<h4>Showing {len(search_results)} Results for <em>{query}</em></h4><ol>\"\n",
    "\n",
    "    for idx,result in enumerate(search_results[:k]):\n",
    "        score = result.get(\"_score\")\n",
    "        title = result.get(\"title\", \"No title\")\n",
    "        body = result.get(\"body\", None)\n",
    "        snippet = body if body else title[:140]+\"...\"\n",
    "        \n",
    "        # Format each result as an HTML list item\n",
    "        html_str += f'<li><b>{title}</b>({score})<br>{snippet}</li>'\n",
    "    \n",
    "    html_str += \"</ol>\"\n",
    "    \n",
    "    # Display the HTML in the Jupyter Notebook\n",
    "    display(HTML(html_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RAG(\"ideal footwear for hikes\",embeddings_collection)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
