{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Misspelling detection and correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: This notebook depends upon the the Retrotech dataset. If you have any issues, please rerun the [Setting up the Retrotech Dataset](../ch4/1.ch4-setting-up-the-retrotech-dataset.ipynb) notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import json\n",
    "from aips import *\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import numpy as np\n",
    "import re\n",
    "nltk.download('stopwords')\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"aips-ch6\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 6.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    \"collation\",\n",
      "    {\n",
      "        \"collationQuery\": \"modern\",\n",
      "        \"hits\": 42,\n",
      "        \"misspellingsAndCorrections\": [\n",
      "            \"moden\",\n",
      "            \"modern\"\n",
      "        ]\n",
      "    },\n",
      "    \"collation\",\n",
      "    {\n",
      "        \"collationQuery\": \"model\",\n",
      "        \"hits\": 40,\n",
      "        \"misspellingsAndCorrections\": [\n",
      "            \"moden\",\n",
      "            \"model\"\n",
      "        ]\n",
      "    },\n",
      "    \"collation\",\n",
      "    {\n",
      "        \"collationQuery\": \"modem\",\n",
      "        \"hits\": 29,\n",
      "        \"misspellingsAndCorrections\": [\n",
      "            \"moden\",\n",
      "            \"modem\"\n",
      "        ]\n",
      "    },\n",
      "    \"collation\",\n",
      "    {\n",
      "        \"collationQuery\": \"modena\",\n",
      "        \"hits\": 1,\n",
      "        \"misspellingsAndCorrections\": [\n",
      "            \"moden\",\n",
      "            \"modena\"\n",
      "        ]\n",
      "    },\n",
      "    \"collation\",\n",
      "    {\n",
      "        \"collationQuery\": \"modes\",\n",
      "        \"hits\": 1,\n",
      "        \"misspellingsAndCorrections\": [\n",
      "            \"moden\",\n",
      "            \"modes\"\n",
      "        ]\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "collection=\"products\"\n",
    "query=\"moden\"\n",
    "\n",
    "request = {\n",
    "    \"params\": {\n",
    "        \"q.op\": \"and\",\n",
    "        \"rows\": 0,\n",
    "        \"indent\": \"on\"\n",
    "    },\n",
    "    \"query\": query,\n",
    "}\n",
    "\n",
    "search_results = requests.post(solr_url + collection + \"/spell\", json=request).json()\n",
    "print(json.dumps(search_results[\"spellcheck\"][\"collations\"], indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the real signals\n",
    "signals_collection=\"signals\"\n",
    "signals_opts={\"zkhost\": \"aips-zk\", \"collection\": signals_collection}\n",
    "df = spark.read.format(\"solr\").options(**signals_opts).load()\n",
    "df.createOrReplaceTempView(\"signals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 6.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create user-searchs table each raw represent one search query.\n",
    "query_signals = spark.sql(\"\"\"\n",
    "  select lower(trim(searches.target)) as keyword, searches.user as user \n",
    "  from signals as searches where searches.type='query'\n",
    "  group by keyword, user\"\"\"\n",
    ").collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Tokenize queries and count word frequencies. \n",
    "Check word frequency distribution quantiles. The quantile will help decide cut off point for potential misspellings and corrections. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 6.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "word_list = defaultdict(int)\n",
    "\n",
    "#for query in signal_sample[\"query_s\"]:\n",
    "for row in query_signals:\n",
    "    query = row[\"keyword\"]\n",
    "    tokenizer = RegexpTokenizer(r'\\w+') \n",
    "    tokens   = tokenizer.tokenize(query)\n",
    "    \n",
    "    for token in tokens:\n",
    "        if token not in stop_words and len(token) > 3 and not token.isdigit():  #drop stopwords and digit only tokens\n",
    "            # and only consider token length > 3, since hard to judge whether a very short token is misspelled or not\n",
    "            word_list[token] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 6.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.1: 5.0,\n",
       " 0.2: 6.0,\n",
       " 0.3: 7.0,\n",
       " 0.4: 8.0,\n",
       " 0.5: 10.0,\n",
       " 0.6: 13.0,\n",
       " 0.7: 18.0,\n",
       " 0.8: 30.0,\n",
       " 0.9: 113.0}"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantiles_to_check = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "quantile_values = np.quantile(np.array(list(word_list.values())), quantiles_to_check)\n",
    "quantiles = dict(zip(quantiles_to_check, quantile_values))\n",
    "quantiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: compute metadata needed for word matching. \n",
    "consider word with low count as misspelling condidates, with high count as correctly spelled candidates. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 6.16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "misspell_candidates = []\n",
    "correction_candidates = []\n",
    "misspell_counts = []\n",
    "correction_counts = []\n",
    "misspell_length = []\n",
    "correction_length = []\n",
    "misspell_initial = []\n",
    "correction_initial = []\n",
    "\n",
    "for k, v in word_list.items():\n",
    "    if v <= quantiles[0.2] : #if v == 1:  # this number based on quantile analysis and the data set, more-likely with user-behvaiour data set to be 1\n",
    "        misspell_candidates.append(k)\n",
    "        misspell_counts.append(v)\n",
    "        misspell_length.append(len(k))\n",
    "        misspell_initial.append(k[0])\n",
    "    if v >= quantiles[0.8]:\n",
    "        correction_candidates.append(k)\n",
    "        correction_counts.append(v)\n",
    "        correction_length.append(len(k))\n",
    "        correction_initial.append(k[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 6.17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "misspell_candidates_df = pd.DataFrame({\n",
    "    \"misspell\":misspell_candidates, \n",
    "    \"misspell_counts\":misspell_counts, \n",
    "    \"misspell_length\":misspell_length,\n",
    "    \"initial\":misspell_initial})\n",
    "\n",
    "correction_candidates_df = pd.DataFrame({\n",
    "    \"correction\":correction_candidates, \n",
    "    \"correction_counts\":correction_counts, \n",
    "    \"correction_length\":correction_length,\n",
    "    \"initial\":correction_initial})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>misspell</th>\n",
       "      <th>misspell_counts</th>\n",
       "      <th>misspell_length</th>\n",
       "      <th>initial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>otterbox iphone cases</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tripod manfrotto</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>singin in the rain</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>canon powershot elph</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fight stick</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>htc evo view</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sx130</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>klipsch image</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tablet case 7</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>borderlands 2</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                misspell  misspell_counts  misspell_length initial\n",
       "0  otterbox iphone cases                6               21       o\n",
       "1       tripod manfrotto                5               16       t\n",
       "2     singin in the rain                6               18       s\n",
       "3   canon powershot elph                6               20       c\n",
       "4            fight stick                5               11       f\n",
       "5           htc evo view                5               12       h\n",
       "6                  sx130                6                5       s\n",
       "7          klipsch image                6               13       k\n",
       "8          tablet case 7                5               13       t\n",
       "9          borderlands 2                5               13       b"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show Results:\n",
    "misspell_candidates_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Find potential matches \n",
    "based on edit distance and whether word initial is the same or not. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lsting 6.18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def good_match(len1, len2, edit_dist): #allow longer words have more edit distance\n",
    "    match = 0\n",
    "    min_length = min(len1, len2)\n",
    "    if min_length < 8:\n",
    "        if edit_dist == 1: match = 1\n",
    "    elif min_length < 11:\n",
    "        if edit_dist <= 2: match = 1\n",
    "    else:\n",
    "        if edit_dist == 3: match = 1\n",
    "    return match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 6.19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_candidates = pd.merge(misspell_candidates_df, correction_candidates_df, on=\"initial\")\n",
    "#join missepll list with correction list based on whether they share the same initials to reduce matching time. \n",
    "matches_candidates[\"edit_dist\"] = matches_candidates.apply(lambda row: nltk.edit_distance(row.misspell,row.correction), axis=1)\n",
    "matches_candidates[\"good_match\"] = matches_candidates.apply(lambda row: good_match(row.misspell_length, row.correction_length, row.edit_dist),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = matches_candidates[matches_candidates[\"good_match\"] == 1].drop([\"initial\",\"good_match\"],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: rank potential matched corrections \n",
    "based on edit distance and correction word frequency. shorter edit distance and higher word count will be prefered. only the top one correction is selected for final matching. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "#matches.sort_values(by=['misspell', 'edit_dist', 'correction_counts'], ascending=[True, True, False])\n",
    "matches_final = matches.groupby('misspell').first().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>misspell</th>\n",
       "      <th>correction</th>\n",
       "      <th>misspell_counts</th>\n",
       "      <th>correction_counts</th>\n",
       "      <th>edit_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>ipad.</td>\n",
       "      <td>ipad</td>\n",
       "      <td>6</td>\n",
       "      <td>7749</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>hp touchpad 32</td>\n",
       "      <td>hp touchpad</td>\n",
       "      <td>5</td>\n",
       "      <td>7144</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>hp toucpad</td>\n",
       "      <td>hp touchpad</td>\n",
       "      <td>6</td>\n",
       "      <td>7144</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>hp tochpad</td>\n",
       "      <td>hp touchpad</td>\n",
       "      <td>6</td>\n",
       "      <td>7144</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>iphone s4</td>\n",
       "      <td>iphone 4s</td>\n",
       "      <td>5</td>\n",
       "      <td>4642</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>iphone4 s</td>\n",
       "      <td>iphone 4s</td>\n",
       "      <td>5</td>\n",
       "      <td>4642</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>iphones 4s</td>\n",
       "      <td>iphone 4s</td>\n",
       "      <td>5</td>\n",
       "      <td>4642</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>touchpaf</td>\n",
       "      <td>touchpad</td>\n",
       "      <td>5</td>\n",
       "      <td>4019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>tochpad</td>\n",
       "      <td>touchpad</td>\n",
       "      <td>6</td>\n",
       "      <td>4019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>toichpad</td>\n",
       "      <td>touchpad</td>\n",
       "      <td>6</td>\n",
       "      <td>4019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>latop</td>\n",
       "      <td>laptop</td>\n",
       "      <td>5</td>\n",
       "      <td>3625</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>laptopa</td>\n",
       "      <td>laptops</td>\n",
       "      <td>6</td>\n",
       "      <td>3435</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>loptops</td>\n",
       "      <td>laptops</td>\n",
       "      <td>5</td>\n",
       "      <td>3435</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>ipods touch</td>\n",
       "      <td>ipod touch</td>\n",
       "      <td>6</td>\n",
       "      <td>2992</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>ipod tuch</td>\n",
       "      <td>ipod touch</td>\n",
       "      <td>6</td>\n",
       "      <td>2992</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>i pod tuch</td>\n",
       "      <td>ipod touch</td>\n",
       "      <td>5</td>\n",
       "      <td>2992</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>ipad  2</td>\n",
       "      <td>ipad 2</td>\n",
       "      <td>6</td>\n",
       "      <td>2807</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>kimdle</td>\n",
       "      <td>kindle</td>\n",
       "      <td>5</td>\n",
       "      <td>2716</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>ipone</td>\n",
       "      <td>iphone</td>\n",
       "      <td>6</td>\n",
       "      <td>2599</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>iphone3</td>\n",
       "      <td>iphone</td>\n",
       "      <td>6</td>\n",
       "      <td>2599</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           misspell   correction  misspell_counts  correction_counts  \\\n",
       "181           ipad.         ipad                6               7749   \n",
       "154  hp touchpad 32  hp touchpad                5               7144   \n",
       "155      hp toucpad  hp touchpad                6               7144   \n",
       "153      hp tochpad  hp touchpad                6               7144   \n",
       "190       iphone s4    iphone 4s                5               4642   \n",
       "193       iphone4 s    iphone 4s                5               4642   \n",
       "194      iphones 4s    iphone 4s                5               4642   \n",
       "412        touchpaf     touchpad                5               4019   \n",
       "406         tochpad     touchpad                6               4019   \n",
       "407        toichpad     touchpad                6               4019   \n",
       "229           latop       laptop                5               3625   \n",
       "228         laptopa      laptops                6               3435   \n",
       "237         loptops      laptops                5               3435   \n",
       "205     ipods touch   ipod touch                6               2992   \n",
       "204       ipod tuch   ipod touch                6               2992   \n",
       "165      i pod tuch   ipod touch                5               2992   \n",
       "173         ipad  2       ipad 2                6               2807   \n",
       "215          kimdle       kindle                5               2716   \n",
       "206           ipone       iphone                6               2599   \n",
       "192         iphone3       iphone                6               2599   \n",
       "\n",
       "     edit_dist  \n",
       "181          1  \n",
       "154          3  \n",
       "155          1  \n",
       "153          1  \n",
       "190          2  \n",
       "193          2  \n",
       "194          1  \n",
       "412          1  \n",
       "406          1  \n",
       "407          1  \n",
       "229          1  \n",
       "228          1  \n",
       "237          1  \n",
       "205          1  \n",
       "204          1  \n",
       "165          2  \n",
       "173          1  \n",
       "215          1  \n",
       "206          1  \n",
       "192          1  "
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show Results:\n",
    "matches_final.sort_values(by=['correction_counts'], ascending=[False])[[\"misspell\", \"correction\", \"misspell_counts\", \"correction_counts\", \"edit_dist\"]].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 6.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Alternative - don't tokenize into individual keywords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "word_list = defaultdict(int)\n",
    "\n",
    "#for query in signal_sample[\"query_s\"]:\n",
    "for row in query_signals:\n",
    "    query = row[\"keyword\"]\n",
    "\n",
    "    if query not in stop_words and len(query) > 3 and not query.isdigit():  \n",
    "        word_list[query] += 1\n",
    "        \n",
    "#run Listing 16.12-16.15 again..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
