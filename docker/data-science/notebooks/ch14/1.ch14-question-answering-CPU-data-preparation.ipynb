{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import html\n",
    "import pandas\n",
    "import pickle\n",
    "import json\n",
    "sys.path.append('..')\n",
    "from aips import *\n",
    "\n",
    "path = \"../data/outdoors/\"\n",
    "outdoors_collection=\"outdoors\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: This notebook depends upon the Outdoors dataset. If you have any issues, please rerun the [Setting up the Outdoors Dataset](../ch13/1.ch13-setting-up-the-outdoors-dataset.ipynb) notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 14.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getQuestions():\n",
    "    qtypes = ['Who','What','When','Where','Why','How']\n",
    "    questions = []\n",
    "    for qt in qtypes:\n",
    "        lq = len(qt)\n",
    "        request = {\n",
    "            \"query\": qt,\n",
    "            \"fields\": [\"id\", \"url\", \"owner_user_id\", \"title\", \"accepted_answer_id\"],\n",
    "            \"params\": {\n",
    "              \"qf\": [\"title\"],\n",
    "              \"fq\": [\"accepted_answer_id:[* TO *]\"],\n",
    "              \"defType\": \"edismax\",\n",
    "              \"rows\":10000\n",
    "            }\n",
    "        }\n",
    "        docs = requests.post(f\"{SOLR_URL}/{outdoors_collection}/select\", json=request).json()[\"response\"][\"docs\"]\n",
    "        questions += [doc for doc in docs if doc['title'][0:lq]==qt] #Only titles starting with a question type\n",
    "    return questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 14.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getContextDataFrame(questions):\n",
    "    contexts={\"id\":[],\"question\":[],\"context\":[],\"url\":[]}\n",
    "    for question in questions:\n",
    "        request = {\n",
    "            \"query\": \"*:*\",\n",
    "            \"fields\": [\"body\"],\n",
    "            \"params\": {\n",
    "              \"fq\": [\"id:\"+str(question[\"accepted_answer_id\"])],\n",
    "              \"defType\": \"edismax\",\n",
    "              \"rows\":1,\n",
    "              \"sort\":\"score desc\"\n",
    "            }\n",
    "        }\n",
    "        docs = requests.post(solr_url + outdoors_collection + \"/select\", json=request).json()[\"response\"][\"docs\"]\n",
    "        contexts[\"id\"].append(question[\"id\"])\n",
    "        contexts[\"url\"].append(question[\"url\"])\n",
    "        contexts[\"question\"].append(question[\"title\"]),\n",
    "        contexts[\"context\"].append(docs[0][\"body\"])\n",
    "    return pandas.DataFrame(contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4410</td>\n",
       "      <td>Who places the anchors that rock climbers use?</td>\n",
       "      <td>There are two distinct styles of free rock cli...</td>\n",
       "      <td>https://outdoors.stackexchange.com/questions/4410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5347</td>\n",
       "      <td>Who places the bolts on rock climbing routes, ...</td>\n",
       "      <td>What you're talking about is Sport climbing. G...</td>\n",
       "      <td>https://outdoors.stackexchange.com/questions/5347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20662</td>\n",
       "      <td>Who gets the bill if you activate a PLB to hel...</td>\n",
       "      <td>Almost always the victim gets the bill, but as...</td>\n",
       "      <td>https://outdoors.stackexchange.com/questions/2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7623</td>\n",
       "      <td>What knot is this one? What are its purposes?</td>\n",
       "      <td>Slip knot It's undoubtably a slip knot that's ...</td>\n",
       "      <td>https://outdoors.stackexchange.com/questions/7623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11587</td>\n",
       "      <td>What sort of crane, and what sort of snake?</td>\n",
       "      <td>To answer the snake part of it, looking at som...</td>\n",
       "      <td>https://outdoors.stackexchange.com/questions/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1660</td>\n",
       "      <td>What is Geocaching?</td>\n",
       "      <td>In short, it's a high-tech treasure hunt. geoc...</td>\n",
       "      <td>https://outdoors.stackexchange.com/questions/1660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>913</td>\n",
       "      <td>What is a buff?</td>\n",
       "      <td>To be honest I was dubious about getting somet...</td>\n",
       "      <td>https://outdoors.stackexchange.com/questions/913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4904</td>\n",
       "      <td>What Rope to purchase?</td>\n",
       "      <td>Short answer: For your first rope, none of the...</td>\n",
       "      <td>https://outdoors.stackexchange.com/questions/4904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6397</td>\n",
       "      <td>What is a bloquers?</td>\n",
       "      <td>I can only assume, that it derives from bloque...</td>\n",
       "      <td>https://outdoors.stackexchange.com/questions/6397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10173</td>\n",
       "      <td>What is a longbow?</td>\n",
       "      <td>The problem with the longbow discussion is tha...</td>\n",
       "      <td>https://outdoors.stackexchange.com/questions/1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                           question  \\\n",
       "0   4410     Who places the anchors that rock climbers use?   \n",
       "1   5347  Who places the bolts on rock climbing routes, ...   \n",
       "2  20662  Who gets the bill if you activate a PLB to hel...   \n",
       "3   7623      What knot is this one? What are its purposes?   \n",
       "4  11587        What sort of crane, and what sort of snake?   \n",
       "5   1660                                What is Geocaching?   \n",
       "6    913                                    What is a buff?   \n",
       "7   4904                             What Rope to purchase?   \n",
       "8   6397                                What is a bloquers?   \n",
       "9  10173                                 What is a longbow?   \n",
       "\n",
       "                                             context  \\\n",
       "0  There are two distinct styles of free rock cli...   \n",
       "1  What you're talking about is Sport climbing. G...   \n",
       "2  Almost always the victim gets the bill, but as...   \n",
       "3  Slip knot It's undoubtably a slip knot that's ...   \n",
       "4  To answer the snake part of it, looking at som...   \n",
       "5  In short, it's a high-tech treasure hunt. geoc...   \n",
       "6  To be honest I was dubious about getting somet...   \n",
       "7  Short answer: For your first rope, none of the...   \n",
       "8  I can only assume, that it derives from bloque...   \n",
       "9  The problem with the longbow discussion is tha...   \n",
       "\n",
       "                                                 url  \n",
       "0  https://outdoors.stackexchange.com/questions/4410  \n",
       "1  https://outdoors.stackexchange.com/questions/5347  \n",
       "2  https://outdoors.stackexchange.com/questions/2...  \n",
       "3  https://outdoors.stackexchange.com/questions/7623  \n",
       "4  https://outdoors.stackexchange.com/questions/1...  \n",
       "5  https://outdoors.stackexchange.com/questions/1660  \n",
       "6   https://outdoors.stackexchange.com/questions/913  \n",
       "7  https://outdoors.stackexchange.com/questions/4904  \n",
       "8  https://outdoors.stackexchange.com/questions/6397  \n",
       "9  https://outdoors.stackexchange.com/questions/1...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions = getQuestions()\n",
    "contexts = getContextDataFrame(questions)\n",
    "contexts[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts.to_csv(path+'question-answer-seed-contexts.csv',index=False)\n",
    "#contexts = pandas.read_csv(path+'data/question-answer-seed-contexts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 14.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline\n",
    "import tqdm\n",
    "\n",
    "model_name = 'deepset/roberta-base-squad2'\n",
    "pipeline_type = 'question-answering'\n",
    "\n",
    "device=-1 #CPU\n",
    "#device=0 #<-- Uncomment to use GPU, if you are running in Google Colab\n",
    "\n",
    "def answerQuestions(contexts,k=10):\n",
    "    nlp = pipeline(pipeline_type, model=model_name, tokenizer=model_name, device=device)\n",
    "    guesses = []\n",
    "    for idx,row in tqdm.tqdm(contexts[0:k].iterrows(),total=k):\n",
    "        result = nlp({\"question\":row[\"question\"],\"context\":row[\"context\"]})\n",
    "        guesses.append(result)\n",
    "    return guesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1d1453293b940cfb57ac7c7203c4ae7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "104450f6ffca40988175bc81882cf10f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/496M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f03b1bd6fd39489f965b55c7faeff407",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a239b889dadd48d6ad444274ddde175f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dc63016188643c8ad149d2f0826ec84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/772 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db1c5705cdd64866bbcd4cbb7f64c295",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/79.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1662 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/transformers/pipelines/question_answering.py:315: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  fw_args = {k: torch.tensor(v, device=self.device) for (k, v) in fw_args.items()}\n",
      "100%|██████████| 1662/1662 [09:04<00:00,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 0.2789272665977478, 'start': 474, 'end': 516, 'answer': 'a local enthusiast or group of enthusiasts'}, {'score': 0.2008480429649353, 'start': 81, 'end': 117, 'answer': 'the person who is creating the climb'}, {'score': 0.018631737679243088, 'start': 14, 'end': 24, 'answer': 'the victim'}, {'score': 0.22231696546077728, 'start': 29, 'end': 38, 'answer': 'slip knot'}, {'score': 0.0005512479692697525, 'start': 1255, 'end': 1262, 'answer': 'aquatic'}, {'score': 0.3749971091747284, 'start': 15, 'end': 40, 'answer': 'a high-tech treasure hunt'}, {'score': 0.5637548565864563, 'start': 192, 'end': 232, 'answer': 'a tube of lightweight, stretchy material'}, {'score': 0.1109151840209961, 'start': 125, 'end': 154, 'answer': 'the cheapest one of the three'}, {'score': 0.8051744699478149, 'start': 68, 'end': 76, 'answer': 'blocking'}, {'score': 0.24700796604156494, 'start': 227, 'end': 265, 'answer': 'the traditional longbow made from wood'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nSome weights of RobertaModel were not initialized from the model checkpoint at deepset/roberta-base-squad2 and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\\n100%|██████████| 1662/1662 [43:19<00:00,  1.56s/it] \\n\\n[{'score': 0.2776225209236145, 'start': 474, 'end': 517, 'answer': 'a local enthusiast or group of enthusiasts.'}, {'score': 0.1954791247844696, 'start': 81, 'end': 118, 'answer': 'the person who is creating the climb.'}, {'score': 0.024139929562807083, 'start': 14, 'end': 24, 'answer': 'the victim'}, {'score': 0.3299234211444855, 'start': 29, 'end': 38, 'answer': 'slip knot'}, {'score': 0.0005422658286988735, 'start': 1255, 'end': 1262, 'answer': 'aquatic'}, {'score': 0.37733304500579834, 'start': 15, 'end': 41, 'answer': 'a high-tech treasure hunt.'}, {'score': 0.5653401613235474, 'start': 192, 'end': 233, 'answer': 'a tube of lightweight, stretchy material.'}, {'score': 0.10057392716407776, 'start': 125, 'end': 155, 'answer': 'the cheapest one of the three,'}, {'score': 0.7781326174736023, 'start': 68, 'end': 77, 'answer': 'blocking.'}, {'score': 0.2520507276058197, 'start': 227, 'end': 266, 'answer': 'the traditional longbow made from wood,'}]\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guesses = answerQuestions(contexts,k=len(contexts))\n",
    "contexts[\"answers\"] = guesses\n",
    "print(guesses[0:10])\n",
    "\"\"\"\n",
    "Some weights of RobertaModel were not initialized from the model checkpoint at deepset/roberta-base-squad2 and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
    "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
    "100%|██████████| 1662/1662 [43:19<00:00,  1.56s/it] \n",
    "\n",
    "[{'score': 0.2776225209236145, 'start': 474, 'end': 517, 'answer': 'a local enthusiast or group of enthusiasts.'}, {'score': 0.1954791247844696, 'start': 81, 'end': 118, 'answer': 'the person who is creating the climb.'}, {'score': 0.024139929562807083, 'start': 14, 'end': 24, 'answer': 'the victim'}, {'score': 0.3299234211444855, 'start': 29, 'end': 38, 'answer': 'slip knot'}, {'score': 0.0005422658286988735, 'start': 1255, 'end': 1262, 'answer': 'aquatic'}, {'score': 0.37733304500579834, 'start': 15, 'end': 41, 'answer': 'a high-tech treasure hunt.'}, {'score': 0.5653401613235474, 'start': 192, 'end': 233, 'answer': 'a tube of lightweight, stretchy material.'}, {'score': 0.10057392716407776, 'start': 125, 'end': 155, 'answer': 'the cheapest one of the three,'}, {'score': 0.7781326174736023, 'start': 68, 'end': 77, 'answer': 'blocking.'}, {'score': 0.2520507276058197, 'start': 227, 'end': 266, 'answer': 'the traditional longbow made from wood,'}]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts.to_csv(path+'question-answer-squad2-guesses.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 14.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Manually labeling data**\n",
    "*The above csv file (data/question-answer-squad2-guesses.csv) is used as a raw first pass at attempting to answer the questions.  This is then used with human-in-the-loop manual correction and labelling of the data.  There is no python code that can do this for you.  The data MUST be labelled by an intelligent person with an understanding of the domain.  All further listings will use the 'golden set' - the manually corrected answer file, and not the guesses that were generated above.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'url', 'title', 'question', 'context', 'answers', '__index_level_0__'],\n",
       "        num_rows: 125\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'url', 'title', 'question', 'context', 'answers', '__index_level_0__'],\n",
       "        num_rows: 32\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'url', 'title', 'question', 'context', 'answers', '__index_level_0__'],\n",
       "        num_rows: 10\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "def getTrainingData(filename):\n",
    "    golden_answers = pandas.read_csv(filename)\n",
    "    golden_answers[\"class\"] = golden_answers[\"class\"].fillna(-2).astype(int)\n",
    "    validated=golden_answers[golden_answers[\"class\"]>-1]\n",
    "    \n",
    "    table={\"id\":[],\"url\":[],\"title\":[],\"question\":[],\"context\":[],\"answers\":[]}\n",
    "    \n",
    "    for idx,row in validated.iterrows():\n",
    "        answers = row[\"gold\"].split('|')\n",
    "        starts = []\n",
    "        notfound = False\n",
    "        for i in range(len(answers)):\n",
    "            found = row[\"context\"].find(answers[i])\n",
    "            starts.append(found)\n",
    "            if(found<0):\n",
    "                notfound = True\n",
    "        if not notfound:\n",
    "            table[\"id\"].append(row[\"id\"])\n",
    "            table[\"url\"].append(row[\"url\"])\n",
    "            table[\"title\"].append(row[\"question\"])\n",
    "            table[\"question\"].append(row[\"question\"])\n",
    "            table[\"context\"].append(row[\"context\"])\n",
    "            table[\"answers\"].append({\n",
    "                \"text\":answers,\n",
    "                \"answer_start\":starts\n",
    "            })\n",
    "    df = pandas.DataFrame(table).sample(frac=1)\n",
    "    train_split = int(len(df)*0.75)\n",
    "    eval_split = int((len(df) - train_split)/1.25) + train_split - 1\n",
    "    train_dataset = datasets.Dataset.from_pandas(df[:train_split])\n",
    "    test_dataset = datasets.Dataset.from_pandas(df[train_split:eval_split])\n",
    "    validation_dataset = datasets.Dataset.from_pandas(df[eval_split:])\n",
    "    datadict = datasets.DatasetDict({'train':train_dataset,'test':test_dataset,'validation':validation_dataset})\n",
    "    return datadict\n",
    "\n",
    "#This golden answers file was labeled by me (Max Irwin).\n",
    "#It took about 2-3 hours to label 200 question/answer rows\n",
    "#Doing so will give you a deeper appreciation for the difficulty of the NLP task.\n",
    "#I *highly* encourage you to label even more documents, and re-run the fine-tuning tasks coming up.\n",
    "datadict = getTrainingData(path+'outdoors_golden_answers_20210130.csv')\n",
    "datadict.save_to_disk(path+'question-answering-training-set')\n",
    "datadict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
