{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load pointwise training set\n",
    "\n",
    "Load the dataset generated [from the previous section](http://localhost:8888/notebooks/ch10/3.ch10-pairwise-transform.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointwise_predictors = np.load('data/pointwise_predictors.npy')\n",
    "feature_data = np.load('data/feature_data.npy')\n",
    "\n",
    "std_devs = feature_data[-1]\n",
    "means = feature_data[-2]\n",
    "pointwise_features = feature_data[:-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 10.16\n",
    "\n",
    "Train the model with the fully transformed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "model = svm.LinearSVC(max_iter=10000, verbose=1)\n",
    "model.fit(pointwise_features, pointwise_predictors)\n",
    "model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features for some other movies..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you wanted to confirm Wrath of Khans features\n",
    "import requests\n",
    "\n",
    "logging_solr_query = {\n",
    "    \"fl\": \"id,title,[features store=movies efi.keywords=\\\"wrath of khan\\\"]\",\n",
    "    'q': \"id:154\", #social network graded documents\n",
    "    'rows': 10,\n",
    "    'wt': 'json'  \n",
    "}\n",
    "\n",
    "resp = requests.post('http://aips-solr:8983/solr/tmdb/select',\n",
    "                     data=logging_solr_query)\n",
    "\n",
    "# Features Solr returns\n",
    "# Wrath of Khan\n",
    "wok_features = [5.9217176, 3.401492, 1982.0]\n",
    "# Search For Spock\n",
    "spock_features = [0.0,0.0,1984.0]\n",
    "\n",
    "# Wrath of Khan\n",
    "normed_wok_features = [0,0,0]\n",
    "for idx, f in enumerate(wok_features):\n",
    "    normed_wok_features[idx] = (f - means[idx]) / std_devs[idx]\n",
    "\n",
    "normed_spock_features = [0,0,0]\n",
    "for idx, f in enumerate(spock_features):\n",
    "    normed_spock_features[idx] = (f - means[idx]) / std_devs[idx]\n",
    "    \n",
    "normed_spock_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score a single document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_one(features, model):\n",
    "    \"\"\" Stores one document (represented as feature array)\n",
    "        using the provided model \"\"\"\n",
    "    score = 0.0\n",
    "    print(\"Feature * Weight\")\n",
    "    for idx, f in enumerate(features):\n",
    "        this_coef = np.asscalar(model.coef_[0][idx])\n",
    "        score += f * this_coef\n",
    "\n",
    "        # Explain for this feature\n",
    "        print(\" {:1.5f} * {:1.5f} \".format(f, this_coef))\n",
    "        if (idx < len(features) - 1):\n",
    "            print(\"+\")\n",
    "    \n",
    "    print('= %s' % score)\n",
    "    \n",
    "    return score\n",
    "\n",
    "\n",
    "score_one(normed_wok_features, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
