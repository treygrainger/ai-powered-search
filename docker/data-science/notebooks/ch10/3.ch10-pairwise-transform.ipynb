{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from ltr.client.solr_client import SolrClient\n",
    "\n",
    "client = SolrClient(host='http://aips-solr:8983/solr')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recreate last section\n",
    "\n",
    "Rebuild everything from last section we'll need to work with the full training set\n",
    "\n",
    "Start by making sure the feature set is installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "requests.delete('http://aips-solr:8983/solr/tmdb/schema/feature-store/movies')\n",
    "\n",
    "import requests\n",
    "\n",
    "feature_set = [\n",
    "    {\n",
    "      \"name\" : \"title_bm25\",\n",
    "      \"store\": \"movies\",\n",
    "      \"class\" : \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "      \"params\" : { #q=title:({$keywords})\n",
    "        \"q\" : \"title:(${keywords})\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"name\" : \"overview_bm25\",\n",
    "      \"store\": \"movies\",\n",
    "      \"class\" : \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "      \"params\" : {\n",
    "        \"q\" : \"overview:(${keywords})\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"name\" : \"release_year\",\n",
    "      \"store\": \"movies\",\n",
    "      \"class\" : \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "      \"params\" : {\n",
    "        \"q\" : \"{!func}release_year\"\n",
    "}}]\n",
    "\n",
    "resp = requests.put('http://aips-solr:8983/solr/tmdb/schema/feature-store',\n",
    "                    json=feature_set)\n",
    "resp.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log features\n",
    "\n",
    "Log the full training set of ~100 movie queries, each with ~40 graded documents. Save judgment list with features logged as `logged_judgments`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltr.log import FeatureLogger\n",
    "from ltr.judgments import judgments_open\n",
    "from itertools import groupby\n",
    "from ltr import download\n",
    "\n",
    "judgments='http://es-learn-to-rank.labs.o19s.com/ai_pow_search_judgments.txt'\n",
    "download([judgments], dest='data/')\n",
    "\n",
    "ftr_logger=FeatureLogger(client, index='tmdb', feature_set='movies')\n",
    "\n",
    "with judgments_open('data/ai_pow_search_judgments.txt') as judgment_list:\n",
    "    for qid, query_judgments in groupby(judgment_list, key=lambda j: j.qid):\n",
    "        ftr_logger.log_for_qid(judgments=query_judgments, \n",
    "                               qid=qid,\n",
    "                               keywords=judgment_list.keywords(qid))\n",
    "\n",
    "logged_judgments = ftr_logger.logged\n",
    "\n",
    "# Now should have lots of judgments with title_bm25, overview_bm25, and release_year \n",
    "# logged out\n",
    "logged_judgments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 10.7 - Plot logged features\n",
    "\n",
    "This data set also has queries `star wars` and `social network` let's see what those look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltr.plots import plot_judgments\n",
    "\n",
    "plot_judgments(qids=[11,40], focus=[11,40], \n",
    "               xlabel=\"Title BM25\",\n",
    "               ylabel=\"Overview BM25\",\n",
    "               title_prepend=\"Logged features for queries:\",\n",
    "               judg_list=ftr_logger.logged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Normalization Function (omitted from book)\n",
    "\n",
    "As we describe in the book, SVMs are sensitive to the range of the underlying data. They work best with normalized features, which we do here.\n",
    "\n",
    "This function computes the mean and standard deviation of all 3 of our features, then scales each feature value accordingly so that feature values at the mean are mapped to 0. And +1 corresponds to 1 std deviation above the mean. -1 1 standard deviation below, etc\n",
    "\n",
    "We capture the mean and standard deviation of each feature for later work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltr.judgments import Judgment\n",
    "\n",
    "def normalize_features(logged_judgments):\n",
    "    all_features = []\n",
    "    means = [0,0,0]\n",
    "    for judgment in logged_judgments:\n",
    "        for idx, f in enumerate(judgment.features):\n",
    "            means[idx] += f\n",
    "        all_features.append(judgment.features)\n",
    "    \n",
    "    for i in range(len(means)):\n",
    "        means[i] /= len(logged_judgments)\n",
    "      \n",
    "    std_devs = [0.0, 0.0, 0.0]\n",
    "    for judgment in logged_judgments:\n",
    "        for idx, f in enumerate(judgment.features):\n",
    "            std_devs[idx] += (f - means[idx])**2\n",
    "            \n",
    "    from math import sqrt\n",
    "    for i in range(len(std_devs)):\n",
    "        std_devs[i] /= len(logged_judgments)\n",
    "        std_devs[i] = sqrt(std_devs[i])\n",
    "        \n",
    "    # Normalize!\n",
    "    normed_judgments = []\n",
    "    for judgment in logged_judgments:\n",
    "        normed_features = [0.0] * len(judgment.features)\n",
    "        for idx, f in enumerate(judgment.features):\n",
    "            normed = (f - means[idx]) / std_devs[idx]\n",
    "            normed_features[idx] = normed\n",
    "        normed_judgment=Judgment(qid=judgment.qid,\n",
    "                                 keywords=judgment.keywords,\n",
    "                                 doc_id=judgment.doc_id,\n",
    "                                 grade=judgment.grade,\n",
    "                                 features=normed_features)\n",
    "        normed_judgment.old_features=judgment.features\n",
    "        normed_judgments.append(normed_judgment)\n",
    "\n",
    "    return means, std_devs, normed_judgments\n",
    "\n",
    "means, std_devs, normed_judgments = normalize_features(ftr_logger.logged)\n",
    "\n",
    "normed_judgments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 10.11 - Normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the normalization, and inspect the difference between of \"The Social Network\" between raw/logged and normalized feature values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means, std_devs, normed_judgments = normalize_features(logged_judgments)\n",
    "\n",
    "logged_judgments[360], normed_judgments[360]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figures 10.8-10.11\n",
    "\n",
    "Examine the normalized judgments now, in preperation for transforming them with SVMRank's pair-wise transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltr.plots import plot_judgments\n",
    "\n",
    "plot_judgments(qids=[11,40], \n",
    "               xlabel=\"Title BM25 Std Devs\",\n",
    "               ylabel=\"Overview BM25 Std Devs\",\n",
    "               title_prepend=\"Normalized features for queries:\",\n",
    "               judg_list=normed_judgments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Listing 10.11 (Python Equivelant)\n",
    "\n",
    "We put psuedocode in the book, but here we show the equivelant Python code. This code also transforms the data to a numpy array of predictors and features for later model training with an SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ltr.judgments import judgments_from_file, judgments_to_nparray\n",
    "\n",
    "def pairwise_transform(normed_judgments):\n",
    "        \n",
    "    from itertools import groupby\n",
    "    pointwise_predictors = []\n",
    "    pointwise_features = []\n",
    "    \n",
    "    # For each query's judgments\n",
    "    for qid, query_judgments in groupby(normed_judgments, key=lambda j: j.qid):\n",
    "\n",
    "        # Annoying issue consuming python iterators, we ensure we have two\n",
    "        # full copies of each query's judgments\n",
    "        query_judgments_copy_1 = list(query_judgments) \n",
    "        query_judgments_copy_2 = list(query_judgments_copy_1)\n",
    "\n",
    "        # Examine every judgment combo for this query, \n",
    "        # if they're different, store the pairwise difference:\n",
    "        # +1 if judgment1 more relevant\n",
    "        # -1 if judgment2 more relevant\n",
    "        for judgment1 in query_judgments_copy_1:\n",
    "            for judgment2 in query_judgments_copy_2:\n",
    "                \n",
    "                j1_features=np.array(judgment1.features)\n",
    "                j2_features=np.array(judgment2.features)\n",
    "                \n",
    "                if judgment1.grade > judgment2.grade:\n",
    "                    pointwise_predictors.append(+1)\n",
    "                    pointwise_features.append(j1_features-j2_features)\n",
    "                elif judgment1.grade < judgment2.grade:\n",
    "                    pointwise_predictors.append(-1)\n",
    "                    pointwise_features.append(j1_features-j2_features)\n",
    "\n",
    "    return np.array(pointwise_features), np.array(pointwise_predictors)\n",
    "\n",
    "pointwise_features, pointwise_predictors = pairwise_transform(normed_judgments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 10.9\n",
    "\n",
    "Finally, we have the full plot training set showing pair-wise differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltr.plots import plot_pairwise_data\n",
    "\n",
    "# Filter down to a judgment list of our two fav queries \n",
    "# out of the normalized data\n",
    "just_star_wars_social_network = []\n",
    "for j in normed_judgments:\n",
    "    if j.qid == 11 or j.qid == 40:\n",
    "        just_star_wars_social_network.append(j)\n",
    "\n",
    "# Pairwise transform just these two, and plot\n",
    "features, predictors = pairwise_transform(just_star_wars_social_network)\n",
    "plot_pairwise_data(features, predictors,\n",
    "                   xlabel=\"Title BM25 (Delta Std Devs)\",\n",
    "                   ylabel=\"Overview BM25 (Delta Std Devs)\",\n",
    "                   title=\"Pairwise Differences, just Star Wars, Social Network\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 10.14 \n",
    "\n",
    "Full dataset pairwise differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltr.plots import plot_pairwise_data\n",
    "\n",
    "plot_pairwise_data(pointwise_features, pointwise_predictors,\n",
    "                   xlabel=\"Title BM25 (Delta Std Devs)\",\n",
    "                   ylabel=\"Overview BM25 (Delta Std Devs)\",\n",
    "                   title=\"All Relevance Pairwise Differences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/feature_data.npy', 'wb') as f:\n",
    "    feature_data = np.append(pointwise_features, [means, std_devs] )\n",
    "    rows=feature_data.shape[0]//3    \n",
    "    cols=3\n",
    "    feature_data = feature_data.reshape((rows,cols))\n",
    "    \n",
    "    np.save(f, feature_data)\n",
    "    print(feature_data.shape)\n",
    "    \n",
    "with open('data/pointwise_predictors.npy', 'wb') as f:\n",
    "    np.save(f, pointwise_predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 10.16\n",
    "\n",
    "Train the model with the fully transformed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "model = svm.LinearSVC(max_iter=10000, verbose=1)\n",
    "model.fit(pointwise_features, pointwise_predictors)\n",
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
