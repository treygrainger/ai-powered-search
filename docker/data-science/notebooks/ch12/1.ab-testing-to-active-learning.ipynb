{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A/B Testing Simulation to Active Learning\n",
    "\n",
    "In this notebook, users have a hidden preference for a single query. We use this to explore A/B testing to see whether a given LTR model actually gives the users what they want.\n",
    "\n",
    "Then we ask, much like in real life, how can we learn what the user _actually_ wants? We employe active learning to try to escape the 'echo chamber' of presentation bias we learned about at the end of chapter 11. After all users can't click on results that never show up in their search results!\n",
    "\n",
    "## ðŸš¨ We're putting it all together in this chapter\n",
    "\n",
    "As this chapter puts together everything from chapters 10 and 11, much of the setup code below wraps up a lot of chapter 11 and 10 into a 'single function' so we can very easily run through the steps in 'one liners'\n",
    "\n",
    "### Getting training data (Ch 11)\n",
    "\n",
    "Chapter 11 is all about turning raw clickstream data into search training data (aka judgments). This involves overcoming biases in how users percieve search. But here we put that in one function call `sessions_to_sdbn`.\n",
    "\n",
    "### Train a model (Ch 10)\n",
    "\n",
    "Chapter 10 is about training an LTR model, including interacting with Solr to extract features, how a ranking model works, how to train a model, and how to perform a good test/train split for search. But here we similarly wrap that up into a handful of function calls, `test_train_split`, `ranksvm_ltr`, and `eval_model`.\n",
    "\n",
    "*long story short, if you see a reference to chapter 10 and 11, it's probably omited from chapter 12* - don't expect it to be covered in chapter 12 extensively.\n",
    "\n",
    "\n",
    "## Setup - gather some sessions (omitted)\n",
    "\n",
    "To get started, we first load a set of simulated search sessions for all queries. \n",
    "\n",
    "Much of this setup is omitted from the chapter. This first part is just loading and synthesizing a bunch of clickstream sessions, like we used in chapter 11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random; random.seed(0)\n",
    "import glob\n",
    "\n",
    "import requests\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from aips import *\n",
    "from ltr.client.solr_client import SolrClient\n",
    "engine = get_engine()\n",
    "client = SolrClient(solr_base=SOLR_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_sessions():\n",
    "    sessions = pd.concat([pd.read_csv(f, compression='gzip')\n",
    "                          for f in glob.glob('ch12/retrotech/*_sessions.gz')])\n",
    "    return sessions.rename(columns={'clicked_doc_id': 'doc_id'})\n",
    "\n",
    "sessions = all_sessions()\n",
    "sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions[\"query\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Part 2 - Add some more query sessions (omitted)\n",
    "\n",
    "Here we duplicate the simulated queries from above, but we flip a handful of the clicks. This just fills out our data a bit more, gives a bit more data to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "\n",
    "def copy_query_sessions(sessions, src_query, dest_query, flip=False):\n",
    "    new_sessions = sessions[sessions[\"query\"] == src_query].copy()  \n",
    "    new_sessions[\"draw\"] = np.random.rand(len(new_sessions), 1)\n",
    "    new_sessions.loc[new_sessions[\"clicked\"] & (new_sessions[\"draw\"] < 0.04), \"clicked\"] = False\n",
    "    new_sessions[\"query\"] = dest_query\n",
    "    return pd.concat([sessions, new_sessions.drop(\"draw\", axis=1)])\n",
    "\n",
    "\n",
    "sessions = copy_query_sessions(sessions, \"transformers dark of the moon\", \"transformers dark of moon\")\n",
    "sessions = copy_query_sessions(sessions, \"transformers dark of the moon\", \"dark of moon\")\n",
    "sessions = copy_query_sessions(sessions, \"transformers dark of the moon\", \"dark of the moon\")\n",
    "sessions = copy_query_sessions(sessions, \"headphones\", \"head phones\")\n",
    "sessions = copy_query_sessions(sessions, \"lcd tv\", \"lcd television\")\n",
    "sessions = copy_query_sessions(sessions, \"lcd tv\", \"television, lcd\")\n",
    "sessions = copy_query_sessions(sessions, \"macbook\", \"apple laptop\")\n",
    "sessions = copy_query_sessions(sessions, \"iphone\", \"apple iphone\")\n",
    "sessions = copy_query_sessions(sessions, \"kindle\", \"amazon kindle\")\n",
    "sessions = copy_query_sessions(sessions, \"kindle\", \"amazon ereader\")\n",
    "sessions = copy_query_sessions(sessions, \"blue ray\", \"blueray\")\n",
    "\n",
    "sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions[\"query\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Part 3 - Our test query, `transformers dvd`, with hidden, 'true' preferences\n",
    "\n",
    "We add a new query to our set of queries `transformers dvd` and we note the users' hidden preferences in the variables `desired_movies` as well as what they consider mediocre `meh_transformers_movies` and not at all relevant `irrelevant_transformers_products`. Each holds the UPC of the associated product.\n",
    "\n",
    "This simulates biased sessions in the data, as if the user never actually sees (and hence never clicks) their actual desired item. If the users desired results are shown, those results get a higher probability of click. Otherwise there is a lower probability of clicks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_sess_id = sessions[\"sess_id\"].max()\n",
    "\n",
    "# For some reason, the sessions only capture examines on the \"dubbed\" transformers movies\n",
    "# ie the Japanese shows brought to an English-speaking market. But we'll see this is not what the \n",
    "# user wants (ie presentation bias). These are \"meh\" mildly interesting. There are also many many\n",
    "# completely irrelevant movies.\n",
    "\n",
    "# What the user wants, but never visible! Never gets clicked!\n",
    "# These are the widescreen transformers dvds of the hollywood movies\n",
    "desired_transformers_movies = [\"97360724240\", \"97360722345\", \"97368920347\"] \n",
    "\n",
    "# Bunch of random merchandise\n",
    "irrelevant_transformers_products = [\"708056579739\", \"93624995012\", \"47875819733\", \"47875839090\", \"708056579746\",\n",
    "                                     \"47875332911\", \"47875842328\", \"879862003524\", \"879862003517\", \"93624974918\"] \n",
    "\n",
    "# Other transformer movies\n",
    "meh_transformers_movies = [\"97363455349\", \"97361312743\", \"97361372389\", \"97361312804\", \"97363532149\", \"97363560449\"]\n",
    "\n",
    "displayed_transformer_products = meh_transformers_movies + irrelevant_transformers_products\n",
    "\n",
    "new_sessions = []\n",
    "for i in range(0,5000):\n",
    "    random.shuffle(displayed_transformer_products)\n",
    "\n",
    "    # shuffle each session\n",
    "    for rank, upc in enumerate(displayed_transformer_products):\n",
    "        draw = random.random()        \n",
    "        clicked = upc in meh_transformers_movies and draw < 0.13 or \\\n",
    "                  upc in irrelevant_transformers_products and draw < 0.005 or \\\n",
    "                  upc in desired_transformers_movies and draw < 0.65 \\\n",
    "\n",
    "        new_sessions.append({\"sess_id\": next_sess_id + i, \n",
    "                             \"query\": \"transformers dvd\", \n",
    "                             \"rank\": rank,\n",
    "                             \"clicked\": clicked,\n",
    "                             \"doc_id\": upc})\n",
    "\n",
    "\n",
    "sessions = pd.concat([sessions, pd.DataFrame(new_sessions)])\n",
    "sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup 4 - chapter 11 In One Function (omitted) \n",
    "\n",
    "Wrapping up Chapter 11 in a single function `sessions_to_sdbn`. \n",
    "\n",
    "This function computes a relevance grade out of raw clickstream data. Recall that the SDBN (Simplified Dynamic Bayesian Network) click model we learned about in chapter 11 helps overcome position bias. We also use a beta prior so that a single click doesn't count as much as an observation with hundreds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sessions_to_sdbn(sessions, prior_weight=10, prior_grade=0.2) -> pd.DataFrame:\n",
    "    \"\"\" Compute SDBN of the provided query as a dataframe.\n",
    "        Where we left off at end of 'overcoming confidence bias' \n",
    "        \"\"\"\n",
    "    all_sdbn = pd.DataFrame()\n",
    "    for query in sessions[\"query\"].unique():\n",
    "        sdbn_sessions = sessions[sessions[\"query\"] == query].copy().set_index(\"sess_id\")\n",
    "\n",
    "        last_click_per_session = sdbn_sessions.groupby([\"clicked\", \"sess_id\"])[\"rank\"].max()[True]\n",
    "\n",
    "        sdbn_sessions[\"last_click_rank\"] = last_click_per_session\n",
    "        sdbn_sessions[\"examined\"] = sdbn_sessions[\"rank\"] <= sdbn_sessions[\"last_click_rank\"]\n",
    "\n",
    "        sdbn = sdbn_sessions[sdbn_sessions[\"examined\"]].groupby(\"doc_id\")[[\"clicked\", \"examined\"]].sum()\n",
    "        sdbn[\"grade\"] = sdbn[\"clicked\"] / sdbn[\"examined\"]\n",
    "        sdbn[\"query\"] = query\n",
    "\n",
    "        sdbn = sdbn.sort_values(\"grade\", ascending=False)\n",
    "\n",
    "        sdbn[\"prior_a\"] = prior_grade*prior_weight\n",
    "        sdbn[\"prior_b\"] = (1-prior_grade)*prior_weight\n",
    "\n",
    "        sdbn[\"posterior_a\"] = sdbn[\"prior_a\"] +  sdbn[\"clicked\"]\n",
    "        sdbn[\"posterior_b\"] = sdbn[\"prior_b\"] + (sdbn[\"examined\"] - sdbn[\"clicked\"])\n",
    "\n",
    "        sdbn[\"beta_grade\"] = sdbn[\"posterior_a\"] / (sdbn[\"posterior_a\"] + sdbn[\"posterior_b\"])\n",
    "\n",
    "        sdbn.sort_values(\"beta_grade\", ascending=False)\n",
    "        all_sdbn = pd.concat([all_sdbn, sdbn])\n",
    "    return all_sdbn[[\"query\", \"clicked\", \"examined\", \"grade\", \"beta_grade\"]].reset_index().set_index([\"query\", \"doc_id\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 12.1 Use Convert Raw Sessions to SDBN\n",
    "\n",
    "We kickoff with the data we left off with in chapter 11.\n",
    "\n",
    "In this listing we user our \"chapter 11 in one function\" `sessions_to_sdbn` to rebuild training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdbn = sessions_to_sdbn(sessions,\n",
    "                        prior_weight=10,\n",
    "                        prior_grade=0.2)\n",
    "sdbn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 10 Functions (omitted from book)\n",
    "\n",
    "Now with the chapter 11 setup out of the way, we'll need to give Chapter 10's code a similar treatment, wrapping that LTR system into a black box.\n",
    "\n",
    "All of the following are support functions for the chapter:\n",
    "\n",
    "1. Convert the sdbn dataframe into individual `Judgment` objects needed for training the model from chapter 10\n",
    "2. Pairwise transformation of the data\n",
    "3. Normalization of the data\n",
    "4. Training the model\n",
    "5. Uploading the model to Solr\n",
    "\n",
    "All of these steps are covered in Chapter 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "from ltr.judgments import judgments_from_file, judgments_to_nparray\n",
    "from sklearn import svm\n",
    "import json\n",
    "import math\n",
    "from itertools import groupby\n",
    "from ltr.log import FeatureLogger\n",
    "from ltr.judgments import judgments_open\n",
    "from itertools import groupby\n",
    "from ltr import download\n",
    "from ltr.judgments import judgments_writer\n",
    "\n",
    "from ltr.judgments import Judgment\n",
    "\n",
    "def sdbn_to_judgments(sdbn):\n",
    "    \"\"\"Turn pandas dataframe into ltr judgments objects.\"\"\"\n",
    "    judgments = []\n",
    "    queries = {}\n",
    "    next_qid = 0\n",
    "    for row_dict in sdbn.reset_index().to_dict(orient=\"records\"):\n",
    "        # Round grade to 10ths, Map 0.3 -> 3, etc\n",
    "        grade = round(row_dict['beta_grade'], 1) * 10\n",
    "        qid = -1\n",
    "        if row_dict['query'] in queries:\n",
    "            qid = queries[row_dict['query']]\n",
    "        else:\n",
    "            queries[row_dict['query']] = next_qid\n",
    "            qid = next_qid\n",
    "            next_qid += 1\n",
    "        assert qid != -1\n",
    "        \n",
    "        judgments.append(Judgment(doc_id=row_dict['doc_id'],\n",
    "                                  keywords=row_dict['query'],\n",
    "                                  qid=qid,\n",
    "                                  grade=int(grade))\n",
    "                        )\n",
    "    return judgments\n",
    "\n",
    "\n",
    "sdbn_to_judgments(sdbn)\n",
    "\n",
    "\n",
    "def write_judgments(judgments, dest='retrotech_judgments.txt'):\n",
    "    with judgments_writer(open(dest, 'wt')) as writer:\n",
    "        for judgment in judgments:\n",
    "            writer.write(judgment)\n",
    "            \n",
    "write_judgments(sdbn_to_judgments(sdbn))\n",
    "!cat retrotech_judgments.txt\n",
    "\n",
    "\n",
    "def normalize_features(logged_judgments):\n",
    "    all_features = []\n",
    "    means = [0] * len(logged_judgments[0].features)\n",
    "    for judgment in logged_judgments:\n",
    "        for idx, f in enumerate(judgment.features):\n",
    "            means[idx] += f\n",
    "        all_features.append(judgment.features)\n",
    "    \n",
    "    for i in range(len(means)):\n",
    "        means[i] /= len(logged_judgments)\n",
    "      \n",
    "    std_devs = [0.0] * len(logged_judgments[0].features)\n",
    "    for judgment in logged_judgments:\n",
    "        for idx, f in enumerate(judgment.features):\n",
    "            std_devs[idx] += (f - means[idx])**2\n",
    "            \n",
    "    for i in range(len(std_devs)):\n",
    "        std_devs[i] /= len(logged_judgments)\n",
    "        std_devs[i] = math.sqrt(std_devs[i])\n",
    "        \n",
    "    # Normalize!\n",
    "    normed_judgments = []\n",
    "    for judgment in logged_judgments:\n",
    "        normed_features = [0.0] * len(judgment.features)\n",
    "        for idx, f in enumerate(judgment.features):\n",
    "            normed = 0.0\n",
    "            if std_devs[idx] > 0: \n",
    "                normed = (f - means[idx]) / std_devs[idx]\n",
    "            normed_features[idx] = normed\n",
    "        normed_judgment=Judgment(qid=judgment.qid,\n",
    "                                 keywords=judgment.keywords,\n",
    "                                 doc_id=judgment.doc_id,\n",
    "                                 grade=judgment.grade,\n",
    "                                 features=normed_features)\n",
    "        normed_judgment.old_features=judgment.features\n",
    "        normed_judgments.append(normed_judgment)\n",
    "\n",
    "    return means, std_devs, normed_judgments\n",
    "\n",
    "\n",
    "def pairwise_transform(normed_judgments, weigh_difference = True):\n",
    "        \n",
    "    predictor_deltas = []\n",
    "    feature_deltas = []\n",
    "    \n",
    "    # For each query's judgments\n",
    "    for qid, query_judgments in groupby(normed_judgments, key=lambda j: j.qid):\n",
    "\n",
    "        # Annoying issue consuming python iterators, we ensure we have two\n",
    "        # full copies of each query's judgments\n",
    "        query_judgments_copy_1 = list(query_judgments) \n",
    "        query_judgments_copy_2 = list(query_judgments_copy_1)\n",
    "\n",
    "        # Examine every judgment combo for this query, \n",
    "        # if they're different, store the pairwise difference:\n",
    "        # +1 if judgment1 more relevant\n",
    "        # -1 if judgment2 more relevant\n",
    "        for judgment1 in query_judgments_copy_1:\n",
    "            for judgment2 in query_judgments_copy_2:\n",
    "                \n",
    "                j1_features=np.array(judgment1.features)\n",
    "                j2_features=np.array(judgment2.features)\n",
    "                \n",
    "                if judgment1.grade > judgment2.grade:\n",
    "                    diff = judgment1.grade - judgment2.grade if weigh_difference else 1.0\n",
    "                    predictor_deltas.append(+1)\n",
    "                    feature_deltas.append(diff * (j1_features-j2_features))\n",
    "                elif judgment1.grade < judgment2.grade:\n",
    "                    diff = judgment2.grade - judgment1.grade if weigh_difference else 1.0\n",
    "                    predictor_deltas.append(-1)\n",
    "                    feature_deltas.append(diff * (j1_features-j2_features))\n",
    "\n",
    "    # For training purposes, we return these as numpy arrays\n",
    "    return np.array(feature_deltas), np.array(predictor_deltas)\n",
    "\n",
    "def upload_model(model, model_name, means, std_devs, feature_set):\n",
    "    linear_model = {\n",
    "      \"store\": \"aips_feature_store\",\n",
    "      \"class\": \"org.apache.solr.ltr.model.LinearModel\",\n",
    "      \"name\": model_name,\n",
    "      \"features\": [\n",
    "      ],\n",
    "      \"params\": {\n",
    "          \"weights\": {\n",
    "          }\n",
    "      }\n",
    "    }\n",
    "\n",
    "    ftr_model = {}\n",
    "    ftr_names = [ftr['name'] for ftr in feature_set]\n",
    "    for idx, ftr_name in enumerate(ftr_names):\n",
    "        config = {\n",
    "            \"name\": ftr_name,\n",
    "            \"norm\": {\n",
    "                \"class\": \"org.apache.solr.ltr.norm.StandardNormalizer\",\n",
    "                \"params\": {\n",
    "                    \"avg\": str(means[idx]),\n",
    "                    \"std\": str(std_devs[idx])\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        linear_model['features'].append(config)\n",
    "        linear_model['params']['weights'][ftr_name] =  model.coef_[0][idx] \n",
    "\n",
    "    # Delete old model\n",
    "    resp = requests.delete(f\"{SOLR_URL}/products/schema/model-store/{model_name}\")\n",
    "\n",
    "    # Upload the model\n",
    "    resp = requests.put(f\"{SOLR_URL}/products/schema/model-store\", json=linear_model)\n",
    "    resp.text\n",
    "    requests.get(f\"{SOLR_URL}/admin/collections?action=RELOAD&name=products&wt=xml\")\n",
    "\n",
    "\n",
    "    \n",
    "## TODO - can't easily to test/train split on these few queries\n",
    "##   make more queries?\n",
    "\n",
    "def ranksvm_ltr(sdbn, model_name, feature_set):\n",
    "    \"\"\"Train a RankSVM model via Solr, store in Solr.\"\"\"\n",
    "    judgments = sdbn_to_judgments(sdbn)\n",
    "    judgments_path = 'retrotech_judgments.txt'\n",
    "    write_judgments(judgments, judgments_path)\n",
    "    \n",
    "    # For more on this code, review Chapter 10\n",
    "    requests.delete(f\"{SOLR_URL}/products/schema/feature-store/aips_feature_store\")\n",
    "    \n",
    "    resp = requests.put(f\"{SOLR_URL}/products/schema/feature-store\",\n",
    "                    json=feature_set)\n",
    "\n",
    "    ftr_logger=FeatureLogger(client, index='products', feature_set=\"aips_feature_store\", id_field='upc')\n",
    "\n",
    "    with judgments_open(judgments_path) as judgment_list:\n",
    "        for qid, query_judgments in groupby(judgments, key=lambda j: j.qid):\n",
    "            ftr_logger.log_for_qid(judgments=query_judgments, \n",
    "                                   qid=qid,\n",
    "                                   keywords=judgment_list.keywords(qid))\n",
    "\n",
    "    logged_judgments = ftr_logger.logged\n",
    "    means, std_devs, normed_judgments = normalize_features(logged_judgments)\n",
    "    feature_deltas, predictor_deltas = pairwise_transform(normed_judgments)\n",
    "\n",
    "    model = svm.LinearSVC(max_iter=10000, verbose=1)\n",
    "    model.fit(feature_deltas, predictor_deltas)  \n",
    "    upload_model(model, model_name, means, std_devs, feature_set)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Also Chapter 10 - Perform a test / train split on the SDBN data (omitted)\n",
    "\n",
    "This function is broken out from the model training. It lets us train a model on one set of data (reusing the chapter 10 training code), reserving test queries for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import floor\n",
    "\n",
    "def test_train_split(sdbn, train):\n",
    "    \"\"\"Split queries in sdbn into train / test split with `train` proportion going to training set.\"\"\"\n",
    "    queries = sdbn.index.get_level_values('query').unique().copy().tolist()\n",
    "    random.shuffle(queries)\n",
    "    num_queries = len(queries)\n",
    "    split_point = floor(num_queries * train)\n",
    "    \n",
    "    train_queries = queries[:split_point]\n",
    "    test_queries = queries[split_point:]\n",
    "    return sdbn.loc[train_queries, :], sdbn.loc[test_queries]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 10 - Search Code (omitted)\n",
    "\n",
    "Also from Chapter 10, a simple function to search using the LTR model and return a list of search results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_with_model(query, model_name, at=10, log=False):\n",
    "    \"\"\" Search using test_model LTR model (see rq to and qf params below). \"\"\"\n",
    "    fuzzy_kws = \"~\" + ' ~'.join(query.split())\n",
    "    squeezed_kws = \"\".join(query.split())\n",
    "    \n",
    "    rq = \\\n",
    "        \"{!ltr reRankDocs=60000 reRankWeight=10.0 model=\" + model_name \\\n",
    "        + \" efi.fuzzy_keywords=\\\"\" + fuzzy_kws + \"\\\" \" \\\n",
    "        + \"efi.squeezed_keywords=\\\"\" + squeezed_kws +\"\\\" \" \\\n",
    "        + \"efi.keywords=\\\"\" + query + \"\\\"}\"\n",
    "\n",
    "    request = {\n",
    "            \"fields\": [\"upc\", \"name\", \"manufacturer\", \"score\"],\n",
    "            \"limit\": at,\n",
    "            \"params\": {\n",
    "              \"rq\": rq,\n",
    "              \"qf\": \"name name_ngram upc manufacturer shortDescription longDescription\",\n",
    "              \"defType\": \"edismax\",\n",
    "              \"q\": query\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    if log:\n",
    "        print(request)\n",
    "\n",
    "    resp = requests.post(f\"{SOLR_URL}/products/select\", \n",
    "                                   json=request).json()\n",
    "        \n",
    "    if log:\n",
    "        print(resp)\n",
    "        \n",
    "    search_results = resp['response']['docs']\n",
    "\n",
    "    for rank, result in enumerate(search_results):\n",
    "        result['rank'] = rank\n",
    "        \n",
    "    return search_results\n",
    "\n",
    "def search_and_grade(query, model_name, sdbn, desired=[]):\n",
    "    results = search_with_model(query, model_name, at=10)\n",
    "    results = pd.DataFrame(results)\n",
    "    results['desired'] = False\n",
    "    for upc in desired:\n",
    "        results.loc[results['upc'] == upc, 'desired'] = True\n",
    "        \n",
    "    sdbn_query = sdbn.loc[query].copy().reset_index()\n",
    "    return results.merge(sdbn_query, left_on='upc', right_on='doc_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 10 - Evaluate the model on the test set (omitted)\n",
    "\n",
    "This function computes the model's performance on a set of test queries. The model was not trained on the queries in `test`. We compute the precision of these queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(test, model_name, sdbn, at=10):\n",
    "    queries = test.index.get_level_values(\"query\").unique()\n",
    "    \n",
    "    query_results = {}\n",
    "    \n",
    "    for query in queries:\n",
    "        search_results = search_with_model(query, model_name, at=at)\n",
    "\n",
    "        results = pd.DataFrame(search_results).reset_index()\n",
    "        judgments = sdbn.loc[query, :].copy().reset_index()\n",
    "        judgments[\"doc_id\"] = judgments[\"doc_id\"].astype(str)\n",
    "        if len(results) == 0:\n",
    "            print(f\"No Results for {query}\")\n",
    "            query_results[query] = 0\n",
    "        else:\n",
    "            graded_results = results.merge(judgments, left_on=\"upc\", right_on=\"doc_id\", how=\"left\")\n",
    "            print(graded_results)\n",
    "            graded_results[[\"clicked\", \"examined\", \"grade\", \"beta_grade\"]] = graded_results[[\"clicked\", \"examined\", \"grade\", \"beta_grade\"]].fillna(0)\n",
    "            grade_results = graded_results.drop(\"doc_id\", axis=1)\n",
    "\n",
    "            query_results[query] = (graded_results[\"beta_grade\"].sum() / at)\n",
    "    return query_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 12.2 - model training\n",
    "\n",
    "We wrap all the important decisions from chapter 10 in a few lines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1234)\n",
    "\n",
    "feature_set = [\n",
    "{\n",
    "  \"name\": \"long_description_bm25\",\n",
    "  \"store\": \"aips_feature_store\",\n",
    "  \"class\": \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "  \"params\": {\"q\" : \"longDescription:(${keywords})\"}\n",
    "},\n",
    "{\n",
    "  \"name\": \"short_description_constant\",\n",
    "  \"store\": \"aips_feature_store\",\n",
    "  \"class\": \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "  \"params\": {\"q\": \"shortDescription:(${keywords})^=1\"}\n",
    "}]\n",
    "\n",
    "train, test = test_train_split(sdbn, train=0.8)\n",
    "ranksvm_ltr(train, \"click_model_basic\", feature_set=feature_set)\n",
    "eval_model(test, \"click_model_basic\", sdbn=sdbn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # What the user wants, but never visible! Never gets clicked!\n",
    "# These are the widescreen transformers dvds of the hollywood movies\n",
    "desired_movies = [\"97360724240\", \"97360722345\", \"97368920347\"] \n",
    "result = search_and_grade('transformers dvd', \"click_model_basic\", sdbn, desired_movies)\n",
    "upcs1 = result['upc']\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 12.3\n",
    "\n",
    "Train a model that performs better offline called `test2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "random.seed(1234)\n",
    "\n",
    "feature_set_improved = [\n",
    "{\n",
    "  \"name\": \"name_fuzzy\",\n",
    "  \"store\": \"aips_feature_store\",\n",
    "  \"class\": \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "  \"params\": {\"q\" : \"name_ngram:(${keywords})\"}\n",
    "},\n",
    "{\n",
    "  \"name\": \"name_pf2\",\n",
    "  \"store\": \"aips_feature_store\",\n",
    "  \"class\": \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "  \"params\": {\"q\": \"{!edismax qf=name name pf2=name}(${keywords})\"}\n",
    "},\n",
    "{\n",
    "  \"name\": \"shortDescription_pf2\",\n",
    "  \"store\": \"aips_feature_store\",\n",
    "  \"class\": \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "  \"params\": { \n",
    "    \"q\": \"{!edismax qf=shortDescription pf2=shortDescription}(${keywords})\"\n",
    "  }\n",
    "}]\n",
    "\n",
    "sdbn = sessions_to_sdbn(sessions) # chapter 11: generate training data\n",
    "\n",
    "train, test = test_train_split(sdbn, train=0.8)\n",
    "ranksvm_ltr(train, \"click_model_improved\", feature_set_improved) # chapter 10: train the model -> the 'LTR engine'\n",
    "eval_model(test, \"click_model_improved\", sdbn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate a user querying, clicking, purchasing (omitted)\n",
    "\n",
    "This function simulates a user performing a query and possibly taking an action as they scan down the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_user_purchase(query, model_name, desired_products, indifferent_products,\n",
    "                           desired_probability=0.15,\n",
    "                           indifferent_probability=0.03,\n",
    "                           uninterested_probability=0.01,\n",
    "                           quit_per_result_probability=0.2):\n",
    "    \"\"\"Simulates a user 'query' where purchase probability depends on if \n",
    "       products upc is in one of three sets.\n",
    "       \n",
    "       Users purchase a single product per session.    \n",
    "       \n",
    "       Users quit with `quit_per_rank_prod` after scanning each rank\n",
    "       \n",
    "       \"\"\"   \n",
    "    search_results = search(query, model_name, at=10)\n",
    "\n",
    "    results = pd.DataFrame(search_results).reset_index()\n",
    "    for doc in results.to_dict(orient=\"records\"): \n",
    "        draw = random.random()\n",
    "        \n",
    "        if doc[\"upc\"] in desired_products:\n",
    "            if draw < desired_probability:\n",
    "                return True\n",
    "        elif doc[\"upc\"] in indifferent_products:\n",
    "            if draw < indifferent_probability:\n",
    "                return True\n",
    "        elif draw < uninterested_probability:\n",
    "            return True\n",
    "        if random.random() < quit_per_result_probability:\n",
    "            return False\n",
    "        \n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 12.4 - Simulated A/B test on just `transformers dvd` query\n",
    "\n",
    "Here we pretend 1000 users were served two rankings for `transformers dvd` and based on the hidden preferences here (`wants_to_purchase` and `might_purchase`) we see which performs better with conversions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1234)\n",
    "\n",
    "wants_to_purchase = [\"97360724240\", \"97363560449\", \"97363532149\",\n",
    "                     \"97360810042\"]\n",
    "might_purchase = [\"97361312743\", \"97363455349\", \"97361372389\"]\n",
    "\n",
    "def model_a_or_b(query, model_a, model_b):\n",
    "    \"\"\"Randomly assign this user to a or b\"\"\"\n",
    "    draw = random.random()\n",
    "    model_name = model_a if draw < 0.5 else model_b\n",
    "    \n",
    "    purchase_made = simulate_user_purchase(query, model_name, \n",
    "                                           wants_to_purchase,\n",
    "                                           might_purchase)\n",
    "    return (model_name, purchase_made)\n",
    "\n",
    "number_of_users = 1000\n",
    "purchases = {\"click_model_basic\": 0, \"click_model_improved\": 0}\n",
    "for _ in range(number_of_users): \n",
    "    model_name, purchase_made = model_a_or_b(\"transformers dvd\", \n",
    "                                             \"click_model_basic\",\n",
    "                                             \"click_model_improved\")\n",
    "    if purchase_made:\n",
    "        purchases[model_name] += 1 \n",
    "    \n",
    "purchases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdbn = sessions_to_sdbn(sessions)\n",
    "sdbn.loc[\"transformers dvd\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New helper: show the features for each SDBN entry (omitted)\n",
    "\n",
    "This function shows us the logged features of each training row for the given sdbn data for debugging.\n",
    "\n",
    "So not just\n",
    "\n",
    "| query   | doc      | grade\n",
    "|---------|----------|---------\n",
    "|transformers dvd | 1234 | 1.0\n",
    "\n",
    "But also a recording of the matches that occured\n",
    "\n",
    "| query           | doc      | grade    | short_desc_match  | long_desc_match |...\n",
    "|-----------------|----------|----------|-------------------|-----------------|---\n",
    "|transformers dvd | 1234     | 1.0      | 0.0               | 1.0             |..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def associate_sdbn_with_features(sdbn, feature_set):\n",
    "    \"\"\"Log features alongside sdbn into a dataframe\"\"\"\n",
    "    judgments = sdbn_to_judgments(sdbn)\n",
    "    judgments_path = \"retrotech_judgments.txt\"\n",
    "    write_judgments(judgments, judgments_path)\n",
    "    \n",
    "    # For more on this code, review Chapter 10\n",
    "    requests.delete(f\"{SOLR_URL}/products/schema/feature-store/explore\")\n",
    "    \n",
    "    resp = requests.put(f\"{SOLR_URL}/products/schema/feature-store\",\n",
    "                    json=feature_set)\n",
    "\n",
    "    ftr_logger=FeatureLogger(client, index=\"products\", feature_set=\"explore\", id_field=\"upc\")\n",
    "    \n",
    "    with judgments_open(judgments_path) as judgment_list:\n",
    "        for qid, query_judgments in groupby(judgments, key=lambda j: j.qid):\n",
    "            ftr_logger.log_for_qid(judgments=query_judgments, \n",
    "                                   qid=qid,\n",
    "                                   keywords=judgment_list.keywords(qid))\n",
    "\n",
    "    logged_judgments = ftr_logger.logged\n",
    "    means, std_devs, normed_judgments = normalize_features(logged_judgments)\n",
    "    feature_deltas, predictor_deltas = pairwise_transform(normed_judgments)\n",
    "    features, predictors = judgments_to_nparray(logged_judgments)\n",
    "    logged_judgments_dataframe = pd.concat([pd.DataFrame(predictors),\n",
    "                                            pd.DataFrame(features)], \n",
    "                                           axis=1,\n",
    "                                           ignore_index=True)\n",
    "    columns = {idx + 2: ftr[\"name\"] for idx, ftr in enumerate(feature_set)}\n",
    "    columns[0] = \"grade\"\n",
    "    columns[1] = \"qid\"\n",
    "    \n",
    "    qid_to_query = {}\n",
    "    for j in logged_judgments:\n",
    "        qid_to_query[j.qid] = j.keywords\n",
    "        \n",
    "    qid_to_query = pd.DataFrame(qid_to_query.values()).reset_index().rename(columns={\"index\": \"qid\", 0: \"query\"})\n",
    "    \n",
    "    logged_judgments_dataframe = logged_judgments_dataframe.rename(columns=columns)\n",
    "    logged_judgments_dataframe = logged_judgments_dataframe.merge(qid_to_query, how=\"left\", on=\"qid\")\n",
    "    cols_order = [\"query\", \"grade\"] + [ftr[\"name\"] for idx, ftr in enumerate(feature_set)]\n",
    "    logged_judgments_dataframe[\"grade\"] = logged_judgments_dataframe[\"grade\"] / 10.0 \n",
    "    return logged_judgments_dataframe[cols_order].sort_values(\"query\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 12.5 - Output matches for one feature set\n",
    "\n",
    "Another way of formulating `presentation_bias` is to look at the kinds of documents not being shown to users, so we can strategically show those to users. Below we show the value of each feature in `explore_feature_set` for each document in the sdbn judgments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdbn = sessions_to_sdbn(sessions)\n",
    "\n",
    "explore_feature_set = [\n",
    "{\n",
    "  \"name\": \"long_desc_match\",\n",
    "  \"store\": \"explore\",\n",
    "  \"class\": \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "  \"params\": {\"q\": \"longDescription:(${keywords})^=1\"}\n",
    "},\n",
    "{\n",
    "  \"name\": \"short_desc_match\",\n",
    "  \"store\": \"explore\",\n",
    "  \"class\": \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "  \"params\": {\"q\": \"shortDescription:(${keywords})^=1\"}\n",
    "},\n",
    "{\n",
    "  \"name\": \"name_match\",\n",
    "  \"store\": \"explore\",\n",
    "  \"class\": \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "  \"params\": {\"q\": \"name:(${keywords})^=1\"}\n",
    "},\n",
    "{\n",
    "  \"name\": \"has_promotion\",\n",
    "  \"store\": \"explore\",\n",
    "  \"class\": \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "  \"params\": {\"q\": \"promotion_b:true\"}\n",
    "}]\n",
    "\n",
    "sdbn_with_features = associate_sdbn_with_features(sdbn, explore_feature_set)\n",
    "sdbn_with_features[sdbn_with_features[\"query\"] == \"transformers dvd\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 12.6 - Train Gaussian Process Regressor\n",
    "\n",
    "We train data on just the `transformers_dvd` training data. \n",
    "\n",
    "NOTE we could also train on the full sdbn data, and see globally what's missing. However it's often convenient to zero in on specific queries to round out their training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "\n",
    "x_train = transformers_dvds[[\"long_desc_match\", \"short_desc_match\",\n",
    "                             \"name_match\", \"has_promotion\"]]\n",
    "y_train = transformers_dvds[\"grade\"]\n",
    "\n",
    "gpr = GaussianProcessRegressor()\n",
    "gpr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 12.7: Predict on every value\n",
    "\n",
    "Here `gpr` predicts on every possible feature value. This lets us analyze which set of feature values to use when exploring with users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_or_one = [0, 1]\n",
    "\n",
    "index = pd.MultiIndex.from_product(\n",
    "    [zero_or_one] * 4, names=[\"long_desc_match\", \"short_desc_match\",\n",
    "                              \"name_match\", \"has_promotion\"])\n",
    "to_explore = pd.DataFrame(index=index).reset_index()\n",
    "\n",
    "predictions_with_std = \\\n",
    "    gpr.predict(to_explore[[\"long_desc_match\", \"short_desc_match\",\n",
    "                                 \"name_match\", \"has_promotion\"]],\n",
    "                return_std=True)\n",
    "to_explore[\"predicted_grade\"] = predictions_with_std[0]\n",
    "to_explore[\"prediction_stddev\"] = predictions_with_std[1]\n",
    "\n",
    "to_explore.sort_values(\"prediction_stddev\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 12.8 - Calculate Expected Improvement\n",
    "\n",
    "\n",
    "We use [Expected Improvement](https://distill.pub/2020/bayesian-optimization/) scoring to select candidates for exploration within the `transformers dvd` query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'http://localhost:8888/'. Verify the server is running and reachable. (Failed to connect to the remote Jupyter Server 'http://localhost:8888/'. Verify the server is running and reachable. (Forbidden).)."
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "theta = 0.6\n",
    "to_explore[\"opportunity\"] = to_explore[\"predicted_grade\"] - \\\n",
    "                            sdbn[\"grade\"].mean() - theta\n",
    "\n",
    "to_explore[\"prob_of_improvement\"] = \\\n",
    "    norm.cdf(to_explore[\"opportunity\"]) / to_explore[\"prediction_stddev\"]\n",
    "\n",
    "to_explore[\"expected_improvement\"] = \\\n",
    "    to_explore[\"opportunity\"] * to_explore[\"prob_of_improvement\"] + \\\n",
    "    to_explore[\"prediction_stddev\"] * \\\n",
    "    norm.pdf(to_explore[\"opportunity\"] / to_explore[\"prediction_stddev\"])\n",
    "\n",
    "to_explore.sort_values(\"expected_improvement\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a query to fetch 'explore' docs (omitted)\n",
    "\n",
    "Based on the selected features from the GaussianProcessRegressor, we create a query to fetch a doc that contains those features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_query(explore_vector, query):\n",
    "    config_explore = {\n",
    "        \"long_desc_match\": {\"field\": \"longDescription\", \"query_dependent\": True},                      \"short_desc_match\": {\"field\": \"shortDescription\", \"query_dependent\": True},\n",
    "        \"name_match\": {\"field\": \"name\", \"query_dependent\": True},\n",
    "        \"long_description_bm25\": {\"field\": \"longDescription\", \"query_dependent\": True},\n",
    "        \"manufacturer_match\": {\"field\": \"manufacturer\", \"query_dependent\": True},\n",
    "        \"has_promotion\": {\"field\": \"promotion_b\", \"query_dependent\": False, \"1_value\": \"true\"}\n",
    "    }\n",
    "    clauses = []\n",
    "    for col_name, config in config_explore.items():\n",
    "        try:\n",
    "            clause = \"\"\n",
    "            if explore_vector[col_name] == 1.0:\n",
    "                clause = f\"+{config[\"field\"]}:\"\n",
    "            elif explore_vector[col_name] == -1.0:\n",
    "                clause = f\"-{config[\"field\"]}:\"\n",
    "            if len(clause) > 0:  \n",
    "                if config[\"query_dependent\"]:\n",
    "                    clause += f\"({query})\"\n",
    "                else:\n",
    "                    clause += f\"{config[\"1_value\"]}\"\n",
    "\n",
    "            clauses.append(clause)\n",
    "        except KeyError as e:\n",
    "            pass\n",
    "    \n",
    "    final_query = \" \".join(clauses)\n",
    "    final_query = final_query.strip()\n",
    "    if len(final_query) == 0:\n",
    "        return \"*:*\"\n",
    "    return final_query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 12.9 - Find document to explore from Solr\n",
    "\n",
    "Here we fetch a document that matches the properties of something missing from our training set for display to the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1234)\n",
    "\n",
    "products_collection = engine.get_collection(\"products\")\n",
    "fields = [\"long_desc_match\", \"short_desc_match\",\n",
    "          \"name_match\", \"has_promotion\"]\n",
    "explore_vector = to_explore.sort_values(\"expected_improvement\",\n",
    "                                        ascending=False) \\\n",
    "                            .head().iloc[0][fields]\n",
    "\n",
    "def explore(collection, query, explore_vector):\n",
    "    \"\"\" Explore according to the provided explore vector, select\n",
    "        a random doc from that group.\"\"\"\n",
    "    draw = random.random()\n",
    "    q = explore_query(explore_vector, query)\n",
    "    request = {\n",
    "        \"fields\": [\"upc\", \"name\", \"manufacturer\", \"score\"],\n",
    "        \"limit\": 1,\n",
    "        \"params\": {\"q\": q, \"sort\": f\"random_{draw} DESC\"}\n",
    "    }\n",
    "    \n",
    "    response = collection.search(request)\n",
    "    return engine.docs_from_response(response)[0][\"upc\"]\n",
    "\n",
    "explore(products_collection, \"transformers dvd\", explore_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate new sessions with the new data\n",
    "\n",
    "(Takes a while)\n",
    "\n",
    "We simulate new sessions, if the upc is in `might_purchase` or `wants_to_purchase`, we set it to 'clicked' with a given probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(1234)\n",
    "\n",
    "wants_to_purchase = [\"97360724240\", \"97363560449\", \"97363532149\", \"97360810042\", \"97368920347\"]\n",
    "might_purchase = [\"97361312743\", \"97363455349\", \"97361372389\"]\n",
    "explore_on_rank = 2.0\n",
    "\n",
    "with_explore_sessions = sessions.copy()\n",
    "for i in range(0, 500):\n",
    "    print(i)\n",
    "    explore_upc = explore(\"transformers dvd\", explore_vector)\n",
    "    print(i, explore_upc)\n",
    "    sess_ids = list(set(sessions[sessions[\"query\"] == \"transformers dvd\"][\"sess_id\"].tolist()))\n",
    "    random.shuffle(sess_ids)\n",
    "    sess_ids[0]\n",
    "    new_session = sessions[sessions[\"sess_id\"] == sess_ids[0]].copy()\n",
    "    new_session[\"sess_id\"] = 100000 + i\n",
    "    new_session.loc[new_session[\"rank\"] == explore_on_rank, \"doc_id\"] = explore_upc\n",
    "    draw = random.random()\n",
    "    new_session.loc[new_session[\"rank\"] == explore_on_rank, \"clicked\"] = False\n",
    "    if explore_upc in wants_to_purchase:\n",
    "        if draw < 0.8:\n",
    "            print(f\"click {explore_upc}\")\n",
    "            new_session.loc[new_session[\"rank\"] == explore_on_rank, \"clicked\"] = True\n",
    "    elif explore_upc in might_purchase:\n",
    "        if draw < 0.5:\n",
    "            print(f\"click {explore_upc}\")\n",
    "            new_session.loc[new_session[\"rank\"] == explore_on_rank, \"clicked\"] = True\n",
    "    else:\n",
    "        if draw < 0.01:\n",
    "            print(f\"click {explore_upc}\")\n",
    "            new_session.loc[new_session[\"rank\"] == explore_on_rank, \"clicked\"] = True\n",
    "\n",
    "    with_explore_sessions = pd.concat([with_explore_sessions, new_session])\n",
    "\n",
    "with_explore_sessions[with_explore_sessions[\"sess_id\"] == 100049]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 12.10 - Update judgments from new sessions\n",
    "\n",
    "Have we added any new docs that appear to be getting more clicks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reimproved_sdbn = sessions_to_sdbn(with_explore_sessions)\n",
    "reimproved_sdbn.loc['transformers dvd']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New heavily clicked doc is promoted!\n",
    "\n",
    "```\n",
    "      {\n",
    "        \"upc\":\"97360810042\",\n",
    "        \"name\":\"Transformers: Dark of the Moon - Blu-ray Disc\",\n",
    "        \"name_ngram\":\"Transformers: Dark of the Moon - Blu-ray Disc\",\n",
    "        \"name_omit_norms\":\"Transformers: Dark of the Moon - Blu-ray Disc\",\n",
    "        \"name_txt_en_split\":\"Transformers: Dark of the Moon - Blu-ray Disc\",\n",
    "        \"manufacturer\":\"\\\\N\",\n",
    "        \"shortDescription\":\"\\\\N\",\n",
    "        \"longDescription\":\"\\\\N\",\n",
    "        \"promotion_b\":true,\n",
    "        \"id\":\"72593b1c-313b-4f25-a4f2-04eae29d858b\",\n",
    "        \"_version_\":1710117636920049669\n",
    "      },\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 12.11 - Rebuild model using updated judgments\n",
    "\n",
    "After showing the new document to users, we can rebuild the model using judgments that cover this feature blindspot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1234)\n",
    "\n",
    "# {'blue ray': 0.0,\n",
    "# 'dryer': 0.07068309073137659,\n",
    "# 'headphones': 0.06426395939086295,\n",
    "# 'dark of moon': 0.25681268708548055,\n",
    "# 'transformers dvd': 0.10077083021678328}\n",
    "\n",
    "feature_set_reimproved = [\n",
    "{\n",
    "  \"name\": \"name_fuzzy\",\n",
    "  \"store\": \"aips_feature_store\",\n",
    "  \"class\": \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "  \"params\": {\"q\" : \"name_ngram:(${keywords})\"}\n",
    "},\n",
    "{\n",
    "  \"name\": \"name_pf2\",\n",
    "  \"store\": \"aips_feature_store\",\n",
    "  \"class\": \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "  \"params\": {\"q\": \"{!edismax qf=name name pf2=name}(${keywords})\"\n",
    "  }\n",
    "},\n",
    "{\n",
    "  \"name\": \"shortDescription_pf2\",\n",
    "  \"store\": \"aips_feature_store\",\n",
    "  \"class\": \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "  \"params\": {\n",
    "    \"q\": \"{!edismax qf=shortDescription pf2=shortDescription}(${keywords})\"\n",
    "  }\n",
    "},\n",
    "{\n",
    "  \"name\": \"has_promotion\",\n",
    "  \"store\": \"aips_feature_store\",\n",
    "  \"class\": \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "  \"params\": {\"q\": \"promotion_b:true^=1.0\"}\n",
    "}]\n",
    "\n",
    "train, test = test_train_split(sdbn, train=0.8)\n",
    "ranksvm_ltr(train, \"click_model_reimproved\", feature_set_improved)\n",
    "eval_model(test, \"click_model_reimproved\", sdbn=reimproved_sdbn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 12.12 - Rerun A/B test on new `test3` model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_users = 1000\n",
    "purchases = {\"click_model\": 0, \"click_model_edismax_promo\": 0}\n",
    "for _ in range(0, number_of_users):    \n",
    "    model_name, purchase_made = model_a_or_b(\"transformers dvd\", \n",
    "                                             \"click_model_basic\",\n",
    "                                             \"click_model_reimproved\")\n",
    "    if purchase_made:\n",
    "        purchases[model_name] += 1 \n",
    "    \n",
    "purchases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listings 12.6-12.8 in one function (omitted)\n",
    "\n",
    "We wrap the core of the Active Learning we covered in this chapter into a single function to allow us to select the ideal document to explore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from scipy.stats import norm\n",
    "\n",
    "\n",
    "def best_explore_candidate(sdbn, feature_set, theta=0.6):\n",
    "    \n",
    "    requests.delete(f\"{SOLR_URL}/products/schema/feature-store/explore\")\n",
    "    \n",
    "    resp = requests.put(f\"{SOLR_URL}/products/schema/feature-store\",\n",
    "                    json=feature_set)\n",
    "    \n",
    "    sdbn_ftrs = associate_sdbn_with_features(sdbn, feature_set)\n",
    "    transformers_dvds = sdbn_ftrs[sdbn_ftrs[\"query\"] == \"transformers dvd\"]\n",
    "\n",
    "    y_train = transformers_dvds[\"grade\"]\n",
    "    feature_names = [ftr[\"name\"] for ftr in explore_feature_set]\n",
    "    x_train = transformers_dvds[feature_names]\n",
    "\n",
    "    gpr=GaussianProcessRegressor()\n",
    "    gpr.fit(x_train, y_train)\n",
    "    \n",
    "    zero_or_one = [0,1]\n",
    "\n",
    "    index = pd.MultiIndex.from_product([zero_or_one] * 4,\n",
    "                                       names = feature_names)\n",
    "    to_explore = pd.DataFrame(index=index).reset_index()\n",
    "\n",
    "    predictions_with_std = gpr.predict(to_explore[feature_names], return_std=True)\n",
    "    to_explore[\"predicted_grade\"] = predictions_with_std[0]\n",
    "    to_explore[\"prediction_stddev\"] = predictions_with_std[1]\n",
    "\n",
    "    to_explore.sort_values(\"prediction_stddev\")\n",
    "\n",
    "    to_explore[\"opportunity\"] = to_explore[\"predicted_grade\"] - sdbn[\"grade\"].mean() - theta\n",
    "\n",
    "\n",
    "    to_explore[\"prob_of_improvement\"] = norm.cdf( (to_explore[\"opportunity\"]) / to_explore[\"prediction_stddev\"])\n",
    "\n",
    "    to_explore[\"expected_improvement\"] = to_explore[\"opportunity\"] * to_explore[\"prob_of_improvement\"] \\\n",
    "     + to_explore[\"prediction_stddev\"] * norm.pdf( to_explore[\"opportunity\"] / to_explore[\"prediction_stddev\"])\n",
    "\n",
    "\n",
    "    to_explore.sort_values(\"expected_improvement\", ascending=False).head()\n",
    "    \n",
    "    options = to_explore.loc[:, feature_names]\n",
    "    return options.loc[0]\n",
    "\n",
    "\n",
    "explore_feature_set = [\n",
    "    {\n",
    "      \"name\" : \"manufacturer_match\",\n",
    "      \"store\": \"explore\",\n",
    "      \"class\" : \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "      \"params\" : {\n",
    "        \"q\" : \"manufacturer:(${keywords})^=1\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"name\" : \"name_fuzzy\",\n",
    "      \"store\": \"explore\",\n",
    "      \"class\" : \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "      \"params\" : {\n",
    "        \"q\" : \"name_ngram:(${keywords})\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"name\" : \"long_description_bm25\",\n",
    "      \"store\": \"explore\",\n",
    "      \"class\" : \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "      \"params\" : {\n",
    "        \"q\" : \"longDescription:(${keywords})\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"name\" : \"short_description_constant\",\n",
    "      \"store\": \"explore\",\n",
    "      \"class\" : \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "      \"params\" : {\n",
    "        \"q\" : \"shortDescription:(${keywords})^=1\"\n",
    "      }\n",
    "    }]\n",
    "\n",
    "\n",
    "\n",
    "best_explore_candidate(sdbn, explore_feature_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 12.13 - Fully Automated LTR Loop\n",
    "\n",
    "These lines expand Listing 12.13 from the book (the book content is a truncated form of what's below). You could put this in a loop and constantly try new features to try to get closer at a generalized ranking solution of what users actually want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploit_feature_set = [\n",
    "{\n",
    "  \"name\": \"name_fuzzy\",\n",
    "  \"store\": \"exploit_store\",\n",
    "  \"class\": \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "  \"params\": {\"q\": \"name_ngram:(${keywords})\"}\n",
    "},\n",
    "{\n",
    "  \"name\": \"long_description_bm25\",\n",
    "  \"store\": \"exploit_store\",\n",
    "  \"class\": \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "  \"params\": {\"q\": \"longDescription:(${keywords})\"}\n",
    "},\n",
    "{\n",
    "  \"name\": \"short_description_constant\",\n",
    "  \"store\": \"exploit_store\",\n",
    "  \"class\": \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "  \"params\": {\"q\": \"shortDescription:(${keywords})^=1\"}\n",
    "}]\n",
    "\n",
    "train, test = test_train_split(sdbn, train=0.8) \n",
    "ranksvm_ltr(train, \"exploit_model\", exploit_feature_set)\n",
    "eval_model(test, \"exploit_model\", sdbn=reimproved_sdbn)\n",
    "\n",
    "# ===============\n",
    "# EXPLORE\n",
    "\n",
    "explore_feature_set = [\n",
    "{\n",
    "  \"name\": \"manufacturer_match\",\n",
    "  \"store\": \"explore\",\n",
    "  \"class\": \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "  \"params\": {\"q\": \"manufacturer:(${keywords})^=1\"}\n",
    "},\n",
    "{\n",
    "  \"name\": \"name_fuzzy\",\n",
    "  \"store\": \"explore\",\n",
    "  \"class\": \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "  \"params\": {\"q\": \"name_ngram:(${keywords})\"}\n",
    "},\n",
    "{\n",
    "  \"name\": \"long_description_bm25\",\n",
    "  \"store\": \"explore\",\n",
    "  \"class\": \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "  \"params\": {\"q\": \"longDescription:(${keywords})\"}\n",
    "},\n",
    "{\n",
    "  \"name\": \"short_description_constant\",\n",
    "  \"store\": \"explore\",\n",
    "  \"class\": \"org.apache.solr.ltr.feature.SolrFeature\",\n",
    "  \"params\": {\"q\": \"shortDescription:(${keywords})^=1\"}\n",
    "}]\n",
    "\n",
    "explore_vector = best_explore_candidate(sdbn, explore_feature_set, theta=0.6)\n",
    "explore_upc = explore('transformers dvd', explore_vector) \n",
    "\n",
    "\n",
    "# =========\n",
    "# GATHER                                   \n",
    "sdbn = sessions_to_sdbn(sessions,            \n",
    "                        prior_weight=10,    \n",
    "                        prior_grade=0.2)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up next: [Chapter 13: Semantic Search with Dense Vectors](../ch13/1.setting-up-the-outdoors-dataset.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
