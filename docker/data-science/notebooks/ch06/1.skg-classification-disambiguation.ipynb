{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [ Chapter 6 - Using Content to Learn Domain-specific Language ]\n",
    "# Query Classification and Disambiguation with Semantic Knowledge Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "NOTE: This notebook depends upon the the Stack Exchange datasets. If you have any issues, please rerun the [Setting up the Stack Exchange Dataset](../ch05/2.index-datasets.ipynb) notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from aips import *\n",
    "import os\n",
    "import json\n",
    "from IPython.display import display,HTML\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"AIPS\").getOrCreate()\n",
    "engine = get_engine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = \"stackexchange\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 6.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: docker\n",
      "  Classifications: \n",
      "    devops  0.88257\n",
      "\n",
      "\n",
      "Query: airplane\n",
      "  Classifications: \n",
      "    travel  0.33525\n",
      "\n",
      "\n",
      "Query: airplane AND crash\n",
      "  Classifications: \n",
      "    scifi  0.02399\n",
      "    travel  0.0066\n",
      "\n",
      "\n",
      "Query: camping\n",
      "  Classifications: \n",
      "    outdoors  0.71621\n",
      "    travel  0.01494\n",
      "\n",
      "\n",
      "Query: alien\n",
      "  Classifications: \n",
      "    scifi  0.64359\n",
      "\n",
      "\n",
      "Query: passport\n",
      "  Classifications: \n",
      "    travel  0.83413\n",
      "\n",
      "\n",
      "Query: driver\n",
      "  Classifications: \n",
      "    travel  0.3975\n",
      "    devops  0.09238\n",
      "\n",
      "\n",
      "Query: driver AND taxi\n",
      "  Classifications: \n",
      "    travel  0.25059\n",
      "    scifi  -0.13167\n",
      "\n",
      "\n",
      "Query: driver AND install\n",
      "  Classifications: \n",
      "    devops  0.22399\n",
      "    travel  -0.00634\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def run_query_classification(query, classification_field=\"category\", \n",
    "                             classification_limit=5, keywords_field=\"body\", min_occurrences=5):\n",
    "        \n",
    "    classification_query = {\n",
    "        \"params\": {\n",
    "            \"qf\": keywords_field,\n",
    "            \"fore\": \"{!type=$defType qf=$qf v=$q}\",\n",
    "            \"back\": \"*:*\",\n",
    "            \"defType\": \"edismax\",\n",
    "            \"rows\": 0,\n",
    "            \"echoParams\": \"none\",\n",
    "            \"omitHeader\": \"true\"\n",
    "        },\n",
    "        \"query\": query,\n",
    "        \"facet\": {\n",
    "            \"classification\":{\n",
    "                \"type\": \"terms\",\n",
    "                \"field\": classification_field,\n",
    "                \"sort\": { \"classification_relatedness\": \"desc\"},\n",
    "                \"mincount\": min_occurrences, \n",
    "                \"limit\": classification_limit,\n",
    "                \"facet\": {\n",
    "                    \"classification_relatedness\": {\n",
    "                        \"type\": \"func\",\n",
    "                        \"func\": \"relatedness($fore,$back)\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "     \n",
    "    search_results = engine.search(collection, classification_query).json()\n",
    "    print(f\"Query: {query}\") \n",
    "    print(\"  Classifications: \")\n",
    "    for bucket in search_results[\"facets\"][\"classification\"][\"buckets\"]:\n",
    "        print(f\"    {bucket['val']}  {bucket['classification_relatedness']['relatedness']}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "run_query_classification(\"docker\", classification_limit=3 )\n",
    "run_query_classification(\"airplane\", classification_limit=1 )\n",
    "run_query_classification(\"airplane AND crash\", classification_limit=2 )\n",
    "run_query_classification(\"camping\", classification_limit=2 )\n",
    "run_query_classification(\"alien\", classification_limit=1 )\n",
    "run_query_classification(\"passport\", classification_limit=1 )\n",
    "run_query_classification(\"driver\", classification_limit=2 )\n",
    "run_query_classification(\"driver AND taxi\", classification_limit=2 )\n",
    "run_query_classification(\"driver AND install\", classification_limit=2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disambiguation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 6.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_disambiguation_query(query, context_field=\"category\", context_limit=5,\n",
    "                             keywords_field=\"body\", keywords_limit=10, min_occurrences=5):      \n",
    "    \n",
    "    disambiguation_query = {\n",
    "        \"params\": {\n",
    "            \"qf\": keywords_field,\n",
    "            \"fore\": \"{!type=$defType qf=$qf v=$q}\",\n",
    "            \"back\": \"*:*\",\n",
    "            \"defType\": \"edismax\",\n",
    "            \"rows\": 0,\n",
    "            \"echoParams\": \"none\",\n",
    "            \"omitHeader\": \"true\"\n",
    "        },\n",
    "        \"query\": query,\n",
    "        \"facet\": {\n",
    "            \"context\":{\n",
    "                \"type\": \"terms\",\n",
    "                \"field\": context_field,\n",
    "                \"sort\": { \"context_relatedness\": \"desc\"},\n",
    "                \"mincount\": min_occurrences, \n",
    "                \"limit\": context_limit,\n",
    "                \"facet\": {\n",
    "                    \"context_relatedness\": {\n",
    "                        \"type\": \"func\",\n",
    "                        \"func\": \"relatedness($fore,$back)\"\n",
    "                    },        \n",
    "                    \"keywords\": {\n",
    "                        \"type\": \"terms\",\n",
    "                        \"field\": keywords_field,\n",
    "                        \"mincount\": min_occurrences,\n",
    "                        \"limit\": keywords_limit,\n",
    "                        \"sort\": { \"keywords_relatedness\": \"desc\"},\n",
    "                        \"facet\": {\n",
    "                            \"keywords_relatedness\": {\n",
    "                                \"type\": \"func\",\n",
    "                                \"func\": \"relatedness($fore,$back)\"\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }    \n",
    "        \n",
    "    search_results = engine.search(collection, disambiguation_query).json()\n",
    "    \n",
    "    print(f\"Query: {query}\") \n",
    "    for ctx_bucket in search_results[\"facets\"][\"context\"][\"buckets\"]:\n",
    "        print(f\"  Context: {ctx_bucket['val']}  {ctx_bucket['context_relatedness']['relatedness']}\")\n",
    "        print(\"    Keywords: \")\n",
    "        for kw_bucket in ctx_bucket[\"keywords\"][\"buckets\"]:\n",
    "            print(f\"      {kw_bucket['val']}  {kw_bucket['keywords_relatedness']['relatedness']}\")\n",
    "        print (\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 6.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: server\n",
      "  Context: devops  0.84145\n",
      "    Keywords: \n",
      "      server  0.93833\n",
      "      servers  0.77346\n",
      "      docker  0.76534\n",
      "      code  0.73233\n",
      "      deploy  0.71189\n",
      "      nginx  0.71097\n",
      "      configuration  0.70761\n",
      "      jenkins  0.70575\n",
      "      git  0.69694\n",
      "      ssh  0.69157\n",
      "\n",
      "\n",
      "  Context: outdoors  -0.07938\n",
      "    Keywords: \n",
      "      server  0.35588\n",
      "      can  0.03435\n",
      "      you  0.03071\n",
      "      with  0.0268\n",
      "      it  0.0203\n",
      "      have  0.01979\n",
      "      of  0.01463\n",
      "      in  0.01434\n",
      "      and  0.013\n",
      "      to  0.01132\n",
      "\n",
      "\n",
      "  Context: travel  -0.15243\n",
      "    Keywords: \n",
      "      server  0.81622\n",
      "      tipping  0.53867\n",
      "      vpn  0.46088\n",
      "      tip  0.4014\n",
      "      servers  0.39731\n",
      "      firewall  0.33683\n",
      "      restaurant  0.22171\n",
      "      bill  0.19194\n",
      "      cash  0.18885\n",
      "      tips  0.18553\n",
      "\n",
      "\n",
      "  Context: cooking  -0.15249\n",
      "    Keywords: \n",
      "      server  0.67144\n",
      "      restaurant  0.16802\n",
      "      pie  0.13122\n",
      "      served  0.12279\n",
      "      restaurants  0.1191\n",
      "      knife  0.10357\n",
      "      pieces  0.1005\n",
      "      serve  0.09023\n",
      "      staff  0.08995\n",
      "      dish  0.08703\n",
      "\n",
      "\n",
      "  Context: scifi  -0.26682\n",
      "    Keywords: \n",
      "      server  0.78639\n",
      "      flynn's  0.54289\n",
      "      computer  0.2871\n",
      "      computers  0.26573\n",
      "      flynn  0.25653\n",
      "      servers  0.25442\n",
      "      grid  0.23073\n",
      "      networking  0.22204\n",
      "      shutdown  0.21251\n",
      "      hacker  0.19916\n",
      "\n",
      "\n",
      "Query: driver\n",
      "  Context: travel  0.3975\n",
      "    Keywords: \n",
      "      driver  0.93521\n",
      "      drivers  0.77284\n",
      "      taxi  0.72622\n",
      "      car  0.64884\n",
      "      license  0.61716\n",
      "      driving  0.60824\n",
      "      taxis  0.58903\n",
      "      bus  0.53085\n",
      "      traffic  0.52823\n",
      "      driver's  0.51776\n",
      "\n",
      "\n",
      "  Context: devops  0.09238\n",
      "    Keywords: \n",
      "      ipam  0.78723\n",
      "      driver  0.77939\n",
      "      aufs  0.7438\n",
      "      overlayfs  0.7438\n",
      "      container_name  0.74113\n",
      "      overlay2  0.69838\n",
      "      cgroup  0.69217\n",
      "      docker  0.68343\n",
      "      compose.yml  0.65904\n",
      "      compose  0.567\n",
      "\n",
      "\n",
      "Query: chef\n",
      "  Context: cooking  0.38655\n",
      "    Keywords: \n",
      "      chef  0.93378\n",
      "      chefs  0.52236\n",
      "      www.pamperedchef.com  0.41992\n",
      "      restaurant  0.39595\n",
      "      kitchen  0.39562\n",
      "      cooking  0.38681\n",
      "      chef's  0.3805\n",
      "      nakiri  0.373\n",
      "      professional  0.36218\n",
      "      santoku  0.35057\n",
      "\n",
      "\n",
      "  Context: devops  0.35734\n",
      "    Keywords: \n",
      "      chef  0.87904\n",
      "      puppet  0.79601\n",
      "      docs.chef.io  0.79143\n",
      "      ansible  0.74511\n",
      "      www.chef.io  0.72743\n",
      "      learn.chef.io  0.72577\n",
      "      default.rb  0.70919\n",
      "      configuration  0.68377\n",
      "      inspec  0.66121\n",
      "      cookbooks  0.6243\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_disambiguation_query(\"server\")\n",
    "run_disambiguation_query(\"driver\", context_limit=2)\n",
    "run_disambiguation_query(\"chef\", context_limit=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Examples (not included in chapter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark  0.80665\n",
      "hadoop  0.59424\n",
      "hive  0.52983\n",
      "kafka  0.51552\n",
      "impala  0.45309\n",
      "streamsets  0.39341\n",
      "scala  0.38564\n",
      "flume  0.38401\n",
      "attunity  0.37374\n",
      "mapreduce  0.36195\n"
     ]
    }
   ],
   "source": [
    "collection=\"jobs\"\n",
    "\n",
    "request = {\n",
    "    \"params\": {\n",
    "        \"qf\": \"job_description job_title\",\n",
    "        \"fore\": \"{!type=$defType qf=$qf v=$q}\",\n",
    "        \"back\": \"*:*\",\n",
    "        \"defType\": \"edismax\",\n",
    "        \"rows\": 0,\n",
    "        \"echoParams\": \"none\",\n",
    "        \"omitHeader\": \"true\"\n",
    "    },\n",
    "    \"query\": \"\\\"spark\\\"\",\n",
    "    \"facet\": {\n",
    "        \"job_description_keywords\": {\n",
    "            \"type\": \"terms\",\n",
    "            \"field\": \"job_description\",\n",
    "            \"sort\": { \"relatedness\": \"desc\"},\n",
    "            \"facet\": {\n",
    "                \"relatedness\": {\n",
    "                    \"type\": \"func\",\n",
    "                    \"func\": \"relatedness($fore,$back)\"\n",
    "                }\n",
    "            }            \n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "search_results = engine.search(collection, request).json()\n",
    "\n",
    "for bucket in search_results[\"facets\"][\"job_description_keywords\"][\"buckets\"]:\n",
    "    print(str(bucket[\"val\"]) + \"  \" + str(bucket[\"relatedness\"][\"relatedness\"]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chef  0.80689\n",
      "puppet  0.59501\n",
      "ansible  0.52824\n",
      "terraform  0.3866\n",
      "jenkins  0.30455\n",
      "culinary  0.25935\n",
      "docker  0.25145\n",
      "cd  0.2434\n",
      "ci  0.23938\n",
      "ruby  0.20856\n"
     ]
    }
   ],
   "source": [
    "collection=\"jobs\"\n",
    "\n",
    "request = {\n",
    "    \"params\": {\n",
    "        \"qf\": \"job_description job_title\",\n",
    "        \"fore\": \"{!type=$defType qf=$qf v=$q}\",\n",
    "        \"back\": \"*:*\",\n",
    "        \"defType\": \"edismax\",\n",
    "        \"rows\": 0,\n",
    "        \"echoParams\": \"none\",\n",
    "        \"omitHeader\": \"true\"\n",
    "    },\n",
    "    \"query\": \"\\\"chef\\\"\",\n",
    "    \"facet\": {\n",
    "        \"job_description_keywords\": {\n",
    "            \"type\": \"terms\",\n",
    "            \"field\": \"job_description\",\n",
    "            \"sort\": { \"relatedness\": \"desc\"},\n",
    "            \"facet\": {\n",
    "                \"relatedness\": {\n",
    "                    \"type\": \"func\",\n",
    "                    \"func\": \"relatedness($fore,$back)\",\n",
    "                    \"min_popularity\": 0.0005\n",
    "                }\n",
    "            }            \n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "search_results = engine.search(collection, request).json()\n",
    "for bucket in search_results[\"facets\"][\"job_description_keywords\"][\"buckets\"]:\n",
    "    print(f'{bucket[\"val\"]}  {bucket[\"relatedness\"][\"relatedness\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Success!\n",
    "\n",
    "You've leveraged a semantic knowledge graph to find related terms for a query, performed query expansion based upon semantically-similar terms, explored multiple different way to impact precision and recall of queries through integrating semantically-augmented queries, generated content-based recommendations leveraging a semantic knowledge graph, explored arbitrary relationship types by traversing a semantic knowledge graph, and performed both query classification and query disambiguration using a semantic knowledge graph.\n",
    "\n",
    "Semantic knowledge graphs can be a powerful tool for understaning user intent and interpreting both queries and content based upon meaning instead of just text kewords.\n",
    "\n",
    "Up next: [Related Keyword Detection from Signals](../ch06/2.related-keywords-from-signals.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
