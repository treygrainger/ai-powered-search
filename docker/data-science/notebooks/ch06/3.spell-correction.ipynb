{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Misspelling detection and correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: This notebook depends upon the the Retrotech dataset. If you have any issues, please rerun the [Setting up the Retrotech Dataset](../ch04/1.setting-up-the-retrotech-dataset.ipynb) notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import json\n",
    "from aips import *\n",
    "import pandas\n",
    "import nltk\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import numpy as np\n",
    "import re\n",
    "nltk.download('stopwords')\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"AIPS\").getOrCreate()\n",
    "engine = get_engine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 6.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'modes': 421, 'model': 159, 'modern': 139, 'modem': 56, 'mode6': 9}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products_collection = engine.get_collection(\"products\")\n",
    "query = \"moden\"\n",
    "response = engine.spell_check(products_collection, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the real signals\n",
    "signals_collection = engine.get_collection(\"signals\")\n",
    "create_view(signals_collection, \"signals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 6.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create user-searchs table each raw represent one search query.\n",
    "query = \"\"\"SELECT searches.user AS user,\n",
    "           LOWER(TRIM(searches.target)) As keyword\n",
    "           FROM signals AS searches WHERE searches.type = 'query'\n",
    "           GROUP BY keyword, user\"\"\"\n",
    "query_signals = spark.sql(query).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Tokenize queries and count word frequencies. \n",
    "Check word frequency distribution quantiles. The quantile will help decide cut off point for potential misspellings and corrections. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 6.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "word_list = defaultdict(int)\n",
    "\n",
    "for row in query_signals:\n",
    "    query = row[\"keyword\"]\n",
    "    tokenizer = RegexpTokenizer(r'\\w+') \n",
    "    tokens = tokenizer.tokenize(query)\n",
    "    for token in tokens:\n",
    "        if token not in stop_words and len(token) > 3 and not token.isdigit():  #drop stopwords and digit only tokens\n",
    "            # and only consider token length > 3, since hard to judge whether a very short token is misspelled or not\n",
    "            word_list[token] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 6.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.1: 5.0,\n",
       " 0.2: 6.0,\n",
       " 0.3: 8.0,\n",
       " 0.4: 12.0,\n",
       " 0.5: 16.0,\n",
       " 0.6: 25.0,\n",
       " 0.7: 47.0,\n",
       " 0.8: 142.20000000000027,\n",
       " 0.9: 333.2000000000007}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantiles_to_check = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "quantile_values = np.quantile(np.array(list(word_list.values())), quantiles_to_check)\n",
    "quantiles = dict(zip(quantiles_to_check, quantile_values))\n",
    "quantiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: compute metadata needed for word matching. \n",
    "consider word with low count as misspelling condidates, with high count as correctly spelled candidates. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 6.16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misspell_candidates = []\n",
    "correction_candidates = []\n",
    "misspell_counts = []\n",
    "correction_counts = []\n",
    "misspell_length = []\n",
    "correction_length = []\n",
    "misspell_initial = []\n",
    "correction_initial = []\n",
    "for key, value in word_list.items():\n",
    "    if value <= quantiles[0.2] : #if value == 1:  # this number based on quantile analysis and the data set, more-likely with user-behvaiour data set to be 1\n",
    "        misspell_candidates.append(key)\n",
    "        misspell_counts.append(value)\n",
    "        misspell_length.append(len(key))\n",
    "        misspell_initial.append(key[0])\n",
    "    if value >= quantiles[0.8]:\n",
    "        correction_candidates.append(key)\n",
    "        correction_counts.append(value)\n",
    "        correction_length.append(len(key))\n",
    "        correction_initial.append(key[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 6.17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misspell_candidates_df = pd.DataFrame({\n",
    "    \"misspell\": misspell_candidates, \n",
    "    \"misspell_counts\": misspell_counts, \n",
    "    \"misspell_length\": misspell_length,\n",
    "    \"initial\": misspell_initial})\n",
    "correction_candidates_df = pd.DataFrame({\n",
    "    \"correction\": correction_candidates, \n",
    "    \"correction_counts\": correction_counts, \n",
    "    \"correction_length\": correction_length,\n",
    "    \"initial\": correction_initial})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'orderBy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Show Results:\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmisspell_candidates_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morderBy\u001b[49m(col(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmisspell_counts\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mdesc())\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/generic.py:5902\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5895\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   5896\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[1;32m   5897\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[1;32m   5898\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[1;32m   5899\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[1;32m   5900\u001b[0m ):\n\u001b[1;32m   5901\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[0;32m-> 5902\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'orderBy'"
     ]
    }
   ],
   "source": [
    "#Show Results:\n",
    "\n",
    "misspell_candidates_df.orderBy(col(\"misspell_counts\").desc()).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Find potential matches \n",
    "based on edit distance and whether word initial is the same or not. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lsting 6.18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def good_match(len1, len2, edit_dist): #allow longer words have more edit distance\n",
    "    match = 0\n",
    "    min_length = min(len1, len2)\n",
    "    if min_length < 8:\n",
    "        if edit_dist == 1: match = 1\n",
    "    elif min_length < 11:\n",
    "        if edit_dist <= 2: match = 1\n",
    "    else:\n",
    "        if edit_dist == 3: match = 1\n",
    "    return match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 6.19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_candidates = pd.merge(misspell_candidates_df,\n",
    "                              correction_candidates_df, on=\"initial\")\n",
    "#join missepll list with correction list based on whether they share the same initials to reduce matching time. \n",
    "matches_candidates[\"edit_dist\"] = matches_candidates.apply(\n",
    "    lambda row: nltk.edit_distance(row.misspell,row.correction), axis=1)\n",
    "matches_candidates[\"good_match\"] = matches_candidates.apply(\n",
    "    lambda row: good_match(row.misspell_length, row.correction_length,\n",
    "                           row.edit_dist),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = matches_candidates[matches_candidates[\"good_match\"] == 1].drop([\"initial\",\"good_match\"],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: rank potential matched corrections \n",
    "based on edit distance and correction word frequency. shorter edit distance and higher word count will be prefered. only the top one correction is selected for final matching. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#matches.sort_values(by=['misspell', 'edit_dist', 'correction_counts'], ascending=[True, True, False])\n",
    "matches_final = matches.groupby(\"misspell\").first().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>misspell</th>\n",
       "      <th>correction</th>\n",
       "      <th>misspell_counts</th>\n",
       "      <th>correction_counts</th>\n",
       "      <th>edit_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>iphone3</td>\n",
       "      <td>iphone</td>\n",
       "      <td>6</td>\n",
       "      <td>16854</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>latop</td>\n",
       "      <td>laptop</td>\n",
       "      <td>5</td>\n",
       "      <td>14119</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>laptopa</td>\n",
       "      <td>laptop</td>\n",
       "      <td>6</td>\n",
       "      <td>14119</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>toucpad</td>\n",
       "      <td>touchpad</td>\n",
       "      <td>6</td>\n",
       "      <td>11550</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>touxhpad</td>\n",
       "      <td>touchpad</td>\n",
       "      <td>5</td>\n",
       "      <td>11550</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>wirless</td>\n",
       "      <td>wireless</td>\n",
       "      <td>6</td>\n",
       "      <td>10060</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>tableta</td>\n",
       "      <td>tablet</td>\n",
       "      <td>6</td>\n",
       "      <td>8260</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cage</td>\n",
       "      <td>case</td>\n",
       "      <td>6</td>\n",
       "      <td>7541</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cape</td>\n",
       "      <td>case</td>\n",
       "      <td>5</td>\n",
       "      <td>7541</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>gallaxy</td>\n",
       "      <td>galaxy</td>\n",
       "      <td>6</td>\n",
       "      <td>5839</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>loptops</td>\n",
       "      <td>laptops</td>\n",
       "      <td>5</td>\n",
       "      <td>5565</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>potable</td>\n",
       "      <td>portable</td>\n",
       "      <td>6</td>\n",
       "      <td>4477</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bluetooh</td>\n",
       "      <td>bluetooth</td>\n",
       "      <td>5</td>\n",
       "      <td>4461</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>wats</td>\n",
       "      <td>wars</td>\n",
       "      <td>5</td>\n",
       "      <td>4179</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>kimdle</td>\n",
       "      <td>kindle</td>\n",
       "      <td>5</td>\n",
       "      <td>4129</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>rauter</td>\n",
       "      <td>router</td>\n",
       "      <td>5</td>\n",
       "      <td>4067</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>moden</td>\n",
       "      <td>modem</td>\n",
       "      <td>5</td>\n",
       "      <td>3590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>modum</td>\n",
       "      <td>modem</td>\n",
       "      <td>6</td>\n",
       "      <td>3590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>tosheba</td>\n",
       "      <td>toshiba</td>\n",
       "      <td>6</td>\n",
       "      <td>3432</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>gates</td>\n",
       "      <td>games</td>\n",
       "      <td>6</td>\n",
       "      <td>3239</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     misspell correction  misspell_counts  correction_counts  edit_dist\n",
       "50    iphone3     iphone                6              16854          1\n",
       "62      latop     laptop                5              14119          1\n",
       "61    laptopa     laptop                6              14119          1\n",
       "136   toucpad   touchpad                6              11550          1\n",
       "137  touxhpad   touchpad                5              11550          1\n",
       "148   wirless   wireless                6              10060          1\n",
       "127   tableta     tablet                6               8260          1\n",
       "8        cage       case                6               7541          1\n",
       "10       cape       case                5               7541          1\n",
       "30    gallaxy     galaxy                6               5839          1\n",
       "64    loptops    laptops                5               5565          1\n",
       "90    potable   portable                6               4477          1\n",
       "5    bluetooh  bluetooth                5               4461          1\n",
       "146      wats       wars                5               4179          1\n",
       "56     kimdle     kindle                5               4129          1\n",
       "99     rauter     router                5               4067          1\n",
       "76      moden      modem                5               3590          1\n",
       "77      modum      modem                6               3590          1\n",
       "135   tosheba    toshiba                6               3432          1\n",
       "34      gates      games                6               3239          1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Show Results:\n",
    "cols = [\"misspell\", \"correction\", \"misspell_counts\", \"correction_counts\", \"edit_dist\"]\n",
    "matches_final.sort_values(by=[\"correction_counts\"], ascending=[False])[cols].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing 6.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Alternative - don't tokenize into individual keywords\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "word_list = defaultdict(int)\n",
    "\n",
    "for row in query_signals:\n",
    "    query = row[\"keyword\"]\n",
    "    if query not in stop_words and len(query) > 3 and not query.isdigit():\n",
    "        word_list[query] += 1\n",
    "\n",
    "# TODO: check listing numbers...\n",
    "#run Listing 16.12-16.15 again..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Up next: Chapter 7 - [Interpreting Query Intent through Semantic Search](../ch07/1.index-datasets.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
